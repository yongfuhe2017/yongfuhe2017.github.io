root@ubuntu2[18:49:48]:~/Desktop/streaming#spark-submit --master spark://10.21.208.21:7077 weibo_message.py 10.20.102.52 9999 > log.txt
Spark assembly has been built with Hive, including Datanucleus jars on classpath
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/01/21 18:49:52 INFO SecurityManager: Changing view acls to: root
15/01/21 18:49:52 INFO SecurityManager: Changing modify acls to: root
15/01/21 18:49:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/01/21 18:49:52 INFO Slf4jLogger: Slf4jLogger started
15/01/21 18:49:52 INFO Remoting: Starting remoting
15/01/21 18:49:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.20.70.80:42783]
15/01/21 18:49:53 INFO Utils: Successfully started service 'sparkDriver' on port 42783.
15/01/21 18:49:53 INFO SparkEnv: Registering MapOutputTracker
15/01/21 18:49:53 INFO SparkEnv: Registering BlockManagerMaster
15/01/21 18:49:53 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20150121184953-16b3
15/01/21 18:49:53 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/01/21 18:49:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/01/21 18:49:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-8a459428-dbbb-4f66-95d0-14c5f1a2576c
15/01/21 18:49:53 INFO HttpServer: Starting HTTP Server
15/01/21 18:49:53 INFO Utils: Successfully started service 'HTTP file server' on port 38402.
15/01/21 18:49:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/01/21 18:49:58 INFO SparkUI: Started SparkUI at http://10.20.70.80:4040
15/01/21 18:49:58 INFO Utils: Copying /root/Desktop/streaming/weibo_message.py to /tmp/spark-23acab22-d019-4369-a693-e7a15b67863e/weibo_message.py
15/01/21 18:49:58 INFO SparkContext: Added file file:/root/Desktop/streaming/weibo_message.py at http://10.20.70.80:38402/files/weibo_message.py with timestamp 1421837398808
15/01/21 18:49:58 INFO AppClient$ClientActor: Connecting to master spark://10.21.208.21:7077...
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20150121184954-0045
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/0 on worker-20150105184954-sh-demo-hadoop-05-44392 (sh-demo-hadoop-05:44392) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/0 on hostPort sh-demo-hadoop-05:44392 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/1 on worker-20150105184954-sh-demo-hadoop-10-43330 (sh-demo-hadoop-10:43330) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/1 on hostPort sh-demo-hadoop-10:43330 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/2 on worker-20150105184952-sh-demo-hadoop-02-60835 (sh-demo-hadoop-02:60835) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/2 on hostPort sh-demo-hadoop-02:60835 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/3 on worker-20150105184954-sh-demo-hadoop-06-34008 (sh-demo-hadoop-06:34008) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/3 on hostPort sh-demo-hadoop-06:34008 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/4 on worker-20150105184954-sh-demo-hadoop-04-59442 (sh-demo-hadoop-04:59442) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/4 on hostPort sh-demo-hadoop-04:59442 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/5 on worker-20150105184954-sh-demo-hadoop-07-58997 (sh-demo-hadoop-07:58997) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/5 on hostPort sh-demo-hadoop-07:58997 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/6 on worker-20150105184959-sh-demo-hadoop-08-56160 (sh-demo-hadoop-08:56160) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/6 on hostPort sh-demo-hadoop-08:56160 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/7 on worker-20150105184952-sh-demo-hadoop-09-51936 (sh-demo-hadoop-09:51936) with 1 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/7 on hostPort sh-demo-hadoop-09:51936 with 1 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/8 on worker-20150105184954-sh-demo-hadoop-03-55855 (sh-demo-hadoop-03:55855) with 1 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/8 on hostPort sh-demo-hadoop-03:55855 with 1 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/2 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/7 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/0 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/3 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/5 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/1 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/6 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/4 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/8 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/0 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/1 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/2 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/3 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/4 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/5 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/6 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/7 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/8 is now RUNNING
15/01/21 18:49:59 INFO NettyBlockTransferService: Server created on 40067
15/01/21 18:49:59 INFO BlockManagerMaster: Trying to register BlockManager
15/01/21 18:49:59 INFO BlockManagerMasterActor: Registering block manager 10.20.70.80:40067 with 265.4 MB RAM, BlockManagerId(<driver>, 10.20.70.80, 40067)
15/01/21 18:49:59 INFO BlockManagerMaster: Registered BlockManager
15/01/21 18:50:00 INFO EventLoggingListener: Logging events to hdfs://10.21.208.21:8020/sparklog/app-20150121184954-0045
15/01/21 18:50:00 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
15/01/21 18:50:00 INFO ReceiverTracker: ReceiverTracker started
15/01/21 18:50:00 INFO ForEachDStream: metadataCleanupDelay = -1
15/01/21 18:50:00 INFO SocketInputDStream: metadataCleanupDelay = -1
15/01/21 18:50:00 INFO SocketInputDStream: Slide time = 5000 ms
15/01/21 18:50:00 INFO SocketInputDStream: Storage level = StorageLevel(false, false, false, false, 1)
15/01/21 18:50:00 INFO SocketInputDStream: Checkpoint interval = null
15/01/21 18:50:00 INFO SocketInputDStream: Remember duration = 5000 ms
15/01/21 18:50:00 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@717c4ec7
15/01/21 18:50:00 INFO ForEachDStream: Slide time = 5000 ms
15/01/21 18:50:00 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, false, 1)
15/01/21 18:50:00 INFO ForEachDStream: Checkpoint interval = null
15/01/21 18:50:00 INFO ForEachDStream: Remember duration = 5000 ms
15/01/21 18:50:00 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@18182506
15/01/21 18:50:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:-2
15/01/21 18:50:00 INFO RecurringTimer: Started timer for JobGenerator at time 1421837405000
15/01/21 18:50:00 INFO JobGenerator: Started JobGenerator at 1421837405000 ms
15/01/21 18:50:00 INFO JobScheduler: Started JobScheduler
15/01/21 18:50:00 INFO DAGScheduler: Registering RDD 2 (start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:00 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:-2) with 20 output partitions (allowLocal=false)
15/01/21 18:50:00 INFO DAGScheduler: Final stage: Stage 1(start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:00 INFO DAGScheduler: Parents of final stage: List(Stage 0)
15/01/21 18:50:00 INFO DAGScheduler: Missing parents: List(Stage 0)
15/01/21 18:50:00 INFO DAGScheduler: Submitting Stage 0 (MappedRDD[2] at start at NativeMethodAccessorImpl.java:-2), which has no missing parents
15/01/21 18:50:00 INFO MemoryStore: ensureFreeSpace(2720) called with curMem=0, maxMem=278302556
15/01/21 18:50:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 2.7 KB, free 265.4 MB)
15/01/21 18:50:00 INFO MemoryStore: ensureFreeSpace(1943) called with curMem=2720, maxMem=278302556
15/01/21 18:50:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1943.0 B, free 265.4 MB)
15/01/21 18:50:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.20.70.80:40067 (size: 1943.0 B, free: 265.4 MB)
15/01/21 18:50:00 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
15/01/21 18:50:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:838
15/01/21 18:50:00 INFO DAGScheduler: Submitting 50 missing tasks from Stage 0 (MappedRDD[2] at start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 50 tasks
15/01/21 18:50:01 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-09:46974/user/Executor#597683221] with ID 7
15/01/21 18:50:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:01 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-02:33569/user/Executor#-1289642399] with ID 2
15/01/21 18:50:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:01 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:01 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-09:54385 with 265.0 MB RAM, BlockManagerId(7, sh-demo-hadoop-09, 54385)
15/01/21 18:50:01 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-02:35432 with 265.0 MB RAM, BlockManagerId(2, sh-demo-hadoop-02, 35432)
15/01/21 18:50:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-09:54385 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-02:35432 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-04:36267/user/Executor#1263277294] with ID 4
15/01/21 18:50:02 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, sh-demo-hadoop-04, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, sh-demo-hadoop-04, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1007 ms on sh-demo-hadoop-02 (1/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1047 ms on sh-demo-hadoop-09 (2/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1024 ms on sh-demo-hadoop-02 (3/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 31 ms on sh-demo-hadoop-02 (4/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 32 ms on sh-demo-hadoop-02 (5/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 47 ms on sh-demo-hadoop-09 (6/50)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-06:56018/user/Executor#-865999376] with ID 3
15/01/21 18:50:02 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, sh-demo-hadoop-06, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, sh-demo-hadoop-06, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 30 ms on sh-demo-hadoop-02 (7/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 34 ms on sh-demo-hadoop-09 (8/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 35 ms on sh-demo-hadoop-02 (9/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 38 ms on sh-demo-hadoop-02 (10/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 35 ms on sh-demo-hadoop-09 (11/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 33 ms on sh-demo-hadoop-02 (12/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 18 ms on sh-demo-hadoop-09 (13/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 34 ms on sh-demo-hadoop-02 (14/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 29 ms on sh-demo-hadoop-02 (15/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 28 ms on sh-demo-hadoop-09 (16/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 20.0 in stage 0.0 (TID 20) in 26 ms on sh-demo-hadoop-02 (17/50)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-08:36591/user/Executor#-720635433] with ID 6
15/01/21 18:50:02 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24, sh-demo-hadoop-08, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25, sh-demo-hadoop-08, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 21.0 in stage 0.0 (TID 21) in 44 ms on sh-demo-hadoop-02 (18/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 22.0 in stage 0.0 (TID 22) in 41 ms on sh-demo-hadoop-09 (19/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 23.0 in stage 0.0 (TID 23) in 43 ms on sh-demo-hadoop-02 (20/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 27.0 in stage 0.0 (TID 27) in 26 ms on sh-demo-hadoop-09 (21/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 26.0 in stage 0.0 (TID 26) in 42 ms on sh-demo-hadoop-02 (22/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 28.0 in stage 0.0 (TID 28) in 31 ms on sh-demo-hadoop-02 (23/50)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-05:41697/user/Executor#-472026627] with ID 0
15/01/21 18:50:02 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32, sh-demo-hadoop-05, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33, sh-demo-hadoop-05, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 29) in 40 ms on sh-demo-hadoop-09 (24/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 30.0 in stage 0.0 (TID 30) in 33 ms on sh-demo-hadoop-02 (25/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 31.0 in stage 0.0 (TID 31) in 32 ms on sh-demo-hadoop-02 (26/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 34.0 in stage 0.0 (TID 34) in 20 ms on sh-demo-hadoop-09 (27/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 35.0 in stage 0.0 (TID 35) in 20 ms on sh-demo-hadoop-02 (28/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 36.0 in stage 0.0 (TID 36) in 22 ms on sh-demo-hadoop-02 (29/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 38.0 in stage 0.0 (TID 38) in 22 ms on sh-demo-hadoop-02 (30/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 37.0 in stage 0.0 (TID 37) in 27 ms on sh-demo-hadoop-09 (31/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 39.0 in stage 0.0 (TID 39) in 24 ms on sh-demo-hadoop-02 (32/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 41.0 in stage 0.0 (TID 41) in 20 ms on sh-demo-hadoop-09 (33/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 40.0 in stage 0.0 (TID 40) in 26 ms on sh-demo-hadoop-02 (34/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 42.0 in stage 0.0 (TID 42) in 26 ms on sh-demo-hadoop-02 (35/50)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-03:55105/user/Executor#-1663855072] with ID 8
15/01/21 18:50:02 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46, sh-demo-hadoop-03, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 44.0 in stage 0.0 (TID 44) in 31 ms on sh-demo-hadoop-02 (36/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 43.0 in stage 0.0 (TID 43) in 38 ms on sh-demo-hadoop-09 (37/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 45.0 in stage 0.0 (TID 45) in 37 ms on sh-demo-hadoop-02 (38/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 47.0 in stage 0.0 (TID 47) in 24 ms on sh-demo-hadoop-02 (39/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 49.0 in stage 0.0 (TID 49) in 14 ms on sh-demo-hadoop-02 (40/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 48.0 in stage 0.0 (TID 48) in 26 ms on sh-demo-hadoop-09 (41/50)
15/01/21 18:50:02 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-04:38128 with 265.0 MB RAM, BlockManagerId(4, sh-demo-hadoop-04, 38128)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622/user/Executor#-1701637077] with ID 1
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-07:57384/user/Executor#937487728] with ID 5
15/01/21 18:50:02 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-06:52083 with 265.0 MB RAM, BlockManagerId(3, sh-demo-hadoop-06, 52083)
15/01/21 18:50:02 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-08:59231 with 265.0 MB RAM, BlockManagerId(6, sh-demo-hadoop-08, 59231)
15/01/21 18:50:02 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-05:59361 with 265.0 MB RAM, BlockManagerId(0, sh-demo-hadoop-05, 59361)
15/01/21 18:50:03 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-03:44092 with 265.0 MB RAM, BlockManagerId(8, sh-demo-hadoop-03, 44092)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-04:38128 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-08:59231 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-06:52083 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-10:56623 with 265.0 MB RAM, BlockManagerId(1, sh-demo-hadoop-10, 56623)
15/01/21 18:50:03 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-07:57986 with 265.0 MB RAM, BlockManagerId(5, sh-demo-hadoop-07, 57986)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-05:59361 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 1523 ms on sh-demo-hadoop-04 (42/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1527 ms on sh-demo-hadoop-04 (43/50)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-03:44092 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 25.0 in stage 0.0 (TID 25) in 1509 ms on sh-demo-hadoop-08 (44/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 24.0 in stage 0.0 (TID 24) in 1514 ms on sh-demo-hadoop-08 (45/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 1621 ms on sh-demo-hadoop-06 (46/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 1623 ms on sh-demo-hadoop-06 (47/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 32.0 in stage 0.0 (TID 32) in 1613 ms on sh-demo-hadoop-05 (48/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 33.0 in stage 0.0 (TID 33) in 1615 ms on sh-demo-hadoop-05 (49/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 46.0 in stage 0.0 (TID 46) in 1569 ms on sh-demo-hadoop-03 (50/50)
15/01/21 18:50:03 INFO DAGScheduler: Stage 0 (start at NativeMethodAccessorImpl.java:-2) finished in 3.036 s
15/01/21 18:50:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/01/21 18:50:03 INFO DAGScheduler: looking for newly runnable stages
15/01/21 18:50:03 INFO DAGScheduler: running: Set()
15/01/21 18:50:03 INFO DAGScheduler: waiting: Set(Stage 1)
15/01/21 18:50:03 INFO DAGScheduler: failed: Set()
15/01/21 18:50:03 INFO DAGScheduler: Missing parents for Stage 1: List()
15/01/21 18:50:03 INFO DAGScheduler: Submitting Stage 1 (ShuffledRDD[3] at start at NativeMethodAccessorImpl.java:-2), which is now runnable
15/01/21 18:50:03 INFO MemoryStore: ensureFreeSpace(2232) called with curMem=4663, maxMem=278302556
15/01/21 18:50:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.2 KB, free 265.4 MB)
15/01/21 18:50:03 INFO MemoryStore: ensureFreeSpace(1642) called with curMem=6895, maxMem=278302556
15/01/21 18:50:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1642.0 B, free 265.4 MB)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.20.70.80:40067 (size: 1642.0 B, free: 265.4 MB)
15/01/21 18:50:03 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/01/21 18:50:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:838
15/01/21 18:50:04 INFO DAGScheduler: Submitting 20 missing tasks from Stage 1 (ShuffledRDD[3] at start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 20 tasks
15/01/21 18:50:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 50, sh-demo-hadoop-04, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 51, sh-demo-hadoop-02, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 52, sh-demo-hadoop-07, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 53, sh-demo-hadoop-03, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 54, sh-demo-hadoop-08, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 55, sh-demo-hadoop-06, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 56, sh-demo-hadoop-10, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 57, sh-demo-hadoop-05, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 58, sh-demo-hadoop-09, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 59, sh-demo-hadoop-04, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 60, sh-demo-hadoop-02, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 61, sh-demo-hadoop-07, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 62, sh-demo-hadoop-08, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 63, sh-demo-hadoop-06, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 64, sh-demo-hadoop-10, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 65, sh-demo-hadoop-05, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-09:54385 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-02:35432 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-08:59231 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-03:44092 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-02:33569
15/01/21 18:50:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 390 bytes
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-09:46974
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-08:36591
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-05:59361 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-03:55105
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-06:52083 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 66, sh-demo-hadoop-09, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 58) in 129 ms on sh-demo-hadoop-09 (1/20)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-05:41697
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-06:56018
15/01/21 18:50:04 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 67, sh-demo-hadoop-09, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 66) in 26 ms on sh-demo-hadoop-09 (2/20)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 68, sh-demo-hadoop-02, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 69, sh-demo-hadoop-02, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 51) in 165 ms on sh-demo-hadoop-02 (3/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 60) in 158 ms on sh-demo-hadoop-02 (4/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 67) in 23 ms on sh-demo-hadoop-09 (5/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 69) in 21 ms on sh-demo-hadoop-02 (6/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 68) in 24 ms on sh-demo-hadoop-02 (7/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 53) in 186 ms on sh-demo-hadoop-03 (8/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 54) in 219 ms on sh-demo-hadoop-08 (9/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 62) in 221 ms on sh-demo-hadoop-08 (10/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 65) in 221 ms on sh-demo-hadoop-05 (11/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 57) in 273 ms on sh-demo-hadoop-05 (12/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 63) in 273 ms on sh-demo-hadoop-06 (13/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 55) in 293 ms on sh-demo-hadoop-06 (14/20)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-04:38128 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-04:36267
15/01/21 18:50:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 50) in 469 ms on sh-demo-hadoop-04 (15/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 59) in 465 ms on sh-demo-hadoop-04 (16/20)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-10:56623 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-07:57986 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-07:57384
15/01/21 18:50:04 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 56) in 946 ms on sh-demo-hadoop-10 (17/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 64) in 941 ms on sh-demo-hadoop-10 (18/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 61) in 952 ms on sh-demo-hadoop-07 (19/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 52) in 963 ms on sh-demo-hadoop-07 (20/20)
15/01/21 18:50:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/01/21 18:50:04 INFO DAGScheduler: Stage 1 (start at NativeMethodAccessorImpl.java:-2) finished in 0.965 s
15/01/21 18:50:04 INFO DAGScheduler: Job 0 finished: start at NativeMethodAccessorImpl.java:-2, took 4.358238 s
15/01/21 18:50:04 INFO ReceiverTracker: Starting 1 receivers
15/01/21 18:50:05 INFO JobScheduler: Added jobs for time 1421837405000 ms
15/01/21 18:50:05 INFO JobScheduler: Starting job streaming job 1421837405000 ms.0 from job set of time 1421837405000 ms
15/01/21 18:50:05 INFO JobScheduler: Finished job streaming job 1421837405000 ms.0 from job set of time 1421837405000 ms
15/01/21 18:50:05 INFO JobScheduler: Total delay: 0.070 s for time 1421837405000 ms (execution: 0.025 s)
15/01/21 18:50:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:05 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:-2
15/01/21 18:50:05 INFO DAGScheduler: Got job 1 (start at NativeMethodAccessorImpl.java:-2) with 1 output partitions (allowLocal=false)
15/01/21 18:50:05 INFO DAGScheduler: Final stage: Stage 2(start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:05 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:05 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:05 INFO DAGScheduler: Submitting Stage 2 (ParallelCollectionRDD[0] at start at NativeMethodAccessorImpl.java:-2), which has no missing parents
15/01/21 18:50:05 INFO MemoryStore: ensureFreeSpace(30480) called with curMem=8537, maxMem=278302556
15/01/21 18:50:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 29.8 KB, free 265.4 MB)
15/01/21 18:50:05 INFO MemoryStore: ensureFreeSpace(17186) called with curMem=39017, maxMem=278302556
15/01/21 18:50:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 16.8 KB, free 265.4 MB)
15/01/21 18:50:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.20.70.80:40067 (size: 16.8 KB, free: 265.4 MB)
15/01/21 18:50:05 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/01/21 18:50:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:838
15/01/21 18:50:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 2 (ParallelCollectionRDD[0] at start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
15/01/21 18:50:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 70, sh-demo-hadoop-10, PROCESS_LOCAL, 1934 bytes)
15/01/21 18:50:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sh-demo-hadoop-10:56623 (size: 16.8 KB, free: 265.0 MB)
15/01/21 18:50:05 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:05 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:05 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:05 INFO BlockManagerInfo: Added input-0-1421837410600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:05 INFO BlockManagerInfo: Added input-0-1421837410600 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:07 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:07 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:09 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:09 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:10 INFO JobScheduler: Added jobs for time 1421837410000 ms
15/01/21 18:50:10 INFO JobScheduler: Starting job streaming job 1421837410000 ms.0 from job set of time 1421837410000 ms
15/01/21 18:50:10 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:50:10 INFO DAGScheduler: Got job 2 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:50:10 INFO DAGScheduler: Final stage: Stage 3(runJob at PythonRDD.scala:344)
15/01/21 18:50:10 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:10 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:10 INFO DAGScheduler: Submitting Stage 3 (PythonRDD[6] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:50:10 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=56203, maxMem=278302556
15/01/21 18:50:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.2 KB, free 265.4 MB)
15/01/21 18:50:10 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=59523, maxMem=278302556
15/01/21 18:50:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.4 MB)
15/01/21 18:50:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:50:10 INFO BlockManagerMaster: Updated info of block broadcast_3_piece0
15/01/21 18:50:10 INFO SparkContext: Created broadcast 3 from getCallSite at DStream.scala:294
15/01/21 18:50:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 3 (PythonRDD[6] at RDD at PythonRDD.scala:43)
15/01/21 18:50:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
15/01/21 18:50:10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 71, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:50:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:50:11 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 71) in 1489 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:50:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/01/21 18:50:11 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:11 INFO DAGScheduler: Stage 3 (runJob at PythonRDD.scala:344) finished in 1.497 s
15/01/21 18:50:11 INFO DAGScheduler: Job 2 finished: runJob at PythonRDD.scala:344, took 1.536090 s
15/01/21 18:50:11 INFO JobScheduler: Finished job streaming job 1421837410000 ms.0 from job set of time 1421837410000 ms
15/01/21 18:50:11 INFO JobScheduler: Total delay: 1.567 s for time 1421837410000 ms (execution: 1.563 s)
15/01/21 18:50:11 INFO BlockRDD: Removing RDD 4 from persistence list
15/01/21 18:50:11 INFO BlockManager: Removing RDD 4
15/01/21 18:50:11 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[4] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837410000 ms
15/01/21 18:50:11 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:11 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:13 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:13 INFO BlockManagerInfo: Added input-0-1421837418800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:13 INFO BlockManagerInfo: Added input-0-1421837418800 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:15 INFO JobScheduler: Added jobs for time 1421837415000 ms
15/01/21 18:50:15 INFO JobScheduler: Starting job streaming job 1421837415000 ms.0 from job set of time 1421837415000 ms
15/01/21 18:50:15 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:50:15 INFO DAGScheduler: Got job 3 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:50:15 INFO DAGScheduler: Final stage: Stage 4(runJob at PythonRDD.scala:344)
15/01/21 18:50:15 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:15 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:15 INFO DAGScheduler: Submitting Stage 4 (PythonRDD[8] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:50:15 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=62014, maxMem=278302556
15/01/21 18:50:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:50:15 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=65334, maxMem=278302556
15/01/21 18:50:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:50:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:50:15 INFO BlockManagerMaster: Updated info of block broadcast_4_piece0
15/01/21 18:50:15 INFO SparkContext: Created broadcast 4 from getCallSite at DStream.scala:294
15/01/21 18:50:15 INFO DAGScheduler: Submitting 1 missing tasks from Stage 4 (PythonRDD[8] at RDD at PythonRDD.scala:43)
15/01/21 18:50:15 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
15/01/21 18:50:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 72, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:50:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:50:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 72) in 94 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:50:15 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
15/01/21 18:50:15 INFO DAGScheduler: Stage 4 (runJob at PythonRDD.scala:344) finished in 0.099 s
15/01/21 18:50:15 INFO DAGScheduler: Job 3 finished: runJob at PythonRDD.scala:344, took 0.109472 s
15/01/21 18:50:15 INFO JobScheduler: Finished job streaming job 1421837415000 ms.0 from job set of time 1421837415000 ms
15/01/21 18:50:15 INFO BlockRDD: Removing RDD 5 from persistence list
15/01/21 18:50:15 INFO JobScheduler: Total delay: 0.125 s for time 1421837415000 ms (execution: 0.123 s)
15/01/21 18:50:15 INFO BlockManager: Removing RDD 5
15/01/21 18:50:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[5] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837415000 ms
15/01/21 18:50:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837405000 ms)
15/01/21 18:50:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:15 INFO BlockManagerInfo: Removed input-0-1421837410600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:15 INFO BlockManagerInfo: Removed input-0-1421837410600 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:15 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:15 INFO BlockManagerInfo: Added input-0-1421837420800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:15 INFO BlockManagerInfo: Added input-0-1421837420800 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:17 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:17 INFO BlockManagerInfo: Added input-0-1421837422800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:17 INFO BlockManagerInfo: Added input-0-1421837422800 in memory on sh-demo-hadoop-02:35432 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:19 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:20 INFO JobScheduler: Added jobs for time 1421837420000 ms
15/01/21 18:50:20 INFO JobScheduler: Starting job streaming job 1421837420000 ms.0 from job set of time 1421837420000 ms
15/01/21 18:50:20 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:50:20 INFO DAGScheduler: Got job 4 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:50:20 INFO DAGScheduler: Final stage: Stage 5(runJob at PythonRDD.scala:344)
15/01/21 18:50:20 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:20 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:20 INFO DAGScheduler: Submitting Stage 5 (PythonRDD[10] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:50:20 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=67825, maxMem=278302556
15/01/21 18:50:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:50:20 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=71145, maxMem=278302556
15/01/21 18:50:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:50:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:50:20 INFO BlockManagerMaster: Updated info of block broadcast_5_piece0
15/01/21 18:50:20 INFO SparkContext: Created broadcast 5 from getCallSite at DStream.scala:294
15/01/21 18:50:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 5 (PythonRDD[10] at RDD at PythonRDD.scala:43)
15/01/21 18:50:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
15/01/21 18:50:20 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 73, sh-demo-hadoop-09, NODE_LOCAL, 1236 bytes)
15/01/21 18:50:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sh-demo-hadoop-09:54385 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:50:20 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 73) in 563 ms on sh-demo-hadoop-09 (1/1)
15/01/21 18:50:20 INFO DAGScheduler: Stage 5 (runJob at PythonRDD.scala:344) finished in 0.562 s
15/01/21 18:50:20 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
15/01/21 18:50:20 INFO DAGScheduler: Job 4 finished: runJob at PythonRDD.scala:344, took 0.577708 s
15/01/21 18:50:20 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:50:20 INFO DAGScheduler: Got job 5 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:50:20 INFO DAGScheduler: Final stage: Stage 6(runJob at PythonRDD.scala:344)
15/01/21 18:50:20 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:20 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:20 INFO DAGScheduler: Submitting Stage 6 (PythonRDD[11] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:50:20 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=73636, maxMem=278302556
15/01/21 18:50:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:50:20 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=76956, maxMem=278302556
15/01/21 18:50:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:50:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:50:20 INFO BlockManagerMaster: Updated info of block broadcast_6_piece0
15/01/21 18:50:20 INFO SparkContext: Created broadcast 6 from getCallSite at DStream.scala:294
15/01/21 18:50:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 6 (PythonRDD[11] at RDD at PythonRDD.scala:43)
15/01/21 18:50:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
15/01/21 18:50:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 74, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:50:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:50:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 74) in 89 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:50:20 INFO DAGScheduler: Stage 6 (runJob at PythonRDD.scala:344) finished in 0.090 s
15/01/21 18:50:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
15/01/21 18:50:20 INFO DAGScheduler: Job 5 finished: runJob at PythonRDD.scala:344, took 0.098937 s
15/01/21 18:50:20 INFO JobScheduler: Finished job streaming job 1421837420000 ms.0 from job set of time 1421837420000 ms
15/01/21 18:50:20 INFO BlockRDD: Removing RDD 7 from persistence list
15/01/21 18:50:20 INFO JobScheduler: Total delay: 0.710 s for time 1421837420000 ms (execution: 0.708 s)
15/01/21 18:50:20 INFO BlockManager: Removing RDD 7
15/01/21 18:50:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[7] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837420000 ms
15/01/21 18:50:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837410000 ms)
15/01/21 18:50:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:20 INFO BlockManagerInfo: Removed input-0-1421837418800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:20 INFO BlockManagerInfo: Removed input-0-1421837418800 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:21 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:23 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:25 INFO JobScheduler: Added jobs for time 1421837425000 ms
15/01/21 18:50:25 INFO JobScheduler: Starting job streaming job 1421837425000 ms.0 from job set of time 1421837425000 ms
15/01/21 18:50:25 INFO JobScheduler: Finished job streaming job 1421837425000 ms.0 from job set of time 1421837425000 ms
15/01/21 18:50:25 INFO JobScheduler: Total delay: 0.005 s for time 1421837425000 ms (execution: 0.004 s)
15/01/21 18:50:25 INFO BlockRDD: Removing RDD 9 from persistence list
15/01/21 18:50:25 INFO BlockManager: Removing RDD 9
15/01/21 18:50:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[9] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837425000 ms
15/01/21 18:50:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837415000 ms)
15/01/21 18:50:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:25 INFO BlockManagerInfo: Removed input-0-1421837420800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:25 INFO BlockManagerInfo: Removed input-0-1421837420800 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:25 INFO BlockManagerInfo: Removed input-0-1421837422800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:25 INFO BlockManagerInfo: Removed input-0-1421837422800 on sh-demo-hadoop-02:35432 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:25 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:27 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:29 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:30 INFO JobScheduler: Added jobs for time 1421837430000 ms
15/01/21 18:50:30 INFO JobScheduler: Starting job streaming job 1421837430000 ms.0 from job set of time 1421837430000 ms
15/01/21 18:50:30 INFO JobScheduler: Finished job streaming job 1421837430000 ms.0 from job set of time 1421837430000 ms
15/01/21 18:50:30 INFO JobScheduler: Total delay: 0.004 s for time 1421837430000 ms (execution: 0.003 s)
15/01/21 18:50:30 INFO BlockRDD: Removing RDD 12 from persistence list
15/01/21 18:50:30 INFO BlockManager: Removing RDD 12
15/01/21 18:50:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[12] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837430000 ms
15/01/21 18:50:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837420000 ms)
15/01/21 18:50:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:31 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:33 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:35 INFO JobScheduler: Added jobs for time 1421837435000 ms
15/01/21 18:50:35 INFO JobScheduler: Starting job streaming job 1421837435000 ms.0 from job set of time 1421837435000 ms
15/01/21 18:50:35 INFO JobScheduler: Finished job streaming job 1421837435000 ms.0 from job set of time 1421837435000 ms
15/01/21 18:50:35 INFO BlockRDD: Removing RDD 13 from persistence list
15/01/21 18:50:35 INFO JobScheduler: Total delay: 0.005 s for time 1421837435000 ms (execution: 0.003 s)
15/01/21 18:50:35 INFO BlockManager: Removing RDD 13
15/01/21 18:50:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[13] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837435000 ms
15/01/21 18:50:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837425000 ms)
15/01/21 18:50:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:35 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:37 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:39 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:40 INFO JobScheduler: Added jobs for time 1421837440000 ms
15/01/21 18:50:40 INFO JobScheduler: Starting job streaming job 1421837440000 ms.0 from job set of time 1421837440000 ms
15/01/21 18:50:40 INFO JobScheduler: Finished job streaming job 1421837440000 ms.0 from job set of time 1421837440000 ms
15/01/21 18:50:40 INFO JobScheduler: Total delay: 0.005 s for time 1421837440000 ms (execution: 0.004 s)
15/01/21 18:50:40 INFO BlockRDD: Removing RDD 14 from persistence list
15/01/21 18:50:40 INFO BlockManager: Removing RDD 14
15/01/21 18:50:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[14] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837440000 ms
15/01/21 18:50:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837430000 ms)
15/01/21 18:50:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:41 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:41 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:43 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:43 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:45 INFO JobScheduler: Added jobs for time 1421837445000 ms
15/01/21 18:50:45 INFO JobScheduler: Starting job streaming job 1421837445000 ms.0 from job set of time 1421837445000 ms
15/01/21 18:50:45 INFO JobScheduler: Finished job streaming job 1421837445000 ms.0 from job set of time 1421837445000 ms
15/01/21 18:50:45 INFO JobScheduler: Total delay: 0.004 s for time 1421837445000 ms (execution: 0.003 s)
15/01/21 18:50:45 INFO BlockRDD: Removing RDD 15 from persistence list
15/01/21 18:50:45 INFO BlockManager: Removing RDD 15
15/01/21 18:50:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[15] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837445000 ms
15/01/21 18:50:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837435000 ms)
15/01/21 18:50:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:45 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:45 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:47 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:47 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:49 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:49 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:50 INFO JobScheduler: Added jobs for time 1421837450000 ms
15/01/21 18:50:50 INFO JobScheduler: Starting job streaming job 1421837450000 ms.0 from job set of time 1421837450000 ms
15/01/21 18:50:50 INFO JobScheduler: Finished job streaming job 1421837450000 ms.0 from job set of time 1421837450000 ms
15/01/21 18:50:50 INFO JobScheduler: Total delay: 0.003 s for time 1421837450000 ms (execution: 0.003 s)
15/01/21 18:50:50 INFO BlockRDD: Removing RDD 16 from persistence list
15/01/21 18:50:50 INFO BlockManager: Removing RDD 16
15/01/21 18:50:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[16] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837450000 ms
15/01/21 18:50:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837440000 ms)
15/01/21 18:50:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:51 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:51 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:53 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:53 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:55 INFO JobScheduler: Added jobs for time 1421837455000 ms
15/01/21 18:50:55 INFO JobScheduler: Starting job streaming job 1421837455000 ms.0 from job set of time 1421837455000 ms
15/01/21 18:50:55 INFO JobScheduler: Finished job streaming job 1421837455000 ms.0 from job set of time 1421837455000 ms
15/01/21 18:50:55 INFO JobScheduler: Total delay: 0.004 s for time 1421837455000 ms (execution: 0.003 s)
15/01/21 18:50:55 INFO BlockRDD: Removing RDD 17 from persistence list
15/01/21 18:50:55 INFO BlockManager: Removing RDD 17
15/01/21 18:50:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[17] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837455000 ms
15/01/21 18:50:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837445000 ms)
15/01/21 18:50:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:55 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:55 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:58 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:58 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:58 INFO BlockManagerInfo: Added input-0-1421837463200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:58 INFO BlockManagerInfo: Added input-0-1421837463200 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:00 INFO JobScheduler: Added jobs for time 1421837460000 ms
15/01/21 18:51:00 INFO JobScheduler: Starting job streaming job 1421837460000 ms.0 from job set of time 1421837460000 ms
15/01/21 18:51:00 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:00 INFO DAGScheduler: Got job 6 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:00 INFO DAGScheduler: Final stage: Stage 7(runJob at PythonRDD.scala:344)
15/01/21 18:51:00 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:00 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:00 INFO DAGScheduler: Submitting Stage 7 (PythonRDD[20] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:00 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=79447, maxMem=278302556
15/01/21 18:51:00 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:00 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=82767, maxMem=278302556
15/01/21 18:51:00 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:00 INFO BlockManagerMaster: Updated info of block broadcast_7_piece0
15/01/21 18:51:00 INFO SparkContext: Created broadcast 7 from getCallSite at DStream.scala:294
15/01/21 18:51:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 7 (PythonRDD[20] at RDD at PythonRDD.scala:43)
15/01/21 18:51:00 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
15/01/21 18:51:00 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 75, sh-demo-hadoop-07, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:00 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:00 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sh-demo-hadoop-07:57986 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:00 INFO BlockManagerInfo: Added input-0-1421837465200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:00 INFO BlockManagerInfo: Added input-0-1421837465200 in memory on sh-demo-hadoop-05:59361 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:00 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 75) in 946 ms on sh-demo-hadoop-07 (1/1)
15/01/21 18:51:00 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
15/01/21 18:51:00 INFO DAGScheduler: Stage 7 (runJob at PythonRDD.scala:344) finished in 0.949 s
15/01/21 18:51:00 INFO DAGScheduler: Job 6 finished: runJob at PythonRDD.scala:344, took 0.957380 s
15/01/21 18:51:00 INFO JobScheduler: Finished job streaming job 1421837460000 ms.0 from job set of time 1421837460000 ms
15/01/21 18:51:00 INFO JobScheduler: Total delay: 0.973 s for time 1421837460000 ms (execution: 0.972 s)
15/01/21 18:51:00 INFO BlockRDD: Removing RDD 18 from persistence list
15/01/21 18:51:00 INFO BlockManager: Removing RDD 18
15/01/21 18:51:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[18] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837460000 ms
15/01/21 18:51:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837450000 ms)
15/01/21 18:51:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:02 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:02 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:04 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:04 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:05 INFO JobScheduler: Added jobs for time 1421837465000 ms
15/01/21 18:51:05 INFO JobScheduler: Starting job streaming job 1421837465000 ms.0 from job set of time 1421837465000 ms
15/01/21 18:51:05 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:05 INFO DAGScheduler: Got job 7 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:05 INFO DAGScheduler: Final stage: Stage 8(runJob at PythonRDD.scala:344)
15/01/21 18:51:05 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:05 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:05 INFO DAGScheduler: Submitting Stage 8 (PythonRDD[22] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:05 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=85258, maxMem=278302556
15/01/21 18:51:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:05 INFO MemoryStore: ensureFreeSpace(2492) called with curMem=88578, maxMem=278302556
15/01/21 18:51:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:05 INFO BlockManagerMaster: Updated info of block broadcast_8_piece0
15/01/21 18:51:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:838
15/01/21 18:51:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 8 (PythonRDD[22] at RDD at PythonRDD.scala:43)
15/01/21 18:51:05 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
15/01/21 18:51:05 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 76, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:05 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 76) in 95 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:05 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
15/01/21 18:51:05 INFO DAGScheduler: Stage 8 (runJob at PythonRDD.scala:344) finished in 0.095 s
15/01/21 18:51:05 INFO DAGScheduler: Job 7 finished: runJob at PythonRDD.scala:344, took 0.111227 s
15/01/21 18:51:05 INFO JobScheduler: Finished job streaming job 1421837465000 ms.0 from job set of time 1421837465000 ms
15/01/21 18:51:05 INFO BlockRDD: Removing RDD 19 from persistence list
15/01/21 18:51:05 INFO BlockManager: Removing RDD 19
15/01/21 18:51:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[19] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837465000 ms
15/01/21 18:51:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837455000 ms)
15/01/21 18:51:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:05 INFO JobScheduler: Total delay: 0.127 s for time 1421837465000 ms (execution: 0.127 s)
15/01/21 18:51:05 INFO BlockManagerInfo: Removed input-0-1421837463200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:05 INFO BlockManagerInfo: Removed input-0-1421837463200 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:06 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:06 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:08 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:08 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:10 INFO JobScheduler: Added jobs for time 1421837470000 ms
15/01/21 18:51:10 INFO JobScheduler: Starting job streaming job 1421837470000 ms.0 from job set of time 1421837470000 ms
15/01/21 18:51:10 INFO JobScheduler: Finished job streaming job 1421837470000 ms.0 from job set of time 1421837470000 ms
15/01/21 18:51:10 INFO BlockRDD: Removing RDD 21 from persistence list
15/01/21 18:51:10 INFO JobScheduler: Total delay: 0.004 s for time 1421837470000 ms (execution: 0.003 s)
15/01/21 18:51:10 INFO BlockManager: Removing RDD 21
15/01/21 18:51:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[21] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837470000 ms
15/01/21 18:51:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837460000 ms)
15/01/21 18:51:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:10 INFO BlockManagerInfo: Removed input-0-1421837465200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:10 INFO BlockManagerInfo: Removed input-0-1421837465200 on sh-demo-hadoop-05:59361 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:10 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:10 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:12 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:14 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:15 INFO JobScheduler: Added jobs for time 1421837475000 ms
15/01/21 18:51:15 INFO JobScheduler: Starting job streaming job 1421837475000 ms.0 from job set of time 1421837475000 ms
15/01/21 18:51:15 INFO JobScheduler: Finished job streaming job 1421837475000 ms.0 from job set of time 1421837475000 ms
15/01/21 18:51:15 INFO JobScheduler: Total delay: 0.005 s for time 1421837475000 ms (execution: 0.004 s)
15/01/21 18:51:15 INFO BlockRDD: Removing RDD 23 from persistence list
15/01/21 18:51:15 INFO BlockManager: Removing RDD 23
15/01/21 18:51:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[23] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837475000 ms
15/01/21 18:51:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837465000 ms)
15/01/21 18:51:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:16 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:18 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:20 INFO JobScheduler: Added jobs for time 1421837480000 ms
15/01/21 18:51:20 INFO JobScheduler: Starting job streaming job 1421837480000 ms.0 from job set of time 1421837480000 ms
15/01/21 18:51:20 INFO JobScheduler: Finished job streaming job 1421837480000 ms.0 from job set of time 1421837480000 ms
15/01/21 18:51:20 INFO JobScheduler: Total delay: 0.006 s for time 1421837480000 ms (execution: 0.004 s)
15/01/21 18:51:20 INFO BlockRDD: Removing RDD 24 from persistence list
15/01/21 18:51:20 INFO BlockManager: Removing RDD 24
15/01/21 18:51:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[24] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837480000 ms
15/01/21 18:51:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837470000 ms)
15/01/21 18:51:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:20 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:22 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:24 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:25 INFO JobScheduler: Added jobs for time 1421837485000 ms
15/01/21 18:51:25 INFO JobScheduler: Starting job streaming job 1421837485000 ms.0 from job set of time 1421837485000 ms
15/01/21 18:51:25 INFO JobScheduler: Finished job streaming job 1421837485000 ms.0 from job set of time 1421837485000 ms
15/01/21 18:51:25 INFO JobScheduler: Total delay: 0.016 s for time 1421837485000 ms (execution: 0.015 s)
15/01/21 18:51:25 INFO BlockRDD: Removing RDD 25 from persistence list
15/01/21 18:51:25 INFO BlockManager: Removing RDD 25
15/01/21 18:51:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[25] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837485000 ms
15/01/21 18:51:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837475000 ms)
15/01/21 18:51:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:26 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:26 INFO BlockManagerInfo: Added input-0-1421837491400 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:26 INFO BlockManagerInfo: Added input-0-1421837491400 in memory on sh-demo-hadoop-05:59361 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:28 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:28 INFO BlockManagerInfo: Added input-0-1421837493400 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:28 INFO BlockManagerInfo: Added input-0-1421837493400 in memory on sh-demo-hadoop-05:59361 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:30 INFO JobScheduler: Added jobs for time 1421837490000 ms
15/01/21 18:51:30 INFO JobScheduler: Starting job streaming job 1421837490000 ms.0 from job set of time 1421837490000 ms
15/01/21 18:51:30 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:30 INFO DAGScheduler: Got job 8 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:30 INFO DAGScheduler: Final stage: Stage 9(runJob at PythonRDD.scala:344)
15/01/21 18:51:30 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:30 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:30 INFO DAGScheduler: Submitting Stage 9 (PythonRDD[28] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:30 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=91070, maxMem=278302556
15/01/21 18:51:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:30 INFO MemoryStore: ensureFreeSpace(2492) called with curMem=94390, maxMem=278302556
15/01/21 18:51:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:30 INFO BlockManagerMaster: Updated info of block broadcast_9_piece0
15/01/21 18:51:30 INFO SparkContext: Created broadcast 9 from getCallSite at DStream.scala:294
15/01/21 18:51:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 9 (PythonRDD[28] at RDD at PythonRDD.scala:43)
15/01/21 18:51:30 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
15/01/21 18:51:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 77, sh-demo-hadoop-05, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on sh-demo-hadoop-05:59361 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:30 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:30 INFO BlockManagerInfo: Added input-0-1421837495600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:30 INFO BlockManagerInfo: Added input-0-1421837495600 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:31 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 77) in 1540 ms on sh-demo-hadoop-05 (1/1)
15/01/21 18:51:31 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
15/01/21 18:51:31 INFO DAGScheduler: Stage 9 (runJob at PythonRDD.scala:344) finished in 1.539 s
15/01/21 18:51:31 INFO DAGScheduler: Job 8 finished: runJob at PythonRDD.scala:344, took 1.554829 s
15/01/21 18:51:31 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:31 INFO DAGScheduler: Got job 9 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:31 INFO DAGScheduler: Final stage: Stage 10(runJob at PythonRDD.scala:344)
15/01/21 18:51:31 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:31 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:31 INFO DAGScheduler: Submitting Stage 10 (PythonRDD[29] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:31 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=96882, maxMem=278302556
15/01/21 18:51:31 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:31 INFO MemoryStore: ensureFreeSpace(2492) called with curMem=100202, maxMem=278302556
15/01/21 18:51:31 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:31 INFO BlockManagerMaster: Updated info of block broadcast_10_piece0
15/01/21 18:51:31 INFO SparkContext: Created broadcast 10 from getCallSite at DStream.scala:294
15/01/21 18:51:31 INFO DAGScheduler: Submitting 1 missing tasks from Stage 10 (PythonRDD[29] at RDD at PythonRDD.scala:43)
15/01/21 18:51:31 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
15/01/21 18:51:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 78, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:31 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 78) in 94 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:31 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
15/01/21 18:51:31 INFO DAGScheduler: Stage 10 (runJob at PythonRDD.scala:344) finished in 0.095 s
15/01/21 18:51:31 INFO DAGScheduler: Job 9 finished: runJob at PythonRDD.scala:344, took 0.108053 s
15/01/21 18:51:31 INFO JobScheduler: Finished job streaming job 1421837490000 ms.0 from job set of time 1421837490000 ms
15/01/21 18:51:31 INFO JobScheduler: Total delay: 1.686 s for time 1421837490000 ms (execution: 1.685 s)
15/01/21 18:51:31 INFO BlockRDD: Removing RDD 26 from persistence list
15/01/21 18:51:31 INFO BlockManager: Removing RDD 26
15/01/21 18:51:31 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837490000 ms
15/01/21 18:51:31 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837480000 ms)
15/01/21 18:51:31 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:32 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:32 INFO BlockManagerInfo: Added input-0-1421837497600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:32 INFO BlockManagerInfo: Added input-0-1421837497600 in memory on sh-demo-hadoop-02:35432 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:34 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:35 INFO JobScheduler: Added jobs for time 1421837495000 ms
15/01/21 18:51:35 INFO JobScheduler: Starting job streaming job 1421837495000 ms.0 from job set of time 1421837495000 ms
15/01/21 18:51:35 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:35 INFO DAGScheduler: Got job 10 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:35 INFO DAGScheduler: Final stage: Stage 11(runJob at PythonRDD.scala:344)
15/01/21 18:51:35 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:35 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:35 INFO DAGScheduler: Submitting Stage 11 (PythonRDD[31] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:35 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=102694, maxMem=278302556
15/01/21 18:51:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:35 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=106014, maxMem=278302556
15/01/21 18:51:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:35 INFO BlockManagerMaster: Updated info of block broadcast_11_piece0
15/01/21 18:51:35 INFO SparkContext: Created broadcast 11 from getCallSite at DStream.scala:294
15/01/21 18:51:35 INFO DAGScheduler: Submitting 1 missing tasks from Stage 11 (PythonRDD[31] at RDD at PythonRDD.scala:43)
15/01/21 18:51:35 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
15/01/21 18:51:35 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 79, sh-demo-hadoop-03, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on sh-demo-hadoop-03:44092 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:35 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 79) in 849 ms on sh-demo-hadoop-03 (1/1)
15/01/21 18:51:35 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
15/01/21 18:51:35 INFO DAGScheduler: Stage 11 (runJob at PythonRDD.scala:344) finished in 0.852 s
15/01/21 18:51:35 INFO DAGScheduler: Job 10 finished: runJob at PythonRDD.scala:344, took 0.861637 s
15/01/21 18:51:35 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:35 INFO DAGScheduler: Got job 11 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:35 INFO DAGScheduler: Final stage: Stage 12(runJob at PythonRDD.scala:344)
15/01/21 18:51:35 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:35 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:35 INFO DAGScheduler: Submitting Stage 12 (PythonRDD[32] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:35 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=108505, maxMem=278302556
15/01/21 18:51:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:35 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=111825, maxMem=278302556
15/01/21 18:51:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:35 INFO BlockManagerMaster: Updated info of block broadcast_12_piece0
15/01/21 18:51:35 INFO SparkContext: Created broadcast 12 from getCallSite at DStream.scala:294
15/01/21 18:51:35 INFO DAGScheduler: Submitting 1 missing tasks from Stage 12 (PythonRDD[32] at RDD at PythonRDD.scala:43)
15/01/21 18:51:35 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
15/01/21 18:51:35 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 80, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:35 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 80) in 92 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:35 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
15/01/21 18:51:35 INFO DAGScheduler: Stage 12 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:51:35 INFO DAGScheduler: Job 11 finished: runJob at PythonRDD.scala:344, took 0.102132 s
15/01/21 18:51:35 INFO JobScheduler: Finished job streaming job 1421837495000 ms.0 from job set of time 1421837495000 ms
15/01/21 18:51:35 INFO JobScheduler: Total delay: 0.987 s for time 1421837495000 ms (execution: 0.986 s)
15/01/21 18:51:35 INFO BlockRDD: Removing RDD 27 from persistence list
15/01/21 18:51:35 INFO BlockManager: Removing RDD 27
15/01/21 18:51:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[27] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837495000 ms
15/01/21 18:51:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837485000 ms)
15/01/21 18:51:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:36 INFO BlockManagerInfo: Removed input-0-1421837491400 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:36 INFO BlockManagerInfo: Removed input-0-1421837491400 on sh-demo-hadoop-05:59361 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:36 INFO BlockManagerInfo: Removed input-0-1421837493400 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:36 INFO BlockManagerInfo: Removed input-0-1421837493400 on sh-demo-hadoop-05:59361 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:36 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:36 INFO BlockManagerInfo: Added input-0-1421837501600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:36 INFO BlockManagerInfo: Added input-0-1421837501600 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:38 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:38 INFO BlockManagerInfo: Added input-0-1421837503600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:38 INFO BlockManagerInfo: Added input-0-1421837503600 in memory on sh-demo-hadoop-04:38128 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:40 INFO JobScheduler: Added jobs for time 1421837500000 ms
15/01/21 18:51:40 INFO JobScheduler: Starting job streaming job 1421837500000 ms.0 from job set of time 1421837500000 ms
15/01/21 18:51:40 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:40 INFO DAGScheduler: Got job 12 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:40 INFO DAGScheduler: Final stage: Stage 13(runJob at PythonRDD.scala:344)
15/01/21 18:51:40 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:40 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:40 INFO DAGScheduler: Submitting Stage 13 (PythonRDD[34] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:40 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=114316, maxMem=278302556
15/01/21 18:51:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:40 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=117636, maxMem=278302556
15/01/21 18:51:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:40 INFO BlockManagerMaster: Updated info of block broadcast_13_piece0
15/01/21 18:51:40 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:838
15/01/21 18:51:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 13 (PythonRDD[34] at RDD at PythonRDD.scala:43)
15/01/21 18:51:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
15/01/21 18:51:40 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 81, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 81) in 93 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
15/01/21 18:51:40 INFO DAGScheduler: Stage 13 (runJob at PythonRDD.scala:344) finished in 0.096 s
15/01/21 18:51:40 INFO DAGScheduler: Job 12 finished: runJob at PythonRDD.scala:344, took 0.104946 s
15/01/21 18:51:40 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:40 INFO DAGScheduler: Got job 13 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:40 INFO DAGScheduler: Final stage: Stage 14(runJob at PythonRDD.scala:344)
15/01/21 18:51:40 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:40 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:40 INFO DAGScheduler: Submitting Stage 14 (PythonRDD[35] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:40 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=120127, maxMem=278302556
15/01/21 18:51:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:40 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=123447, maxMem=278302556
15/01/21 18:51:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:40 INFO BlockManagerMaster: Updated info of block broadcast_14_piece0
15/01/21 18:51:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:838
15/01/21 18:51:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 14 (PythonRDD[35] at RDD at PythonRDD.scala:43)
15/01/21 18:51:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
15/01/21 18:51:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 82, sh-demo-hadoop-04, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on sh-demo-hadoop-04:38128 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:40 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:40 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:40 INFO BlockManagerInfo: Added input-0-1421837505800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:40 INFO BlockManagerInfo: Added input-0-1421837505800 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 82) in 860 ms on sh-demo-hadoop-04 (1/1)
15/01/21 18:51:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
15/01/21 18:51:40 INFO DAGScheduler: Stage 14 (runJob at PythonRDD.scala:344) finished in 0.861 s
15/01/21 18:51:40 INFO DAGScheduler: Job 13 finished: runJob at PythonRDD.scala:344, took 0.870580 s
15/01/21 18:51:40 INFO JobScheduler: Finished job streaming job 1421837500000 ms.0 from job set of time 1421837500000 ms
15/01/21 18:51:40 INFO JobScheduler: Total delay: 0.999 s for time 1421837500000 ms (execution: 0.998 s)
15/01/21 18:51:41 INFO BlockRDD: Removing RDD 30 from persistence list
15/01/21 18:51:41 INFO BlockManager: Removing RDD 30
15/01/21 18:51:41 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[30] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837500000 ms
15/01/21 18:51:41 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837490000 ms)
15/01/21 18:51:41 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:41 INFO BlockManagerInfo: Removed input-0-1421837497600 on sh-demo-hadoop-02:35432 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:41 INFO BlockManagerInfo: Removed input-0-1421837495600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:41 INFO BlockManagerInfo: Removed input-0-1421837497600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:41 INFO BlockManagerInfo: Removed input-0-1421837495600 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:42 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:42 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:42 INFO BlockManagerInfo: Added input-0-1421837507800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:42 INFO BlockManagerInfo: Added input-0-1421837507800 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:44 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:44 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:44 INFO BlockManagerInfo: Added input-0-1421837509800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:44 INFO BlockManagerInfo: Added input-0-1421837509800 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:45 INFO JobScheduler: Added jobs for time 1421837505000 ms
15/01/21 18:51:45 INFO JobScheduler: Starting job streaming job 1421837505000 ms.0 from job set of time 1421837505000 ms
15/01/21 18:51:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:45 INFO DAGScheduler: Got job 14 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:45 INFO DAGScheduler: Final stage: Stage 15(runJob at PythonRDD.scala:344)
15/01/21 18:51:45 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:45 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:45 INFO DAGScheduler: Submitting Stage 15 (PythonRDD[37] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:45 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=125938, maxMem=278302556
15/01/21 18:51:45 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:45 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=129258, maxMem=278302556
15/01/21 18:51:45 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:45 INFO BlockManagerMaster: Updated info of block broadcast_15_piece0
15/01/21 18:51:45 INFO SparkContext: Created broadcast 15 from getCallSite at DStream.scala:294
15/01/21 18:51:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 15 (PythonRDD[37] at RDD at PythonRDD.scala:43)
15/01/21 18:51:45 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
15/01/21 18:51:45 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 83, sh-demo-hadoop-09, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on sh-demo-hadoop-09:54385 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:45 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 83) in 45 ms on sh-demo-hadoop-09 (1/1)
15/01/21 18:51:45 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
15/01/21 18:51:45 INFO DAGScheduler: Stage 15 (runJob at PythonRDD.scala:344) finished in 0.047 s
15/01/21 18:51:45 INFO DAGScheduler: Job 14 finished: runJob at PythonRDD.scala:344, took 0.057072 s
15/01/21 18:51:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:45 INFO DAGScheduler: Got job 15 (runJob at PythonRDD.scala:344) with 2 output partitions (allowLocal=true)
15/01/21 18:51:45 INFO DAGScheduler: Final stage: Stage 16(runJob at PythonRDD.scala:344)
15/01/21 18:51:45 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:45 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:45 INFO DAGScheduler: Submitting Stage 16 (PythonRDD[38] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:45 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=131749, maxMem=278302556
15/01/21 18:51:45 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:45 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=135069, maxMem=278302556
15/01/21 18:51:45 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:45 INFO BlockManagerMaster: Updated info of block broadcast_16_piece0
15/01/21 18:51:45 INFO SparkContext: Created broadcast 16 from getCallSite at DStream.scala:294
15/01/21 18:51:45 INFO DAGScheduler: Submitting 2 missing tasks from Stage 16 (PythonRDD[38] at RDD at PythonRDD.scala:43)
15/01/21 18:51:45 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
15/01/21 18:51:45 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 84, sh-demo-hadoop-06, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:45 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 85, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on sh-demo-hadoop-06:52083 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:45 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 85) in 93 ms on sh-demo-hadoop-10 (1/2)
15/01/21 18:51:45 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 84) in 847 ms on sh-demo-hadoop-06 (2/2)
15/01/21 18:51:45 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
15/01/21 18:51:45 INFO DAGScheduler: Stage 16 (runJob at PythonRDD.scala:344) finished in 0.849 s
15/01/21 18:51:45 INFO DAGScheduler: Job 15 finished: runJob at PythonRDD.scala:344, took 0.856789 s
15/01/21 18:51:45 INFO JobScheduler: Finished job streaming job 1421837505000 ms.0 from job set of time 1421837505000 ms
15/01/21 18:51:45 INFO BlockRDD: Removing RDD 33 from persistence list
15/01/21 18:51:45 INFO BlockManager: Removing RDD 33
15/01/21 18:51:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[33] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837505000 ms
15/01/21 18:51:45 INFO JobScheduler: Total delay: 0.952 s for time 1421837505000 ms (execution: 0.951 s)
15/01/21 18:51:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837495000 ms)
15/01/21 18:51:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:45 INFO BlockManagerInfo: Removed input-0-1421837501600 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Removed input-0-1421837501600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Removed input-0-1421837503600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Removed input-0-1421837503600 on sh-demo-hadoop-04:38128 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:46 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:46 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:46 INFO BlockManagerInfo: Added input-0-1421837511800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:46 INFO BlockManagerInfo: Added input-0-1421837511800 in memory on sh-demo-hadoop-02:35432 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:48 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:48 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:48 INFO BlockManagerInfo: Added input-0-1421837513800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:48 INFO BlockManagerInfo: Added input-0-1421837513800 in memory on sh-demo-hadoop-08:59231 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:50 INFO JobScheduler: Added jobs for time 1421837510000 ms
15/01/21 18:51:50 INFO JobScheduler: Starting job streaming job 1421837510000 ms.0 from job set of time 1421837510000 ms
15/01/21 18:51:50 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:50 INFO DAGScheduler: Got job 16 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:50 INFO DAGScheduler: Final stage: Stage 17(runJob at PythonRDD.scala:344)
15/01/21 18:51:50 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:50 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:50 INFO DAGScheduler: Submitting Stage 17 (PythonRDD[40] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:50 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=137560, maxMem=278302556
15/01/21 18:51:50 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:50 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=140880, maxMem=278302556
15/01/21 18:51:50 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:50 INFO BlockManagerMaster: Updated info of block broadcast_17_piece0
15/01/21 18:51:50 INFO SparkContext: Created broadcast 17 from getCallSite at DStream.scala:294
15/01/21 18:51:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 17 (PythonRDD[40] at RDD at PythonRDD.scala:43)
15/01/21 18:51:50 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
15/01/21 18:51:50 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 86, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:50 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 86) in 90 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:50 INFO DAGScheduler: Stage 17 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:51:50 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
15/01/21 18:51:50 INFO DAGScheduler: Job 16 finished: runJob at PythonRDD.scala:344, took 0.103444 s
15/01/21 18:51:50 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:50 INFO DAGScheduler: Got job 17 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:50 INFO DAGScheduler: Final stage: Stage 18(runJob at PythonRDD.scala:344)
15/01/21 18:51:50 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:50 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:50 INFO DAGScheduler: Submitting Stage 18 (PythonRDD[41] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:50 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=143371, maxMem=278302556
15/01/21 18:51:50 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:50 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=146691, maxMem=278302556
15/01/21 18:51:50 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:50 INFO BlockManagerMaster: Updated info of block broadcast_18_piece0
15/01/21 18:51:50 INFO SparkContext: Created broadcast 18 from getCallSite at DStream.scala:294
15/01/21 18:51:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 18 (PythonRDD[41] at RDD at PythonRDD.scala:43)
15/01/21 18:51:50 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
15/01/21 18:51:50 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 87, sh-demo-hadoop-08, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on sh-demo-hadoop-08:59231 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:50 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:50 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:50 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 87) in 774 ms on sh-demo-hadoop-08 (1/1)
15/01/21 18:51:50 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
15/01/21 18:51:50 INFO DAGScheduler: Stage 18 (runJob at PythonRDD.scala:344) finished in 0.775 s
15/01/21 18:51:50 INFO DAGScheduler: Job 17 finished: runJob at PythonRDD.scala:344, took 0.806167 s
15/01/21 18:51:50 INFO JobScheduler: Finished job streaming job 1421837510000 ms.0 from job set of time 1421837510000 ms
15/01/21 18:51:50 INFO JobScheduler: Total delay: 0.938 s for time 1421837510000 ms (execution: 0.936 s)
15/01/21 18:51:50 INFO BlockRDD: Removing RDD 36 from persistence list
15/01/21 18:51:50 INFO BlockManager: Removing RDD 36
15/01/21 18:51:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[36] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837510000 ms
15/01/21 18:51:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837500000 ms)
15/01/21 18:51:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837505800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837505800 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837507800 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837509800 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837507800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837509800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Added input-0-1421837516000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Added input-0-1421837516000 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:52 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:52 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:52 INFO BlockManagerInfo: Added input-0-1421837518000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:52 INFO BlockManagerInfo: Added input-0-1421837518000 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:54 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:54 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:54 INFO BlockManagerInfo: Added input-0-1421837520000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:54 INFO BlockManagerInfo: Added input-0-1421837520000 in memory on sh-demo-hadoop-04:38128 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:55 INFO JobScheduler: Added jobs for time 1421837515000 ms
15/01/21 18:51:55 INFO JobScheduler: Starting job streaming job 1421837515000 ms.0 from job set of time 1421837515000 ms
15/01/21 18:51:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:55 INFO DAGScheduler: Got job 18 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:55 INFO DAGScheduler: Final stage: Stage 19(runJob at PythonRDD.scala:344)
15/01/21 18:51:55 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:55 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:55 INFO DAGScheduler: Submitting Stage 19 (PythonRDD[43] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:55 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=149182, maxMem=278302556
15/01/21 18:51:55 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:55 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=152502, maxMem=278302556
15/01/21 18:51:55 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:51:55 INFO BlockManagerMaster: Updated info of block broadcast_19_piece0
15/01/21 18:51:55 INFO SparkContext: Created broadcast 19 from getCallSite at DStream.scala:294
15/01/21 18:51:55 INFO DAGScheduler: Submitting 1 missing tasks from Stage 19 (PythonRDD[43] at RDD at PythonRDD.scala:43)
15/01/21 18:51:55 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
15/01/21 18:51:55 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 88, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:55 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 88) in 90 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:55 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
15/01/21 18:51:55 INFO DAGScheduler: Stage 19 (runJob at PythonRDD.scala:344) finished in 0.093 s
15/01/21 18:51:55 INFO DAGScheduler: Job 18 finished: runJob at PythonRDD.scala:344, took 0.100860 s
15/01/21 18:51:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:55 INFO DAGScheduler: Got job 19 (runJob at PythonRDD.scala:344) with 2 output partitions (allowLocal=true)
15/01/21 18:51:55 INFO DAGScheduler: Final stage: Stage 20(runJob at PythonRDD.scala:344)
15/01/21 18:51:55 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:55 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:55 INFO DAGScheduler: Submitting Stage 20 (PythonRDD[44] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:55 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=154993, maxMem=278302556
15/01/21 18:51:55 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:55 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=158313, maxMem=278302556
15/01/21 18:51:55 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:51:55 INFO BlockManagerMaster: Updated info of block broadcast_20_piece0
15/01/21 18:51:55 INFO SparkContext: Created broadcast 20 from getCallSite at DStream.scala:294
15/01/21 18:51:55 INFO DAGScheduler: Submitting 2 missing tasks from Stage 20 (PythonRDD[44] at RDD at PythonRDD.scala:43)
15/01/21 18:51:55 INFO TaskSchedulerImpl: Adding task set 20.0 with 2 tasks
15/01/21 18:51:55 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 89, sh-demo-hadoop-09, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:55 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 90, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on sh-demo-hadoop-09:54385 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:55 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 89) in 77 ms on sh-demo-hadoop-09 (1/2)
15/01/21 18:51:55 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 90) in 89 ms on sh-demo-hadoop-10 (2/2)
15/01/21 18:51:55 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
15/01/21 18:51:55 INFO DAGScheduler: Stage 20 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:51:55 INFO DAGScheduler: Job 19 finished: runJob at PythonRDD.scala:344, took 0.100986 s
15/01/21 18:51:55 INFO JobScheduler: Finished job streaming job 1421837515000 ms.0 from job set of time 1421837515000 ms
15/01/21 18:51:55 INFO BlockRDD: Removing RDD 39 from persistence list
15/01/21 18:51:55 INFO JobScheduler: Total delay: 0.225 s for time 1421837515000 ms (execution: 0.224 s)
15/01/21 18:51:55 INFO BlockManager: Removing RDD 39
15/01/21 18:51:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[39] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837515000 ms
15/01/21 18:51:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837505000 ms)
15/01/21 18:51:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:55 INFO BlockManagerInfo: Removed input-0-1421837511800 on sh-demo-hadoop-02:35432 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Removed input-0-1421837511800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Removed input-0-1421837513800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Removed input-0-1421837513800 on sh-demo-hadoop-08:59231 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:56 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:56 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:56 INFO BlockManagerInfo: Added input-0-1421837522000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:56 INFO BlockManagerInfo: Added input-0-1421837522000 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:58 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:58 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:59 INFO BlockManagerInfo: Added input-0-1421837524200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:59 INFO BlockManagerInfo: Added input-0-1421837524200 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:00 INFO JobScheduler: Added jobs for time 1421837520000 ms
15/01/21 18:52:00 INFO JobScheduler: Starting job streaming job 1421837520000 ms.0 from job set of time 1421837520000 ms
15/01/21 18:52:00 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:00 INFO DAGScheduler: Got job 20 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:00 INFO DAGScheduler: Final stage: Stage 21(runJob at PythonRDD.scala:344)
15/01/21 18:52:00 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:00 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:00 INFO DAGScheduler: Submitting Stage 21 (PythonRDD[46] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:00 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=160804, maxMem=278302556
15/01/21 18:52:00 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:52:00 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=164124, maxMem=278302556
15/01/21 18:52:00 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:00 INFO BlockManagerMaster: Updated info of block broadcast_21_piece0
15/01/21 18:52:00 INFO SparkContext: Created broadcast 21 from getCallSite at DStream.scala:294
15/01/21 18:52:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 21 (PythonRDD[46] at RDD at PythonRDD.scala:43)
15/01/21 18:52:00 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
15/01/21 18:52:00 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 91, sh-demo-hadoop-07, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:00 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on sh-demo-hadoop-07:57986 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:52:00 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 91) in 186 ms on sh-demo-hadoop-07 (1/1)
15/01/21 18:52:00 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
15/01/21 18:52:00 INFO DAGScheduler: Stage 21 (runJob at PythonRDD.scala:344) finished in 0.189 s
15/01/21 18:52:00 INFO DAGScheduler: Job 20 finished: runJob at PythonRDD.scala:344, took 0.196594 s
15/01/21 18:52:00 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:00 INFO DAGScheduler: Got job 21 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:00 INFO DAGScheduler: Final stage: Stage 22(runJob at PythonRDD.scala:344)
15/01/21 18:52:00 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:00 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:00 INFO DAGScheduler: Submitting Stage 22 (PythonRDD[47] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:00 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=166615, maxMem=278302556
15/01/21 18:52:00 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:00 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=169935, maxMem=278302556
15/01/21 18:52:00 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:00 INFO BlockManagerMaster: Updated info of block broadcast_22_piece0
15/01/21 18:52:00 INFO SparkContext: Created broadcast 22 from getCallSite at DStream.scala:294
15/01/21 18:52:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 22 (PythonRDD[47] at RDD at PythonRDD.scala:43)
15/01/21 18:52:00 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
15/01/21 18:52:00 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 92, sh-demo-hadoop-09, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:00 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on sh-demo-hadoop-09:54385 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:52:00 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 92) in 75 ms on sh-demo-hadoop-09 (1/1)
15/01/21 18:52:00 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
15/01/21 18:52:00 INFO DAGScheduler: Stage 22 (runJob at PythonRDD.scala:344) finished in 0.076 s
15/01/21 18:52:00 INFO DAGScheduler: Job 21 finished: runJob at PythonRDD.scala:344, took 0.083436 s
15/01/21 18:52:00 INFO JobScheduler: Finished job streaming job 1421837520000 ms.0 from job set of time 1421837520000 ms
15/01/21 18:52:00 INFO BlockRDD: Removing RDD 42 from persistence list
15/01/21 18:52:00 INFO BlockManager: Removing RDD 42
15/01/21 18:52:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[42] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837520000 ms
15/01/21 18:52:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837510000 ms)
15/01/21 18:52:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:00 INFO JobScheduler: Total delay: 0.305 s for time 1421837520000 ms (execution: 0.304 s)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837518000 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837516000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837520000 on sh-demo-hadoop-04:38128 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837518000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837520000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837516000 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:00 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:01 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:01 INFO BlockManagerInfo: Added input-0-1421837526200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:01 INFO BlockManagerInfo: Added input-0-1421837526200 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:03 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:03 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:03 INFO BlockManagerInfo: Added input-0-1421837528200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:03 INFO BlockManagerInfo: Added input-0-1421837528200 in memory on sh-demo-hadoop-04:38128 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:05 INFO JobScheduler: Added jobs for time 1421837525000 ms
15/01/21 18:52:05 INFO JobScheduler: Starting job streaming job 1421837525000 ms.0 from job set of time 1421837525000 ms
15/01/21 18:52:05 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:05 INFO DAGScheduler: Got job 22 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:05 INFO DAGScheduler: Final stage: Stage 23(runJob at PythonRDD.scala:344)
15/01/21 18:52:05 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:05 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:05 INFO DAGScheduler: Submitting Stage 23 (PythonRDD[49] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:05 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=172426, maxMem=278302556
15/01/21 18:52:05 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:05 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=175746, maxMem=278302556
15/01/21 18:52:05 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:05 INFO BlockManagerMaster: Updated info of block broadcast_23_piece0
15/01/21 18:52:05 INFO SparkContext: Created broadcast 23 from getCallSite at DStream.scala:294
15/01/21 18:52:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 23 (PythonRDD[49] at RDD at PythonRDD.scala:43)
15/01/21 18:52:05 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
15/01/21 18:52:05 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 93, sh-demo-hadoop-07, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:05 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:05 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on sh-demo-hadoop-07:57986 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:52:05 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:05 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 93) in 136 ms on sh-demo-hadoop-07 (1/1)
15/01/21 18:52:05 INFO DAGScheduler: Stage 23 (runJob at PythonRDD.scala:344) finished in 0.137 s
15/01/21 18:52:05 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
15/01/21 18:52:05 INFO DAGScheduler: Job 22 finished: runJob at PythonRDD.scala:344, took 0.145818 s
15/01/21 18:52:05 INFO BlockManagerInfo: Added input-0-1421837530200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:05 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:05 INFO DAGScheduler: Got job 23 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:05 INFO DAGScheduler: Final stage: Stage 24(runJob at PythonRDD.scala:344)
15/01/21 18:52:05 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:05 INFO BlockManagerInfo: Added input-0-1421837530200 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:05 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:05 INFO DAGScheduler: Submitting Stage 24 (PythonRDD[50] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:05 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=178237, maxMem=278302556
15/01/21 18:52:05 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:05 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=181557, maxMem=278302556
15/01/21 18:52:05 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:05 INFO BlockManagerMaster: Updated info of block broadcast_24_piece0
15/01/21 18:52:05 INFO SparkContext: Created broadcast 24 from getCallSite at DStream.scala:294
15/01/21 18:52:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 24 (PythonRDD[50] at RDD at PythonRDD.scala:43)
15/01/21 18:52:05 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
15/01/21 18:52:05 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 94, sh-demo-hadoop-04, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on sh-demo-hadoop-04:38128 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:52:05 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 94) in 93 ms on sh-demo-hadoop-04 (1/1)
15/01/21 18:52:05 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
15/01/21 18:52:05 INFO DAGScheduler: Stage 24 (runJob at PythonRDD.scala:344) finished in 0.090 s
15/01/21 18:52:05 INFO DAGScheduler: Job 23 finished: runJob at PythonRDD.scala:344, took 0.102708 s
15/01/21 18:52:05 INFO JobScheduler: Finished job streaming job 1421837525000 ms.0 from job set of time 1421837525000 ms
15/01/21 18:52:05 INFO BlockRDD: Removing RDD 45 from persistence list
15/01/21 18:52:05 INFO JobScheduler: Total delay: 0.276 s for time 1421837525000 ms (execution: 0.275 s)
15/01/21 18:52:05 INFO BlockManager: Removing RDD 45
15/01/21 18:52:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[45] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837525000 ms
15/01/21 18:52:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837515000 ms)
15/01/21 18:52:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:05 INFO BlockManagerInfo: Removed input-0-1421837522000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Removed input-0-1421837524200 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Removed input-0-1421837524200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Removed input-0-1421837522000 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:07 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:07 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:09 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:09 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:10 INFO JobScheduler: Added jobs for time 1421837530000 ms
15/01/21 18:52:10 INFO JobScheduler: Starting job streaming job 1421837530000 ms.0 from job set of time 1421837530000 ms
15/01/21 18:52:10 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:10 INFO DAGScheduler: Got job 24 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:10 INFO DAGScheduler: Final stage: Stage 25(runJob at PythonRDD.scala:344)
15/01/21 18:52:10 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:10 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:10 INFO DAGScheduler: Submitting Stage 25 (PythonRDD[52] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:10 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=184048, maxMem=278302556
15/01/21 18:52:10 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:10 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=187368, maxMem=278302556
15/01/21 18:52:10 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:10 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:10 INFO BlockManagerMaster: Updated info of block broadcast_25_piece0
15/01/21 18:52:10 INFO SparkContext: Created broadcast 25 from getCallSite at DStream.scala:294
15/01/21 18:52:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 25 (PythonRDD[52] at RDD at PythonRDD.scala:43)
15/01/21 18:52:10 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
15/01/21 18:52:10 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 95, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:10 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:52:10 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 95) in 90 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:52:10 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
15/01/21 18:52:10 INFO DAGScheduler: Stage 25 (runJob at PythonRDD.scala:344) finished in 0.093 s
15/01/21 18:52:10 INFO DAGScheduler: Job 24 finished: runJob at PythonRDD.scala:344, took 0.101093 s
15/01/21 18:52:10 INFO JobScheduler: Finished job streaming job 1421837530000 ms.0 from job set of time 1421837530000 ms
15/01/21 18:52:10 INFO JobScheduler: Total delay: 0.128 s for time 1421837530000 ms (execution: 0.127 s)
15/01/21 18:52:10 INFO BlockRDD: Removing RDD 48 from persistence list
15/01/21 18:52:10 INFO BlockManager: Removing RDD 48
15/01/21 18:52:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[48] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837530000 ms
15/01/21 18:52:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837520000 ms)
15/01/21 18:52:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:10 INFO BlockManagerInfo: Removed input-0-1421837526200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:10 INFO BlockManagerInfo: Removed input-0-1421837528200 on sh-demo-hadoop-04:38128 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:10 INFO BlockManagerInfo: Removed input-0-1421837528200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:10 INFO BlockManagerInfo: Removed input-0-1421837526200 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:11 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:11 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:13 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:15 INFO JobScheduler: Added jobs for time 1421837535000 ms
15/01/21 18:52:15 INFO JobScheduler: Starting job streaming job 1421837535000 ms.0 from job set of time 1421837535000 ms
15/01/21 18:52:15 INFO JobScheduler: Finished job streaming job 1421837535000 ms.0 from job set of time 1421837535000 ms
15/01/21 18:52:15 INFO JobScheduler: Total delay: 0.004 s for time 1421837535000 ms (execution: 0.003 s)
15/01/21 18:52:15 INFO BlockRDD: Removing RDD 51 from persistence list
15/01/21 18:52:15 INFO BlockManager: Removing RDD 51
15/01/21 18:52:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[51] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837535000 ms
15/01/21 18:52:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837525000 ms)
15/01/21 18:52:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:15 INFO BlockManagerInfo: Removed input-0-1421837530200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:15 INFO BlockManagerInfo: Removed input-0-1421837530200 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:15 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:17 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:19 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:20 INFO JobScheduler: Added jobs for time 1421837540000 ms
15/01/21 18:52:20 INFO JobScheduler: Starting job streaming job 1421837540000 ms.0 from job set of time 1421837540000 ms
15/01/21 18:52:20 INFO JobScheduler: Finished job streaming job 1421837540000 ms.0 from job set of time 1421837540000 ms
15/01/21 18:52:20 INFO JobScheduler: Total delay: 0.004 s for time 1421837540000 ms (execution: 0.003 s)
15/01/21 18:52:20 INFO BlockRDD: Removing RDD 53 from persistence list
15/01/21 18:52:20 INFO BlockManager: Removing RDD 53
15/01/21 18:52:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[53] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837540000 ms
15/01/21 18:52:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837530000 ms)
15/01/21 18:52:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:21 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:23 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:25 INFO JobScheduler: Added jobs for time 1421837545000 ms
15/01/21 18:52:25 INFO JobScheduler: Starting job streaming job 1421837545000 ms.0 from job set of time 1421837545000 ms
15/01/21 18:52:25 INFO JobScheduler: Finished job streaming job 1421837545000 ms.0 from job set of time 1421837545000 ms
15/01/21 18:52:25 INFO JobScheduler: Total delay: 0.003 s for time 1421837545000 ms (execution: 0.003 s)
15/01/21 18:52:25 INFO BlockRDD: Removing RDD 54 from persistence list
15/01/21 18:52:25 INFO BlockManager: Removing RDD 54
15/01/21 18:52:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[54] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837545000 ms
15/01/21 18:52:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837535000 ms)
15/01/21 18:52:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:25 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:27 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:29 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:30 INFO JobScheduler: Added jobs for time 1421837550000 ms
15/01/21 18:52:30 INFO JobScheduler: Starting job streaming job 1421837550000 ms.0 from job set of time 1421837550000 ms
15/01/21 18:52:30 INFO JobScheduler: Finished job streaming job 1421837550000 ms.0 from job set of time 1421837550000 ms
15/01/21 18:52:30 INFO JobScheduler: Total delay: 0.003 s for time 1421837550000 ms (execution: 0.002 s)
15/01/21 18:52:30 INFO BlockRDD: Removing RDD 55 from persistence list
15/01/21 18:52:30 INFO BlockManager: Removing RDD 55
15/01/21 18:52:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[55] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837550000 ms
15/01/21 18:52:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837540000 ms)
15/01/21 18:52:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:31 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:33 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:35 INFO JobScheduler: Added jobs for time 1421837555000 ms
15/01/21 18:52:35 INFO JobScheduler: Starting job streaming job 1421837555000 ms.0 from job set of time 1421837555000 ms
15/01/21 18:52:35 INFO JobScheduler: Finished job streaming job 1421837555000 ms.0 from job set of time 1421837555000 ms
15/01/21 18:52:35 INFO JobScheduler: Total delay: 0.004 s for time 1421837555000 ms (execution: 0.003 s)
15/01/21 18:52:35 INFO BlockRDD: Removing RDD 56 from persistence list
15/01/21 18:52:35 INFO BlockManager: Removing RDD 56
15/01/21 18:52:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[56] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837555000 ms
15/01/21 18:52:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837545000 ms)
15/01/21 18:52:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:35 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:37 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:39 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:40 INFO JobScheduler: Added jobs for time 1421837560000 ms
15/01/21 18:52:40 INFO JobScheduler: Starting job streaming job 1421837560000 ms.0 from job set of time 1421837560000 ms
15/01/21 18:52:40 INFO JobScheduler: Finished job streaming job 1421837560000 ms.0 from job set of time 1421837560000 ms
15/01/21 18:52:40 INFO JobScheduler: Total delay: 0.003 s for time 1421837560000 ms (execution: 0.003 s)
15/01/21 18:52:40 INFO BlockRDD: Removing RDD 57 from persistence list
15/01/21 18:52:40 INFO BlockManager: Removing RDD 57
15/01/21 18:52:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[57] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837560000 ms
15/01/21 18:52:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837550000 ms)
15/01/21 18:52:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:41 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:41 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:43 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:43 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:45 INFO JobScheduler: Added jobs for time 1421837565000 ms
15/01/21 18:52:45 INFO JobScheduler: Starting job streaming job 1421837565000 ms.0 from job set of time 1421837565000 ms
15/01/21 18:52:45 INFO JobScheduler: Finished job streaming job 1421837565000 ms.0 from job set of time 1421837565000 ms
15/01/21 18:52:45 INFO JobScheduler: Total delay: 0.004 s for time 1421837565000 ms (execution: 0.003 s)
15/01/21 18:52:45 INFO BlockRDD: Removing RDD 58 from persistence list
15/01/21 18:52:45 INFO BlockManager: Removing RDD 58
15/01/21 18:52:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[58] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837565000 ms
15/01/21 18:52:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837555000 ms)
15/01/21 18:52:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:45 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:45 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:47 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:47 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:49 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:49 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:50 INFO JobScheduler: Added jobs for time 1421837570000 ms
15/01/21 18:52:50 INFO JobScheduler: Starting job streaming job 1421837570000 ms.0 from job set of time 1421837570000 ms
15/01/21 18:52:50 INFO JobScheduler: Finished job streaming job 1421837570000 ms.0 from job set of time 1421837570000 ms
15/01/21 18:52:50 INFO JobScheduler: Total delay: 0.004 s for time 1421837570000 ms (execution: 0.003 s)
15/01/21 18:52:50 INFO BlockRDD: Removing RDD 59 from persistence list
15/01/21 18:52:50 INFO BlockManager: Removing RDD 59
15/01/21 18:52:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[59] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837570000 ms
15/01/21 18:52:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837560000 ms)
15/01/21 18:52:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:51 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:51 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:53 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:53 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:53 INFO BlockManagerInfo: Added input-0-1421837578600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:53 INFO BlockManagerInfo: Added input-0-1421837578600 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:55 INFO JobScheduler: Added jobs for time 1421837575000 ms
15/01/21 18:52:55 INFO JobScheduler: Starting job streaming job 1421837575000 ms.0 from job set of time 1421837575000 ms
15/01/21 18:52:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:55 INFO DAGScheduler: Got job 25 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:55 INFO DAGScheduler: Final stage: Stage 26(runJob at PythonRDD.scala:344)
15/01/21 18:52:55 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:55 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:55 INFO DAGScheduler: Submitting Stage 26 (PythonRDD[62] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:55 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=189859, maxMem=278302556
15/01/21 18:52:55 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:55 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=193179, maxMem=278302556
15/01/21 18:52:55 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:55 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:55 INFO BlockManagerMaster: Updated info of block broadcast_26_piece0
15/01/21 18:52:55 INFO SparkContext: Created broadcast 26 from getCallSite at DStream.scala:294
15/01/21 18:52:55 INFO DAGScheduler: Submitting 1 missing tasks from Stage 26 (PythonRDD[62] at RDD at PythonRDD.scala:43)
15/01/21 18:52:55 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
15/01/21 18:52:55 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 96, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:55 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:52:55 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 96) in 90 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:52:55 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
15/01/21 18:52:55 INFO DAGScheduler: Stage 26 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:52:55 INFO DAGScheduler: Job 25 finished: runJob at PythonRDD.scala:344, took 0.099414 s
15/01/21 18:52:55 INFO JobScheduler: Finished job streaming job 1421837575000 ms.0 from job set of time 1421837575000 ms
15/01/21 18:52:55 INFO JobScheduler: Total delay: 0.113 s for time 1421837575000 ms (execution: 0.112 s)
15/01/21 18:52:55 INFO BlockRDD: Removing RDD 60 from persistence list
15/01/21 18:52:55 INFO BlockManager: Removing RDD 60
15/01/21 18:52:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[60] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837575000 ms
15/01/21 18:52:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837565000 ms)
15/01/21 18:52:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:55 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:55 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:57 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:57 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:59 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:59 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:00 INFO JobScheduler: Added jobs for time 1421837580000 ms
15/01/21 18:53:00 INFO JobScheduler: Starting job streaming job 1421837580000 ms.0 from job set of time 1421837580000 ms
15/01/21 18:53:00 INFO JobScheduler: Finished job streaming job 1421837580000 ms.0 from job set of time 1421837580000 ms
15/01/21 18:53:00 INFO JobScheduler: Total delay: 0.005 s for time 1421837580000 ms (execution: 0.004 s)
15/01/21 18:53:00 INFO BlockRDD: Removing RDD 61 from persistence list
15/01/21 18:53:00 INFO BlockManager: Removing RDD 61
15/01/21 18:53:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[61] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837580000 ms
15/01/21 18:53:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837570000 ms)
15/01/21 18:53:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:00 INFO BlockManagerInfo: Removed input-0-1421837578600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:00 INFO BlockManagerInfo: Removed input-0-1421837578600 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:01 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:01 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:03 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:03 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:05 INFO JobScheduler: Added jobs for time 1421837585000 ms
15/01/21 18:53:05 INFO JobScheduler: Starting job streaming job 1421837585000 ms.0 from job set of time 1421837585000 ms
15/01/21 18:53:05 INFO JobScheduler: Finished job streaming job 1421837585000 ms.0 from job set of time 1421837585000 ms
15/01/21 18:53:05 INFO JobScheduler: Total delay: 0.004 s for time 1421837585000 ms (execution: 0.003 s)
15/01/21 18:53:05 INFO BlockRDD: Removing RDD 63 from persistence list
15/01/21 18:53:05 INFO BlockManager: Removing RDD 63
15/01/21 18:53:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[63] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837585000 ms
15/01/21 18:53:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837575000 ms)
15/01/21 18:53:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:05 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:05 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:07 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:07 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:09 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:09 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:09 INFO BlockManagerInfo: Added input-0-1421837594800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:09 INFO BlockManagerInfo: Added input-0-1421837594800 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:10 INFO JobScheduler: Added jobs for time 1421837590000 ms
15/01/21 18:53:10 INFO JobScheduler: Starting job streaming job 1421837590000 ms.0 from job set of time 1421837590000 ms
15/01/21 18:53:10 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:10 INFO DAGScheduler: Got job 26 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:10 INFO DAGScheduler: Final stage: Stage 27(runJob at PythonRDD.scala:344)
15/01/21 18:53:10 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:10 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:10 INFO DAGScheduler: Submitting Stage 27 (PythonRDD[66] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:10 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=195670, maxMem=278302556
15/01/21 18:53:10 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:10 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=198990, maxMem=278302556
15/01/21 18:53:10 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:10 INFO BlockManagerMaster: Updated info of block broadcast_27_piece0
15/01/21 18:53:10 INFO SparkContext: Created broadcast 27 from getCallSite at DStream.scala:294
15/01/21 18:53:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 27 (PythonRDD[66] at RDD at PythonRDD.scala:43)
15/01/21 18:53:10 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
15/01/21 18:53:10 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 97, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:53:10 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 97) in 88 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:53:10 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
15/01/21 18:53:10 INFO DAGScheduler: Stage 27 (runJob at PythonRDD.scala:344) finished in 0.090 s
15/01/21 18:53:10 INFO DAGScheduler: Job 26 finished: runJob at PythonRDD.scala:344, took 0.097075 s
15/01/21 18:53:10 INFO JobScheduler: Finished job streaming job 1421837590000 ms.0 from job set of time 1421837590000 ms
15/01/21 18:53:10 INFO JobScheduler: Total delay: 0.109 s for time 1421837590000 ms (execution: 0.108 s)
15/01/21 18:53:10 INFO BlockRDD: Removing RDD 64 from persistence list
15/01/21 18:53:10 INFO BlockManager: Removing RDD 64
15/01/21 18:53:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[64] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837590000 ms
15/01/21 18:53:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837580000 ms)
15/01/21 18:53:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:11 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:11 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:11 INFO BlockManagerInfo: Added input-0-1421837596800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:11 INFO BlockManagerInfo: Added input-0-1421837596800 in memory on sh-demo-hadoop-04:38128 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:13 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:15 INFO JobScheduler: Added jobs for time 1421837595000 ms
15/01/21 18:53:15 INFO JobScheduler: Starting job streaming job 1421837595000 ms.0 from job set of time 1421837595000 ms
15/01/21 18:53:15 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:15 INFO DAGScheduler: Got job 27 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:15 INFO DAGScheduler: Final stage: Stage 28(runJob at PythonRDD.scala:344)
15/01/21 18:53:15 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:15 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:15 INFO DAGScheduler: Submitting Stage 28 (PythonRDD[68] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:15 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=201481, maxMem=278302556
15/01/21 18:53:15 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:15 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=204801, maxMem=278302556
15/01/21 18:53:15 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:15 INFO BlockManagerMaster: Updated info of block broadcast_28_piece0
15/01/21 18:53:15 INFO SparkContext: Created broadcast 28 from getCallSite at DStream.scala:294
15/01/21 18:53:15 INFO DAGScheduler: Submitting 1 missing tasks from Stage 28 (PythonRDD[68] at RDD at PythonRDD.scala:43)
15/01/21 18:53:15 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
15/01/21 18:53:15 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 98, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:53:15 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 98) in 91 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:53:15 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
15/01/21 18:53:15 INFO DAGScheduler: Stage 28 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:53:15 INFO DAGScheduler: Job 27 finished: runJob at PythonRDD.scala:344, took 0.101362 s
15/01/21 18:53:15 INFO JobScheduler: Finished job streaming job 1421837595000 ms.0 from job set of time 1421837595000 ms
15/01/21 18:53:15 INFO JobScheduler: Total delay: 0.125 s for time 1421837595000 ms (execution: 0.124 s)
15/01/21 18:53:15 INFO BlockRDD: Removing RDD 65 from persistence list
15/01/21 18:53:15 INFO BlockManager: Removing RDD 65
15/01/21 18:53:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[65] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837595000 ms
15/01/21 18:53:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837585000 ms)
15/01/21 18:53:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:15 INFO BlockManagerInfo: Removed input-0-1421837594800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:15 INFO BlockManagerInfo: Removed input-0-1421837594800 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:15 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:17 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:19 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:20 INFO JobScheduler: Added jobs for time 1421837600000 ms
15/01/21 18:53:20 INFO JobScheduler: Starting job streaming job 1421837600000 ms.0 from job set of time 1421837600000 ms
15/01/21 18:53:20 INFO JobScheduler: Finished job streaming job 1421837600000 ms.0 from job set of time 1421837600000 ms
15/01/21 18:53:20 INFO BlockRDD: Removing RDD 67 from persistence list
15/01/21 18:53:20 INFO JobScheduler: Total delay: 0.004 s for time 1421837600000 ms (execution: 0.003 s)
15/01/21 18:53:20 INFO BlockManager: Removing RDD 67
15/01/21 18:53:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[67] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837600000 ms
15/01/21 18:53:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837590000 ms)
15/01/21 18:53:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:20 INFO BlockManagerInfo: Removed input-0-1421837596800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:20 INFO BlockManagerInfo: Removed input-0-1421837596800 on sh-demo-hadoop-04:38128 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:21 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:23 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:25 INFO JobScheduler: Added jobs for time 1421837605000 ms
15/01/21 18:53:25 INFO JobScheduler: Starting job streaming job 1421837605000 ms.0 from job set of time 1421837605000 ms
15/01/21 18:53:25 INFO JobScheduler: Finished job streaming job 1421837605000 ms.0 from job set of time 1421837605000 ms
15/01/21 18:53:25 INFO JobScheduler: Total delay: 0.003 s for time 1421837605000 ms (execution: 0.003 s)
15/01/21 18:53:25 INFO BlockRDD: Removing RDD 69 from persistence list
15/01/21 18:53:25 INFO BlockManager: Removing RDD 69
15/01/21 18:53:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[69] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837605000 ms
15/01/21 18:53:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837595000 ms)
15/01/21 18:53:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:25 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:27 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:27 INFO BlockManagerInfo: Added input-0-1421837613000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:27 INFO BlockManagerInfo: Added input-0-1421837613000 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:29 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:30 INFO JobScheduler: Added jobs for time 1421837610000 ms
15/01/21 18:53:30 INFO JobScheduler: Starting job streaming job 1421837610000 ms.0 from job set of time 1421837610000 ms
15/01/21 18:53:30 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:30 INFO DAGScheduler: Got job 28 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:30 INFO DAGScheduler: Final stage: Stage 29(runJob at PythonRDD.scala:344)
15/01/21 18:53:30 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:30 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:30 INFO DAGScheduler: Submitting Stage 29 (PythonRDD[72] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:30 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=207292, maxMem=278302556
15/01/21 18:53:30 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:30 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=210612, maxMem=278302556
15/01/21 18:53:30 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:30 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:30 INFO BlockManagerMaster: Updated info of block broadcast_29_piece0
15/01/21 18:53:30 INFO SparkContext: Created broadcast 29 from getCallSite at DStream.scala:294
15/01/21 18:53:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 29 (PythonRDD[72] at RDD at PythonRDD.scala:43)
15/01/21 18:53:30 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
15/01/21 18:53:30 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 99, sh-demo-hadoop-06, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:30 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on sh-demo-hadoop-06:52083 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:53:30 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 99) in 63 ms on sh-demo-hadoop-06 (1/1)
15/01/21 18:53:30 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
15/01/21 18:53:30 INFO DAGScheduler: Stage 29 (runJob at PythonRDD.scala:344) finished in 0.065 s
15/01/21 18:53:30 INFO DAGScheduler: Job 28 finished: runJob at PythonRDD.scala:344, took 0.072853 s
15/01/21 18:53:30 INFO JobScheduler: Finished job streaming job 1421837610000 ms.0 from job set of time 1421837610000 ms
15/01/21 18:53:30 INFO JobScheduler: Total delay: 0.087 s for time 1421837610000 ms (execution: 0.086 s)
15/01/21 18:53:30 INFO BlockRDD: Removing RDD 70 from persistence list
15/01/21 18:53:30 INFO BlockManager: Removing RDD 70
15/01/21 18:53:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[70] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837610000 ms
15/01/21 18:53:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837600000 ms)
15/01/21 18:53:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:31 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:33 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:35 INFO JobScheduler: Added jobs for time 1421837615000 ms
15/01/21 18:53:35 INFO JobScheduler: Starting job streaming job 1421837615000 ms.0 from job set of time 1421837615000 ms
15/01/21 18:53:35 INFO JobScheduler: Finished job streaming job 1421837615000 ms.0 from job set of time 1421837615000 ms
15/01/21 18:53:35 INFO JobScheduler: Total delay: 0.005 s for time 1421837615000 ms (execution: 0.004 s)
15/01/21 18:53:35 INFO BlockRDD: Removing RDD 71 from persistence list
15/01/21 18:53:35 INFO BlockManager: Removing RDD 71
15/01/21 18:53:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[71] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837615000 ms
15/01/21 18:53:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837605000 ms)
15/01/21 18:53:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:35 INFO BlockManagerInfo: Removed input-0-1421837613000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:35 INFO BlockManagerInfo: Removed input-0-1421837613000 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:35 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:37 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:39 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:40 INFO JobScheduler: Added jobs for time 1421837620000 ms
15/01/21 18:53:40 INFO JobScheduler: Starting job streaming job 1421837620000 ms.0 from job set of time 1421837620000 ms
15/01/21 18:53:40 INFO JobScheduler: Finished job streaming job 1421837620000 ms.0 from job set of time 1421837620000 ms
15/01/21 18:53:40 INFO JobScheduler: Total delay: 0.003 s for time 1421837620000 ms (execution: 0.002 s)
15/01/21 18:53:40 INFO BlockRDD: Removing RDD 73 from persistence list
15/01/21 18:53:40 INFO BlockManager: Removing RDD 73
15/01/21 18:53:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[73] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837620000 ms
15/01/21 18:53:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837610000 ms)
15/01/21 18:53:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:40 INFO BlockManagerInfo: Added input-0-1421837625200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:40 INFO BlockManagerInfo: Added input-0-1421837625200 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:41 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:42 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:42 INFO BlockManagerInfo: Added input-0-1421837627200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:42 INFO BlockManagerInfo: Added input-0-1421837627200 in memory on sh-demo-hadoop-02:35432 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:44 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:44 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:45 INFO JobScheduler: Added jobs for time 1421837625000 ms
15/01/21 18:53:45 INFO JobScheduler: Starting job streaming job 1421837625000 ms.0 from job set of time 1421837625000 ms
15/01/21 18:53:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:45 INFO DAGScheduler: Got job 29 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:45 INFO DAGScheduler: Final stage: Stage 30(runJob at PythonRDD.scala:344)
15/01/21 18:53:45 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:45 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:45 INFO DAGScheduler: Submitting Stage 30 (PythonRDD[76] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:45 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=213103, maxMem=278302556
15/01/21 18:53:45 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:45 INFO MemoryStore: ensureFreeSpace(2493) called with curMem=216423, maxMem=278302556
15/01/21 18:53:45 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:45 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:45 INFO BlockManagerMaster: Updated info of block broadcast_30_piece0
15/01/21 18:53:45 INFO SparkContext: Created broadcast 30 from getCallSite at DStream.scala:294
15/01/21 18:53:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 30 (PythonRDD[76] at RDD at PythonRDD.scala:43)
15/01/21 18:53:45 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
15/01/21 18:53:45 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 100, sh-demo-hadoop-07, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:45 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on sh-demo-hadoop-07:57986 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:53:45 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 100) in 68 ms on sh-demo-hadoop-07 (1/1)
15/01/21 18:53:45 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
15/01/21 18:53:45 INFO DAGScheduler: Stage 30 (runJob at PythonRDD.scala:344) finished in 0.069 s
15/01/21 18:53:45 INFO DAGScheduler: Job 29 finished: runJob at PythonRDD.scala:344, took 0.077359 s
15/01/21 18:53:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:45 INFO DAGScheduler: Got job 30 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:45 INFO DAGScheduler: Final stage: Stage 31(runJob at PythonRDD.scala:344)
15/01/21 18:53:45 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:45 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:45 INFO DAGScheduler: Submitting Stage 31 (PythonRDD[77] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:45 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=218916, maxMem=278302556
15/01/21 18:53:45 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:45 INFO MemoryStore: ensureFreeSpace(2493) called with curMem=222236, maxMem=278302556
15/01/21 18:53:45 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:45 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:45 INFO BlockManagerMaster: Updated info of block broadcast_31_piece0
15/01/21 18:53:45 INFO SparkContext: Created broadcast 31 from getCallSite at DStream.scala:294
15/01/21 18:53:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 31 (PythonRDD[77] at RDD at PythonRDD.scala:43)
15/01/21 18:53:45 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
15/01/21 18:53:45 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 101, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:45 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:53:45 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 101) in 92 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:53:45 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
15/01/21 18:53:45 INFO DAGScheduler: Stage 31 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:53:45 INFO DAGScheduler: Job 30 finished: runJob at PythonRDD.scala:344, took 0.107191 s
15/01/21 18:53:45 INFO JobScheduler: Finished job streaming job 1421837625000 ms.0 from job set of time 1421837625000 ms
15/01/21 18:53:45 INFO JobScheduler: Total delay: 0.208 s for time 1421837625000 ms (execution: 0.207 s)
15/01/21 18:53:45 INFO BlockRDD: Removing RDD 74 from persistence list
15/01/21 18:53:45 INFO BlockManager: Removing RDD 74
15/01/21 18:53:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[74] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837625000 ms
15/01/21 18:53:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837615000 ms)
15/01/21 18:53:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:46 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:46 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:48 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:48 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:50 INFO JobScheduler: Added jobs for time 1421837630000 ms
15/01/21 18:53:50 INFO JobScheduler: Starting job streaming job 1421837630000 ms.0 from job set of time 1421837630000 ms
15/01/21 18:53:50 INFO JobScheduler: Finished job streaming job 1421837630000 ms.0 from job set of time 1421837630000 ms
15/01/21 18:53:50 INFO JobScheduler: Total delay: 0.003 s for time 1421837630000 ms (execution: 0.003 s)
15/01/21 18:53:50 INFO BlockRDD: Removing RDD 75 from persistence list
15/01/21 18:53:50 INFO BlockManager: Removing RDD 75
15/01/21 18:53:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[75] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837630000 ms
15/01/21 18:53:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837620000 ms)
15/01/21 18:53:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:50 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:50 INFO BlockManagerInfo: Removed input-0-1421837625200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:50 INFO BlockManagerInfo: Removed input-0-1421837627200 on sh-demo-hadoop-02:35432 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:50 INFO BlockManagerInfo: Removed input-0-1421837625200 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:50 INFO BlockManagerInfo: Removed input-0-1421837627200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:50 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:52 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:52 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:54 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:54 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:54 INFO BlockManagerInfo: Added input-0-1421837639600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:54 INFO BlockManagerInfo: Added input-0-1421837639600 in memory on sh-demo-hadoop-05:59361 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:55 INFO JobScheduler: Added jobs for time 1421837635000 ms
15/01/21 18:53:55 INFO JobScheduler: Starting job streaming job 1421837635000 ms.0 from job set of time 1421837635000 ms
15/01/21 18:53:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:55 INFO DAGScheduler: Got job 31 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:55 INFO DAGScheduler: Final stage: Stage 32(runJob at PythonRDD.scala:344)
15/01/21 18:53:55 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:55 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:55 INFO DAGScheduler: Submitting Stage 32 (PythonRDD[80] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:55 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=224729, maxMem=278302556
15/01/21 18:53:55 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:55 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=228049, maxMem=278302556
15/01/21 18:53:55 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:55 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:55 INFO BlockManagerMaster: Updated info of block broadcast_32_piece0
15/01/21 18:53:55 INFO SparkContext: Created broadcast 32 from getCallSite at DStream.scala:294
15/01/21 18:53:55 INFO DAGScheduler: Submitting 1 missing tasks from Stage 32 (PythonRDD[80] at RDD at PythonRDD.scala:43)
15/01/21 18:53:55 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
15/01/21 18:53:55 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 102, sh-demo-hadoop-05, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:55 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on sh-demo-hadoop-05:59361 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:53:55 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 102) in 61 ms on sh-demo-hadoop-05 (1/1)
15/01/21 18:53:55 INFO DAGScheduler: Stage 32 (runJob at PythonRDD.scala:344) finished in 0.062 s
15/01/21 18:53:55 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
15/01/21 18:53:55 INFO DAGScheduler: Job 31 finished: runJob at PythonRDD.scala:344, took 0.070544 s
15/01/21 18:53:55 INFO JobScheduler: Finished job streaming job 1421837635000 ms.0 from job set of time 1421837635000 ms
15/01/21 18:53:55 INFO JobScheduler: Total delay: 0.083 s for time 1421837635000 ms (execution: 0.082 s)
15/01/21 18:53:55 INFO BlockRDD: Removing RDD 78 from persistence list
15/01/21 18:53:55 INFO BlockManager: Removing RDD 78
15/01/21 18:53:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[78] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837635000 ms
15/01/21 18:53:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837625000 ms)
15/01/21 18:53:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:56 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:56 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:56 INFO BlockManagerInfo: Added input-0-1421837641600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:56 INFO BlockManagerInfo: Added input-0-1421837641600 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:58 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:58 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:00 INFO JobScheduler: Added jobs for time 1421837640000 ms
15/01/21 18:54:00 INFO JobScheduler: Starting job streaming job 1421837640000 ms.0 from job set of time 1421837640000 ms
15/01/21 18:54:00 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:54:00 INFO DAGScheduler: Got job 32 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:54:00 INFO DAGScheduler: Final stage: Stage 33(runJob at PythonRDD.scala:344)
15/01/21 18:54:00 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:54:00 INFO DAGScheduler: Missing parents: List()
15/01/21 18:54:00 INFO DAGScheduler: Submitting Stage 33 (PythonRDD[82] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:54:00 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=230540, maxMem=278302556
15/01/21 18:54:00 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:54:00 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=233860, maxMem=278302556
15/01/21 18:54:00 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:54:00 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:54:00 INFO BlockManagerMaster: Updated info of block broadcast_33_piece0
15/01/21 18:54:00 INFO SparkContext: Created broadcast 33 from getCallSite at DStream.scala:294
15/01/21 18:54:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 33 (PythonRDD[82] at RDD at PythonRDD.scala:43)
15/01/21 18:54:00 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
15/01/21 18:54:00 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 103, sh-demo-hadoop-03, NODE_LOCAL, 1236 bytes)
15/01/21 18:54:00 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on sh-demo-hadoop-03:44092 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:54:00 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 103) in 53 ms on sh-demo-hadoop-03 (1/1)
15/01/21 18:54:00 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
15/01/21 18:54:00 INFO DAGScheduler: Stage 33 (runJob at PythonRDD.scala:344) finished in 0.054 s
15/01/21 18:54:00 INFO DAGScheduler: Job 32 finished: runJob at PythonRDD.scala:344, took 0.062056 s
15/01/21 18:54:00 INFO JobScheduler: Finished job streaming job 1421837640000 ms.0 from job set of time 1421837640000 ms
15/01/21 18:54:00 INFO JobScheduler: Total delay: 0.074 s for time 1421837640000 ms (execution: 0.073 s)
15/01/21 18:54:00 INFO BlockRDD: Removing RDD 79 from persistence list
15/01/21 18:54:00 INFO BlockManager: Removing RDD 79
15/01/21 18:54:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[79] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837640000 ms
15/01/21 18:54:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837630000 ms)
15/01/21 18:54:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:54:00 INFO BlockManagerInfo: Removed input-0-1421837639600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:54:00 INFO BlockManagerInfo: Removed input-0-1421837639600 on sh-demo-hadoop-05:59361 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:54:00 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:00 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:02 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:02 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:04 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:04 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:05 INFO JobScheduler: Added jobs for time 1421837645000 ms
15/01/21 18:54:05 INFO JobScheduler: Starting job streaming job 1421837645000 ms.0 from job set of time 1421837645000 ms
15/01/21 18:54:05 INFO JobScheduler: Finished job streaming job 1421837645000 ms.0 from job set of time 1421837645000 ms
15/01/21 18:54:05 INFO JobScheduler: Total delay: 0.003 s for time 1421837645000 ms (execution: 0.003 s)
15/01/21 18:54:05 INFO BlockRDD: Removing RDD 81 from persistence list
15/01/21 18:54:05 INFO BlockManager: Removing RDD 81
15/01/21 18:54:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[81] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837645000 ms
15/01/21 18:54:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837635000 ms)
15/01/21 18:54:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:54:05 INFO BlockManagerInfo: Removed input-0-1421837641600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:54:05 INFO BlockManagerInfo: Removed input-0-1421837641600 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:54:06 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:06 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:08 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:08 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:10 INFO JobScheduler: Added jobs for time 1421837650000 ms
15/01/21 18:54:10 INFO JobScheduler: Starting job streaming job 1421837650000 ms.0 from job set of time 1421837650000 ms
15/01/21 18:54:10 INFO JobScheduler: Finished job streaming job 1421837650000 ms.0 from job set of time 1421837650000 ms
15/01/21 18:54:10 INFO JobScheduler: Total delay: 0.004 s for time 1421837650000 ms (execution: 0.003 s)
15/01/21 18:54:10 INFO BlockRDD: Removing RDD 83 from persistence list
15/01/21 18:54:10 INFO BlockManager: Removing RDD 83
15/01/21 18:54:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[83] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837650000 ms
15/01/21 18:54:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837640000 ms)
15/01/21 18:54:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:54:10 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:10 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:12 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:14 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:15 INFO JobScheduler: Added jobs for time 1421837655000 ms
15/01/21 18:54:15 INFO JobScheduler: Starting job streaming job 1421837655000 ms.0 from job set of time 1421837655000 ms
15/01/21 18:54:15 INFO JobScheduler: Finished job streaming job 1421837655000 ms.0 from job set of time 1421837655000 ms
15/01/21 18:54:15 INFO JobScheduler: Total delay: 0.018 s for time 1421837655000 ms (execution: 0.017 s)
15/01/21 18:54:15 INFO BlockRDD: Removing RDD 84 from persistence list
15/01/21 18:54:15 INFO BlockManager: Removing RDD 84
15/01/21 18:54:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[84] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837655000 ms
15/01/21 18:54:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837645000 ms)
15/01/21 18:54:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
=======
root@ubuntu2[18:49:48]:~/Desktop/streaming#spark-submit --master spark://10.21.208.21:7077 weibo_message.py 10.20.102.52 9999 > log.txt
Spark assembly has been built with Hive, including Datanucleus jars on classpath
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/01/21 18:49:52 INFO SecurityManager: Changing view acls to: root
15/01/21 18:49:52 INFO SecurityManager: Changing modify acls to: root
15/01/21 18:49:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/01/21 18:49:52 INFO Slf4jLogger: Slf4jLogger started
15/01/21 18:49:52 INFO Remoting: Starting remoting
15/01/21 18:49:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.20.70.80:42783]
15/01/21 18:49:53 INFO Utils: Successfully started service 'sparkDriver' on port 42783.
15/01/21 18:49:53 INFO SparkEnv: Registering MapOutputTracker
15/01/21 18:49:53 INFO SparkEnv: Registering BlockManagerMaster
15/01/21 18:49:53 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20150121184953-16b3
15/01/21 18:49:53 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/01/21 18:49:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/01/21 18:49:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-8a459428-dbbb-4f66-95d0-14c5f1a2576c
15/01/21 18:49:53 INFO HttpServer: Starting HTTP Server
15/01/21 18:49:53 INFO Utils: Successfully started service 'HTTP file server' on port 38402.
15/01/21 18:49:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/01/21 18:49:58 INFO SparkUI: Started SparkUI at http://10.20.70.80:4040
15/01/21 18:49:58 INFO Utils: Copying /root/Desktop/streaming/weibo_message.py to /tmp/spark-23acab22-d019-4369-a693-e7a15b67863e/weibo_message.py
15/01/21 18:49:58 INFO SparkContext: Added file file:/root/Desktop/streaming/weibo_message.py at http://10.20.70.80:38402/files/weibo_message.py with timestamp 1421837398808
15/01/21 18:49:58 INFO AppClient$ClientActor: Connecting to master spark://10.21.208.21:7077...
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20150121184954-0045
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/0 on worker-20150105184954-sh-demo-hadoop-05-44392 (sh-demo-hadoop-05:44392) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/0 on hostPort sh-demo-hadoop-05:44392 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/1 on worker-20150105184954-sh-demo-hadoop-10-43330 (sh-demo-hadoop-10:43330) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/1 on hostPort sh-demo-hadoop-10:43330 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/2 on worker-20150105184952-sh-demo-hadoop-02-60835 (sh-demo-hadoop-02:60835) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/2 on hostPort sh-demo-hadoop-02:60835 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/3 on worker-20150105184954-sh-demo-hadoop-06-34008 (sh-demo-hadoop-06:34008) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/3 on hostPort sh-demo-hadoop-06:34008 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/4 on worker-20150105184954-sh-demo-hadoop-04-59442 (sh-demo-hadoop-04:59442) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/4 on hostPort sh-demo-hadoop-04:59442 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/5 on worker-20150105184954-sh-demo-hadoop-07-58997 (sh-demo-hadoop-07:58997) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/5 on hostPort sh-demo-hadoop-07:58997 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/6 on worker-20150105184959-sh-demo-hadoop-08-56160 (sh-demo-hadoop-08:56160) with 2 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/6 on hostPort sh-demo-hadoop-08:56160 with 2 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/7 on worker-20150105184952-sh-demo-hadoop-09-51936 (sh-demo-hadoop-09:51936) with 1 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/7 on hostPort sh-demo-hadoop-09:51936 with 1 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor added: app-20150121184954-0045/8 on worker-20150105184954-sh-demo-hadoop-03-55855 (sh-demo-hadoop-03:55855) with 1 cores
15/01/21 18:49:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150121184954-0045/8 on hostPort sh-demo-hadoop-03:55855 with 1 cores, 512.0 MB RAM
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/2 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/7 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/0 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/3 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/5 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/1 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/6 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/4 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/8 is now LOADING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/0 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/1 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/2 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/3 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/4 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/5 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/6 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/7 is now RUNNING
15/01/21 18:49:59 INFO AppClient$ClientActor: Executor updated: app-20150121184954-0045/8 is now RUNNING
15/01/21 18:49:59 INFO NettyBlockTransferService: Server created on 40067
15/01/21 18:49:59 INFO BlockManagerMaster: Trying to register BlockManager
15/01/21 18:49:59 INFO BlockManagerMasterActor: Registering block manager 10.20.70.80:40067 with 265.4 MB RAM, BlockManagerId(<driver>, 10.20.70.80, 40067)
15/01/21 18:49:59 INFO BlockManagerMaster: Registered BlockManager
15/01/21 18:50:00 INFO EventLoggingListener: Logging events to hdfs://10.21.208.21:8020/sparklog/app-20150121184954-0045
15/01/21 18:50:00 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
15/01/21 18:50:00 INFO ReceiverTracker: ReceiverTracker started
15/01/21 18:50:00 INFO ForEachDStream: metadataCleanupDelay = -1
15/01/21 18:50:00 INFO SocketInputDStream: metadataCleanupDelay = -1
15/01/21 18:50:00 INFO SocketInputDStream: Slide time = 5000 ms
15/01/21 18:50:00 INFO SocketInputDStream: Storage level = StorageLevel(false, false, false, false, 1)
15/01/21 18:50:00 INFO SocketInputDStream: Checkpoint interval = null
15/01/21 18:50:00 INFO SocketInputDStream: Remember duration = 5000 ms
15/01/21 18:50:00 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@717c4ec7
15/01/21 18:50:00 INFO ForEachDStream: Slide time = 5000 ms
15/01/21 18:50:00 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, false, 1)
15/01/21 18:50:00 INFO ForEachDStream: Checkpoint interval = null
15/01/21 18:50:00 INFO ForEachDStream: Remember duration = 5000 ms
15/01/21 18:50:00 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@18182506
15/01/21 18:50:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:-2
15/01/21 18:50:00 INFO RecurringTimer: Started timer for JobGenerator at time 1421837405000
15/01/21 18:50:00 INFO JobGenerator: Started JobGenerator at 1421837405000 ms
15/01/21 18:50:00 INFO JobScheduler: Started JobScheduler
15/01/21 18:50:00 INFO DAGScheduler: Registering RDD 2 (start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:00 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:-2) with 20 output partitions (allowLocal=false)
15/01/21 18:50:00 INFO DAGScheduler: Final stage: Stage 1(start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:00 INFO DAGScheduler: Parents of final stage: List(Stage 0)
15/01/21 18:50:00 INFO DAGScheduler: Missing parents: List(Stage 0)
15/01/21 18:50:00 INFO DAGScheduler: Submitting Stage 0 (MappedRDD[2] at start at NativeMethodAccessorImpl.java:-2), which has no missing parents
15/01/21 18:50:00 INFO MemoryStore: ensureFreeSpace(2720) called with curMem=0, maxMem=278302556
15/01/21 18:50:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 2.7 KB, free 265.4 MB)
15/01/21 18:50:00 INFO MemoryStore: ensureFreeSpace(1943) called with curMem=2720, maxMem=278302556
15/01/21 18:50:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1943.0 B, free 265.4 MB)
15/01/21 18:50:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.20.70.80:40067 (size: 1943.0 B, free: 265.4 MB)
15/01/21 18:50:00 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
15/01/21 18:50:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:838
15/01/21 18:50:00 INFO DAGScheduler: Submitting 50 missing tasks from Stage 0 (MappedRDD[2] at start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 50 tasks
15/01/21 18:50:01 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-09:46974/user/Executor#597683221] with ID 7
15/01/21 18:50:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:01 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-02:33569/user/Executor#-1289642399] with ID 2
15/01/21 18:50:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:01 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:01 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-09:54385 with 265.0 MB RAM, BlockManagerId(7, sh-demo-hadoop-09, 54385)
15/01/21 18:50:01 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-02:35432 with 265.0 MB RAM, BlockManagerId(2, sh-demo-hadoop-02, 35432)
15/01/21 18:50:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-09:54385 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-02:35432 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-04:36267/user/Executor#1263277294] with ID 4
15/01/21 18:50:02 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, sh-demo-hadoop-04, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, sh-demo-hadoop-04, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1007 ms on sh-demo-hadoop-02 (1/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1047 ms on sh-demo-hadoop-09 (2/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1024 ms on sh-demo-hadoop-02 (3/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 31 ms on sh-demo-hadoop-02 (4/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 32 ms on sh-demo-hadoop-02 (5/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 47 ms on sh-demo-hadoop-09 (6/50)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-06:56018/user/Executor#-865999376] with ID 3
15/01/21 18:50:02 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, sh-demo-hadoop-06, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, sh-demo-hadoop-06, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 30 ms on sh-demo-hadoop-02 (7/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 34 ms on sh-demo-hadoop-09 (8/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 35 ms on sh-demo-hadoop-02 (9/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 38 ms on sh-demo-hadoop-02 (10/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 35 ms on sh-demo-hadoop-09 (11/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 33 ms on sh-demo-hadoop-02 (12/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 18 ms on sh-demo-hadoop-09 (13/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 34 ms on sh-demo-hadoop-02 (14/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 29 ms on sh-demo-hadoop-02 (15/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 28 ms on sh-demo-hadoop-09 (16/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 20.0 in stage 0.0 (TID 20) in 26 ms on sh-demo-hadoop-02 (17/50)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-08:36591/user/Executor#-720635433] with ID 6
15/01/21 18:50:02 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24, sh-demo-hadoop-08, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25, sh-demo-hadoop-08, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 21.0 in stage 0.0 (TID 21) in 44 ms on sh-demo-hadoop-02 (18/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 22.0 in stage 0.0 (TID 22) in 41 ms on sh-demo-hadoop-09 (19/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 23.0 in stage 0.0 (TID 23) in 43 ms on sh-demo-hadoop-02 (20/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 27.0 in stage 0.0 (TID 27) in 26 ms on sh-demo-hadoop-09 (21/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 26.0 in stage 0.0 (TID 26) in 42 ms on sh-demo-hadoop-02 (22/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 28.0 in stage 0.0 (TID 28) in 31 ms on sh-demo-hadoop-02 (23/50)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-05:41697/user/Executor#-472026627] with ID 0
15/01/21 18:50:02 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32, sh-demo-hadoop-05, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33, sh-demo-hadoop-05, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 29) in 40 ms on sh-demo-hadoop-09 (24/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 30.0 in stage 0.0 (TID 30) in 33 ms on sh-demo-hadoop-02 (25/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 31.0 in stage 0.0 (TID 31) in 32 ms on sh-demo-hadoop-02 (26/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 34.0 in stage 0.0 (TID 34) in 20 ms on sh-demo-hadoop-09 (27/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 35.0 in stage 0.0 (TID 35) in 20 ms on sh-demo-hadoop-02 (28/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 36.0 in stage 0.0 (TID 36) in 22 ms on sh-demo-hadoop-02 (29/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 38.0 in stage 0.0 (TID 38) in 22 ms on sh-demo-hadoop-02 (30/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 37.0 in stage 0.0 (TID 37) in 27 ms on sh-demo-hadoop-09 (31/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 39.0 in stage 0.0 (TID 39) in 24 ms on sh-demo-hadoop-02 (32/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 41.0 in stage 0.0 (TID 41) in 20 ms on sh-demo-hadoop-09 (33/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 40.0 in stage 0.0 (TID 40) in 26 ms on sh-demo-hadoop-02 (34/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 42.0 in stage 0.0 (TID 42) in 26 ms on sh-demo-hadoop-02 (35/50)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-03:55105/user/Executor#-1663855072] with ID 8
15/01/21 18:50:02 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46, sh-demo-hadoop-03, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 44.0 in stage 0.0 (TID 44) in 31 ms on sh-demo-hadoop-02 (36/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48, sh-demo-hadoop-09, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 43.0 in stage 0.0 (TID 43) in 38 ms on sh-demo-hadoop-09 (37/50)
15/01/21 18:50:02 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49, sh-demo-hadoop-02, PROCESS_LOCAL, 1306 bytes)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 45.0 in stage 0.0 (TID 45) in 37 ms on sh-demo-hadoop-02 (38/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 47.0 in stage 0.0 (TID 47) in 24 ms on sh-demo-hadoop-02 (39/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 49.0 in stage 0.0 (TID 49) in 14 ms on sh-demo-hadoop-02 (40/50)
15/01/21 18:50:02 INFO TaskSetManager: Finished task 48.0 in stage 0.0 (TID 48) in 26 ms on sh-demo-hadoop-09 (41/50)
15/01/21 18:50:02 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-04:38128 with 265.0 MB RAM, BlockManagerId(4, sh-demo-hadoop-04, 38128)
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622/user/Executor#-1701637077] with ID 1
15/01/21 18:50:02 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@sh-demo-hadoop-07:57384/user/Executor#937487728] with ID 5
15/01/21 18:50:02 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-06:52083 with 265.0 MB RAM, BlockManagerId(3, sh-demo-hadoop-06, 52083)
15/01/21 18:50:02 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-08:59231 with 265.0 MB RAM, BlockManagerId(6, sh-demo-hadoop-08, 59231)
15/01/21 18:50:02 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-05:59361 with 265.0 MB RAM, BlockManagerId(0, sh-demo-hadoop-05, 59361)
15/01/21 18:50:03 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-03:44092 with 265.0 MB RAM, BlockManagerId(8, sh-demo-hadoop-03, 44092)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-04:38128 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-08:59231 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-06:52083 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-10:56623 with 265.0 MB RAM, BlockManagerId(1, sh-demo-hadoop-10, 56623)
15/01/21 18:50:03 INFO BlockManagerMasterActor: Registering block manager sh-demo-hadoop-07:57986 with 265.0 MB RAM, BlockManagerId(5, sh-demo-hadoop-07, 57986)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-05:59361 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 1523 ms on sh-demo-hadoop-04 (42/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1527 ms on sh-demo-hadoop-04 (43/50)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sh-demo-hadoop-03:44092 (size: 1943.0 B, free: 265.0 MB)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 25.0 in stage 0.0 (TID 25) in 1509 ms on sh-demo-hadoop-08 (44/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 24.0 in stage 0.0 (TID 24) in 1514 ms on sh-demo-hadoop-08 (45/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 1621 ms on sh-demo-hadoop-06 (46/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 1623 ms on sh-demo-hadoop-06 (47/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 32.0 in stage 0.0 (TID 32) in 1613 ms on sh-demo-hadoop-05 (48/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 33.0 in stage 0.0 (TID 33) in 1615 ms on sh-demo-hadoop-05 (49/50)
15/01/21 18:50:03 INFO TaskSetManager: Finished task 46.0 in stage 0.0 (TID 46) in 1569 ms on sh-demo-hadoop-03 (50/50)
15/01/21 18:50:03 INFO DAGScheduler: Stage 0 (start at NativeMethodAccessorImpl.java:-2) finished in 3.036 s
15/01/21 18:50:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/01/21 18:50:03 INFO DAGScheduler: looking for newly runnable stages
15/01/21 18:50:03 INFO DAGScheduler: running: Set()
15/01/21 18:50:03 INFO DAGScheduler: waiting: Set(Stage 1)
15/01/21 18:50:03 INFO DAGScheduler: failed: Set()
15/01/21 18:50:03 INFO DAGScheduler: Missing parents for Stage 1: List()
15/01/21 18:50:03 INFO DAGScheduler: Submitting Stage 1 (ShuffledRDD[3] at start at NativeMethodAccessorImpl.java:-2), which is now runnable
15/01/21 18:50:03 INFO MemoryStore: ensureFreeSpace(2232) called with curMem=4663, maxMem=278302556
15/01/21 18:50:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.2 KB, free 265.4 MB)
15/01/21 18:50:03 INFO MemoryStore: ensureFreeSpace(1642) called with curMem=6895, maxMem=278302556
15/01/21 18:50:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1642.0 B, free 265.4 MB)
15/01/21 18:50:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.20.70.80:40067 (size: 1642.0 B, free: 265.4 MB)
15/01/21 18:50:03 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/01/21 18:50:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:838
15/01/21 18:50:04 INFO DAGScheduler: Submitting 20 missing tasks from Stage 1 (ShuffledRDD[3] at start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 20 tasks
15/01/21 18:50:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 50, sh-demo-hadoop-04, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 51, sh-demo-hadoop-02, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 52, sh-demo-hadoop-07, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 53, sh-demo-hadoop-03, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 54, sh-demo-hadoop-08, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 55, sh-demo-hadoop-06, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 56, sh-demo-hadoop-10, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 57, sh-demo-hadoop-05, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 58, sh-demo-hadoop-09, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 59, sh-demo-hadoop-04, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 60, sh-demo-hadoop-02, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 61, sh-demo-hadoop-07, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 62, sh-demo-hadoop-08, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 63, sh-demo-hadoop-06, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 64, sh-demo-hadoop-10, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 65, sh-demo-hadoop-05, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-09:54385 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-02:35432 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-08:59231 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-03:44092 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-02:33569
15/01/21 18:50:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 390 bytes
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-09:46974
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-08:36591
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-05:59361 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-03:55105
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-06:52083 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 66, sh-demo-hadoop-09, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 58) in 129 ms on sh-demo-hadoop-09 (1/20)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-05:41697
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-06:56018
15/01/21 18:50:04 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 67, sh-demo-hadoop-09, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 66) in 26 ms on sh-demo-hadoop-09 (2/20)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 68, sh-demo-hadoop-02, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 69, sh-demo-hadoop-02, PROCESS_LOCAL, 1113 bytes)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 51) in 165 ms on sh-demo-hadoop-02 (3/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 60) in 158 ms on sh-demo-hadoop-02 (4/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 67) in 23 ms on sh-demo-hadoop-09 (5/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 69) in 21 ms on sh-demo-hadoop-02 (6/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 68) in 24 ms on sh-demo-hadoop-02 (7/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 53) in 186 ms on sh-demo-hadoop-03 (8/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 54) in 219 ms on sh-demo-hadoop-08 (9/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 62) in 221 ms on sh-demo-hadoop-08 (10/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 65) in 221 ms on sh-demo-hadoop-05 (11/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 57) in 273 ms on sh-demo-hadoop-05 (12/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 63) in 273 ms on sh-demo-hadoop-06 (13/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 55) in 293 ms on sh-demo-hadoop-06 (14/20)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-04:38128 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-04:36267
15/01/21 18:50:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 50) in 469 ms on sh-demo-hadoop-04 (15/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 59) in 465 ms on sh-demo-hadoop-04 (16/20)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-10:56623 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sh-demo-hadoop-07:57986 (size: 1642.0 B, free: 265.0 MB)
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:04 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@sh-demo-hadoop-07:57384
15/01/21 18:50:04 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 56) in 946 ms on sh-demo-hadoop-10 (17/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 64) in 941 ms on sh-demo-hadoop-10 (18/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 61) in 952 ms on sh-demo-hadoop-07 (19/20)
15/01/21 18:50:04 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 52) in 963 ms on sh-demo-hadoop-07 (20/20)
15/01/21 18:50:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/01/21 18:50:04 INFO DAGScheduler: Stage 1 (start at NativeMethodAccessorImpl.java:-2) finished in 0.965 s
15/01/21 18:50:04 INFO DAGScheduler: Job 0 finished: start at NativeMethodAccessorImpl.java:-2, took 4.358238 s
15/01/21 18:50:04 INFO ReceiverTracker: Starting 1 receivers
15/01/21 18:50:05 INFO JobScheduler: Added jobs for time 1421837405000 ms
15/01/21 18:50:05 INFO JobScheduler: Starting job streaming job 1421837405000 ms.0 from job set of time 1421837405000 ms
15/01/21 18:50:05 INFO JobScheduler: Finished job streaming job 1421837405000 ms.0 from job set of time 1421837405000 ms
15/01/21 18:50:05 INFO JobScheduler: Total delay: 0.070 s for time 1421837405000 ms (execution: 0.025 s)
15/01/21 18:50:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:05 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:-2
15/01/21 18:50:05 INFO DAGScheduler: Got job 1 (start at NativeMethodAccessorImpl.java:-2) with 1 output partitions (allowLocal=false)
15/01/21 18:50:05 INFO DAGScheduler: Final stage: Stage 2(start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:05 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:05 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:05 INFO DAGScheduler: Submitting Stage 2 (ParallelCollectionRDD[0] at start at NativeMethodAccessorImpl.java:-2), which has no missing parents
15/01/21 18:50:05 INFO MemoryStore: ensureFreeSpace(30480) called with curMem=8537, maxMem=278302556
15/01/21 18:50:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 29.8 KB, free 265.4 MB)
15/01/21 18:50:05 INFO MemoryStore: ensureFreeSpace(17186) called with curMem=39017, maxMem=278302556
15/01/21 18:50:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 16.8 KB, free 265.4 MB)
15/01/21 18:50:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.20.70.80:40067 (size: 16.8 KB, free: 265.4 MB)
15/01/21 18:50:05 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/01/21 18:50:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:838
15/01/21 18:50:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 2 (ParallelCollectionRDD[0] at start at NativeMethodAccessorImpl.java:-2)
15/01/21 18:50:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
15/01/21 18:50:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 70, sh-demo-hadoop-10, PROCESS_LOCAL, 1934 bytes)
15/01/21 18:50:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sh-demo-hadoop-10:56623 (size: 16.8 KB, free: 265.0 MB)
15/01/21 18:50:05 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:05 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:05 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:05 INFO BlockManagerInfo: Added input-0-1421837410600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:05 INFO BlockManagerInfo: Added input-0-1421837410600 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:07 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:07 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:09 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:09 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:10 INFO JobScheduler: Added jobs for time 1421837410000 ms
15/01/21 18:50:10 INFO JobScheduler: Starting job streaming job 1421837410000 ms.0 from job set of time 1421837410000 ms
15/01/21 18:50:10 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:50:10 INFO DAGScheduler: Got job 2 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:50:10 INFO DAGScheduler: Final stage: Stage 3(runJob at PythonRDD.scala:344)
15/01/21 18:50:10 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:10 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:10 INFO DAGScheduler: Submitting Stage 3 (PythonRDD[6] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:50:10 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=56203, maxMem=278302556
15/01/21 18:50:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.2 KB, free 265.4 MB)
15/01/21 18:50:10 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=59523, maxMem=278302556
15/01/21 18:50:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.4 MB)
15/01/21 18:50:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:50:10 INFO BlockManagerMaster: Updated info of block broadcast_3_piece0
15/01/21 18:50:10 INFO SparkContext: Created broadcast 3 from getCallSite at DStream.scala:294
15/01/21 18:50:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 3 (PythonRDD[6] at RDD at PythonRDD.scala:43)
15/01/21 18:50:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
15/01/21 18:50:10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 71, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:50:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:50:11 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 71) in 1489 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:50:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/01/21 18:50:11 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:11 INFO DAGScheduler: Stage 3 (runJob at PythonRDD.scala:344) finished in 1.497 s
15/01/21 18:50:11 INFO DAGScheduler: Job 2 finished: runJob at PythonRDD.scala:344, took 1.536090 s
15/01/21 18:50:11 INFO JobScheduler: Finished job streaming job 1421837410000 ms.0 from job set of time 1421837410000 ms
15/01/21 18:50:11 INFO JobScheduler: Total delay: 1.567 s for time 1421837410000 ms (execution: 1.563 s)
15/01/21 18:50:11 INFO BlockRDD: Removing RDD 4 from persistence list
15/01/21 18:50:11 INFO BlockManager: Removing RDD 4
15/01/21 18:50:11 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[4] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837410000 ms
15/01/21 18:50:11 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:11 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:13 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:13 INFO BlockManagerInfo: Added input-0-1421837418800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:13 INFO BlockManagerInfo: Added input-0-1421837418800 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:15 INFO JobScheduler: Added jobs for time 1421837415000 ms
15/01/21 18:50:15 INFO JobScheduler: Starting job streaming job 1421837415000 ms.0 from job set of time 1421837415000 ms
15/01/21 18:50:15 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:50:15 INFO DAGScheduler: Got job 3 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:50:15 INFO DAGScheduler: Final stage: Stage 4(runJob at PythonRDD.scala:344)
15/01/21 18:50:15 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:15 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:15 INFO DAGScheduler: Submitting Stage 4 (PythonRDD[8] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:50:15 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=62014, maxMem=278302556
15/01/21 18:50:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:50:15 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=65334, maxMem=278302556
15/01/21 18:50:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:50:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:50:15 INFO BlockManagerMaster: Updated info of block broadcast_4_piece0
15/01/21 18:50:15 INFO SparkContext: Created broadcast 4 from getCallSite at DStream.scala:294
15/01/21 18:50:15 INFO DAGScheduler: Submitting 1 missing tasks from Stage 4 (PythonRDD[8] at RDD at PythonRDD.scala:43)
15/01/21 18:50:15 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
15/01/21 18:50:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 72, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:50:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:50:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 72) in 94 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:50:15 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
15/01/21 18:50:15 INFO DAGScheduler: Stage 4 (runJob at PythonRDD.scala:344) finished in 0.099 s
15/01/21 18:50:15 INFO DAGScheduler: Job 3 finished: runJob at PythonRDD.scala:344, took 0.109472 s
15/01/21 18:50:15 INFO JobScheduler: Finished job streaming job 1421837415000 ms.0 from job set of time 1421837415000 ms
15/01/21 18:50:15 INFO BlockRDD: Removing RDD 5 from persistence list
15/01/21 18:50:15 INFO JobScheduler: Total delay: 0.125 s for time 1421837415000 ms (execution: 0.123 s)
15/01/21 18:50:15 INFO BlockManager: Removing RDD 5
15/01/21 18:50:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[5] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837415000 ms
15/01/21 18:50:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837405000 ms)
15/01/21 18:50:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:15 INFO BlockManagerInfo: Removed input-0-1421837410600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:15 INFO BlockManagerInfo: Removed input-0-1421837410600 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:15 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:15 INFO BlockManagerInfo: Added input-0-1421837420800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:15 INFO BlockManagerInfo: Added input-0-1421837420800 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:17 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:17 INFO BlockManagerInfo: Added input-0-1421837422800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:17 INFO BlockManagerInfo: Added input-0-1421837422800 in memory on sh-demo-hadoop-02:35432 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:19 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:20 INFO JobScheduler: Added jobs for time 1421837420000 ms
15/01/21 18:50:20 INFO JobScheduler: Starting job streaming job 1421837420000 ms.0 from job set of time 1421837420000 ms
15/01/21 18:50:20 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:50:20 INFO DAGScheduler: Got job 4 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:50:20 INFO DAGScheduler: Final stage: Stage 5(runJob at PythonRDD.scala:344)
15/01/21 18:50:20 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:20 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:20 INFO DAGScheduler: Submitting Stage 5 (PythonRDD[10] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:50:20 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=67825, maxMem=278302556
15/01/21 18:50:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:50:20 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=71145, maxMem=278302556
15/01/21 18:50:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:50:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:50:20 INFO BlockManagerMaster: Updated info of block broadcast_5_piece0
15/01/21 18:50:20 INFO SparkContext: Created broadcast 5 from getCallSite at DStream.scala:294
15/01/21 18:50:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 5 (PythonRDD[10] at RDD at PythonRDD.scala:43)
15/01/21 18:50:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
15/01/21 18:50:20 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 73, sh-demo-hadoop-09, NODE_LOCAL, 1236 bytes)
15/01/21 18:50:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sh-demo-hadoop-09:54385 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:50:20 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 73) in 563 ms on sh-demo-hadoop-09 (1/1)
15/01/21 18:50:20 INFO DAGScheduler: Stage 5 (runJob at PythonRDD.scala:344) finished in 0.562 s
15/01/21 18:50:20 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
15/01/21 18:50:20 INFO DAGScheduler: Job 4 finished: runJob at PythonRDD.scala:344, took 0.577708 s
15/01/21 18:50:20 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:50:20 INFO DAGScheduler: Got job 5 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:50:20 INFO DAGScheduler: Final stage: Stage 6(runJob at PythonRDD.scala:344)
15/01/21 18:50:20 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:50:20 INFO DAGScheduler: Missing parents: List()
15/01/21 18:50:20 INFO DAGScheduler: Submitting Stage 6 (PythonRDD[11] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:50:20 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=73636, maxMem=278302556
15/01/21 18:50:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:50:20 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=76956, maxMem=278302556
15/01/21 18:50:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:50:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:50:20 INFO BlockManagerMaster: Updated info of block broadcast_6_piece0
15/01/21 18:50:20 INFO SparkContext: Created broadcast 6 from getCallSite at DStream.scala:294
15/01/21 18:50:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 6 (PythonRDD[11] at RDD at PythonRDD.scala:43)
15/01/21 18:50:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
15/01/21 18:50:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 74, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:50:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:50:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 74) in 89 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:50:20 INFO DAGScheduler: Stage 6 (runJob at PythonRDD.scala:344) finished in 0.090 s
15/01/21 18:50:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
15/01/21 18:50:20 INFO DAGScheduler: Job 5 finished: runJob at PythonRDD.scala:344, took 0.098937 s
15/01/21 18:50:20 INFO JobScheduler: Finished job streaming job 1421837420000 ms.0 from job set of time 1421837420000 ms
15/01/21 18:50:20 INFO BlockRDD: Removing RDD 7 from persistence list
15/01/21 18:50:20 INFO JobScheduler: Total delay: 0.710 s for time 1421837420000 ms (execution: 0.708 s)
15/01/21 18:50:20 INFO BlockManager: Removing RDD 7
15/01/21 18:50:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[7] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837420000 ms
15/01/21 18:50:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837410000 ms)
15/01/21 18:50:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:20 INFO BlockManagerInfo: Removed input-0-1421837418800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:20 INFO BlockManagerInfo: Removed input-0-1421837418800 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:21 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:23 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:25 INFO JobScheduler: Added jobs for time 1421837425000 ms
15/01/21 18:50:25 INFO JobScheduler: Starting job streaming job 1421837425000 ms.0 from job set of time 1421837425000 ms
15/01/21 18:50:25 INFO JobScheduler: Finished job streaming job 1421837425000 ms.0 from job set of time 1421837425000 ms
15/01/21 18:50:25 INFO JobScheduler: Total delay: 0.005 s for time 1421837425000 ms (execution: 0.004 s)
15/01/21 18:50:25 INFO BlockRDD: Removing RDD 9 from persistence list
15/01/21 18:50:25 INFO BlockManager: Removing RDD 9
15/01/21 18:50:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[9] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837425000 ms
15/01/21 18:50:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837415000 ms)
15/01/21 18:50:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:25 INFO BlockManagerInfo: Removed input-0-1421837420800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:25 INFO BlockManagerInfo: Removed input-0-1421837420800 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:25 INFO BlockManagerInfo: Removed input-0-1421837422800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:25 INFO BlockManagerInfo: Removed input-0-1421837422800 on sh-demo-hadoop-02:35432 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:50:25 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:27 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:29 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:30 INFO JobScheduler: Added jobs for time 1421837430000 ms
15/01/21 18:50:30 INFO JobScheduler: Starting job streaming job 1421837430000 ms.0 from job set of time 1421837430000 ms
15/01/21 18:50:30 INFO JobScheduler: Finished job streaming job 1421837430000 ms.0 from job set of time 1421837430000 ms
15/01/21 18:50:30 INFO JobScheduler: Total delay: 0.004 s for time 1421837430000 ms (execution: 0.003 s)
15/01/21 18:50:30 INFO BlockRDD: Removing RDD 12 from persistence list
15/01/21 18:50:30 INFO BlockManager: Removing RDD 12
15/01/21 18:50:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[12] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837430000 ms
15/01/21 18:50:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837420000 ms)
15/01/21 18:50:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:31 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:33 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:35 INFO JobScheduler: Added jobs for time 1421837435000 ms
15/01/21 18:50:35 INFO JobScheduler: Starting job streaming job 1421837435000 ms.0 from job set of time 1421837435000 ms
15/01/21 18:50:35 INFO JobScheduler: Finished job streaming job 1421837435000 ms.0 from job set of time 1421837435000 ms
15/01/21 18:50:35 INFO BlockRDD: Removing RDD 13 from persistence list
15/01/21 18:50:35 INFO JobScheduler: Total delay: 0.005 s for time 1421837435000 ms (execution: 0.003 s)
15/01/21 18:50:35 INFO BlockManager: Removing RDD 13
15/01/21 18:50:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[13] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837435000 ms
15/01/21 18:50:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837425000 ms)
15/01/21 18:50:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:35 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:37 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:39 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:40 INFO JobScheduler: Added jobs for time 1421837440000 ms
15/01/21 18:50:40 INFO JobScheduler: Starting job streaming job 1421837440000 ms.0 from job set of time 1421837440000 ms
15/01/21 18:50:40 INFO JobScheduler: Finished job streaming job 1421837440000 ms.0 from job set of time 1421837440000 ms
15/01/21 18:50:40 INFO JobScheduler: Total delay: 0.005 s for time 1421837440000 ms (execution: 0.004 s)
15/01/21 18:50:40 INFO BlockRDD: Removing RDD 14 from persistence list
15/01/21 18:50:40 INFO BlockManager: Removing RDD 14
15/01/21 18:50:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[14] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837440000 ms
15/01/21 18:50:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837430000 ms)
15/01/21 18:50:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:41 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:41 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:43 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:43 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:45 INFO JobScheduler: Added jobs for time 1421837445000 ms
15/01/21 18:50:45 INFO JobScheduler: Starting job streaming job 1421837445000 ms.0 from job set of time 1421837445000 ms
15/01/21 18:50:45 INFO JobScheduler: Finished job streaming job 1421837445000 ms.0 from job set of time 1421837445000 ms
15/01/21 18:50:45 INFO JobScheduler: Total delay: 0.004 s for time 1421837445000 ms (execution: 0.003 s)
15/01/21 18:50:45 INFO BlockRDD: Removing RDD 15 from persistence list
15/01/21 18:50:45 INFO BlockManager: Removing RDD 15
15/01/21 18:50:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[15] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837445000 ms
15/01/21 18:50:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837435000 ms)
15/01/21 18:50:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:45 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:45 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:47 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:47 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:49 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:49 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:50 INFO JobScheduler: Added jobs for time 1421837450000 ms
15/01/21 18:50:50 INFO JobScheduler: Starting job streaming job 1421837450000 ms.0 from job set of time 1421837450000 ms
15/01/21 18:50:50 INFO JobScheduler: Finished job streaming job 1421837450000 ms.0 from job set of time 1421837450000 ms
15/01/21 18:50:50 INFO JobScheduler: Total delay: 0.003 s for time 1421837450000 ms (execution: 0.003 s)
15/01/21 18:50:50 INFO BlockRDD: Removing RDD 16 from persistence list
15/01/21 18:50:50 INFO BlockManager: Removing RDD 16
15/01/21 18:50:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[16] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837450000 ms
15/01/21 18:50:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837440000 ms)
15/01/21 18:50:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:51 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:51 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:53 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:53 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:55 INFO JobScheduler: Added jobs for time 1421837455000 ms
15/01/21 18:50:55 INFO JobScheduler: Starting job streaming job 1421837455000 ms.0 from job set of time 1421837455000 ms
15/01/21 18:50:55 INFO JobScheduler: Finished job streaming job 1421837455000 ms.0 from job set of time 1421837455000 ms
15/01/21 18:50:55 INFO JobScheduler: Total delay: 0.004 s for time 1421837455000 ms (execution: 0.003 s)
15/01/21 18:50:55 INFO BlockRDD: Removing RDD 17 from persistence list
15/01/21 18:50:55 INFO BlockManager: Removing RDD 17
15/01/21 18:50:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[17] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837455000 ms
15/01/21 18:50:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837445000 ms)
15/01/21 18:50:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:50:55 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:55 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:58 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:50:58 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:50:58 INFO BlockManagerInfo: Added input-0-1421837463200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:50:58 INFO BlockManagerInfo: Added input-0-1421837463200 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:00 INFO JobScheduler: Added jobs for time 1421837460000 ms
15/01/21 18:51:00 INFO JobScheduler: Starting job streaming job 1421837460000 ms.0 from job set of time 1421837460000 ms
15/01/21 18:51:00 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:00 INFO DAGScheduler: Got job 6 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:00 INFO DAGScheduler: Final stage: Stage 7(runJob at PythonRDD.scala:344)
15/01/21 18:51:00 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:00 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:00 INFO DAGScheduler: Submitting Stage 7 (PythonRDD[20] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:00 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=79447, maxMem=278302556
15/01/21 18:51:00 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:00 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=82767, maxMem=278302556
15/01/21 18:51:00 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:00 INFO BlockManagerMaster: Updated info of block broadcast_7_piece0
15/01/21 18:51:00 INFO SparkContext: Created broadcast 7 from getCallSite at DStream.scala:294
15/01/21 18:51:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 7 (PythonRDD[20] at RDD at PythonRDD.scala:43)
15/01/21 18:51:00 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
15/01/21 18:51:00 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 75, sh-demo-hadoop-07, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:00 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:00 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sh-demo-hadoop-07:57986 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:00 INFO BlockManagerInfo: Added input-0-1421837465200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:00 INFO BlockManagerInfo: Added input-0-1421837465200 in memory on sh-demo-hadoop-05:59361 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:00 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 75) in 946 ms on sh-demo-hadoop-07 (1/1)
15/01/21 18:51:00 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
15/01/21 18:51:00 INFO DAGScheduler: Stage 7 (runJob at PythonRDD.scala:344) finished in 0.949 s
15/01/21 18:51:00 INFO DAGScheduler: Job 6 finished: runJob at PythonRDD.scala:344, took 0.957380 s
15/01/21 18:51:00 INFO JobScheduler: Finished job streaming job 1421837460000 ms.0 from job set of time 1421837460000 ms
15/01/21 18:51:00 INFO JobScheduler: Total delay: 0.973 s for time 1421837460000 ms (execution: 0.972 s)
15/01/21 18:51:00 INFO BlockRDD: Removing RDD 18 from persistence list
15/01/21 18:51:00 INFO BlockManager: Removing RDD 18
15/01/21 18:51:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[18] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837460000 ms
15/01/21 18:51:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837450000 ms)
15/01/21 18:51:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:02 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:02 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:04 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:04 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:05 INFO JobScheduler: Added jobs for time 1421837465000 ms
15/01/21 18:51:05 INFO JobScheduler: Starting job streaming job 1421837465000 ms.0 from job set of time 1421837465000 ms
15/01/21 18:51:05 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:05 INFO DAGScheduler: Got job 7 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:05 INFO DAGScheduler: Final stage: Stage 8(runJob at PythonRDD.scala:344)
15/01/21 18:51:05 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:05 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:05 INFO DAGScheduler: Submitting Stage 8 (PythonRDD[22] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:05 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=85258, maxMem=278302556
15/01/21 18:51:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:05 INFO MemoryStore: ensureFreeSpace(2492) called with curMem=88578, maxMem=278302556
15/01/21 18:51:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:05 INFO BlockManagerMaster: Updated info of block broadcast_8_piece0
15/01/21 18:51:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:838
15/01/21 18:51:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 8 (PythonRDD[22] at RDD at PythonRDD.scala:43)
15/01/21 18:51:05 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
15/01/21 18:51:05 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 76, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:05 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 76) in 95 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:05 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
15/01/21 18:51:05 INFO DAGScheduler: Stage 8 (runJob at PythonRDD.scala:344) finished in 0.095 s
15/01/21 18:51:05 INFO DAGScheduler: Job 7 finished: runJob at PythonRDD.scala:344, took 0.111227 s
15/01/21 18:51:05 INFO JobScheduler: Finished job streaming job 1421837465000 ms.0 from job set of time 1421837465000 ms
15/01/21 18:51:05 INFO BlockRDD: Removing RDD 19 from persistence list
15/01/21 18:51:05 INFO BlockManager: Removing RDD 19
15/01/21 18:51:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[19] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837465000 ms
15/01/21 18:51:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837455000 ms)
15/01/21 18:51:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:05 INFO JobScheduler: Total delay: 0.127 s for time 1421837465000 ms (execution: 0.127 s)
15/01/21 18:51:05 INFO BlockManagerInfo: Removed input-0-1421837463200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:05 INFO BlockManagerInfo: Removed input-0-1421837463200 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:06 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:06 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:08 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:08 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:10 INFO JobScheduler: Added jobs for time 1421837470000 ms
15/01/21 18:51:10 INFO JobScheduler: Starting job streaming job 1421837470000 ms.0 from job set of time 1421837470000 ms
15/01/21 18:51:10 INFO JobScheduler: Finished job streaming job 1421837470000 ms.0 from job set of time 1421837470000 ms
15/01/21 18:51:10 INFO BlockRDD: Removing RDD 21 from persistence list
15/01/21 18:51:10 INFO JobScheduler: Total delay: 0.004 s for time 1421837470000 ms (execution: 0.003 s)
15/01/21 18:51:10 INFO BlockManager: Removing RDD 21
15/01/21 18:51:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[21] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837470000 ms
15/01/21 18:51:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837460000 ms)
15/01/21 18:51:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:10 INFO BlockManagerInfo: Removed input-0-1421837465200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:10 INFO BlockManagerInfo: Removed input-0-1421837465200 on sh-demo-hadoop-05:59361 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:10 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:10 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:12 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:14 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:15 INFO JobScheduler: Added jobs for time 1421837475000 ms
15/01/21 18:51:15 INFO JobScheduler: Starting job streaming job 1421837475000 ms.0 from job set of time 1421837475000 ms
15/01/21 18:51:15 INFO JobScheduler: Finished job streaming job 1421837475000 ms.0 from job set of time 1421837475000 ms
15/01/21 18:51:15 INFO JobScheduler: Total delay: 0.005 s for time 1421837475000 ms (execution: 0.004 s)
15/01/21 18:51:15 INFO BlockRDD: Removing RDD 23 from persistence list
15/01/21 18:51:15 INFO BlockManager: Removing RDD 23
15/01/21 18:51:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[23] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837475000 ms
15/01/21 18:51:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837465000 ms)
15/01/21 18:51:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:16 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:18 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:20 INFO JobScheduler: Added jobs for time 1421837480000 ms
15/01/21 18:51:20 INFO JobScheduler: Starting job streaming job 1421837480000 ms.0 from job set of time 1421837480000 ms
15/01/21 18:51:20 INFO JobScheduler: Finished job streaming job 1421837480000 ms.0 from job set of time 1421837480000 ms
15/01/21 18:51:20 INFO JobScheduler: Total delay: 0.006 s for time 1421837480000 ms (execution: 0.004 s)
15/01/21 18:51:20 INFO BlockRDD: Removing RDD 24 from persistence list
15/01/21 18:51:20 INFO BlockManager: Removing RDD 24
15/01/21 18:51:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[24] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837480000 ms
15/01/21 18:51:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837470000 ms)
15/01/21 18:51:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:20 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:22 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:24 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:25 INFO JobScheduler: Added jobs for time 1421837485000 ms
15/01/21 18:51:25 INFO JobScheduler: Starting job streaming job 1421837485000 ms.0 from job set of time 1421837485000 ms
15/01/21 18:51:25 INFO JobScheduler: Finished job streaming job 1421837485000 ms.0 from job set of time 1421837485000 ms
15/01/21 18:51:25 INFO JobScheduler: Total delay: 0.016 s for time 1421837485000 ms (execution: 0.015 s)
15/01/21 18:51:25 INFO BlockRDD: Removing RDD 25 from persistence list
15/01/21 18:51:25 INFO BlockManager: Removing RDD 25
15/01/21 18:51:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[25] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837485000 ms
15/01/21 18:51:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837475000 ms)
15/01/21 18:51:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:26 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:26 INFO BlockManagerInfo: Added input-0-1421837491400 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:26 INFO BlockManagerInfo: Added input-0-1421837491400 in memory on sh-demo-hadoop-05:59361 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:28 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:28 INFO BlockManagerInfo: Added input-0-1421837493400 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:28 INFO BlockManagerInfo: Added input-0-1421837493400 in memory on sh-demo-hadoop-05:59361 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:30 INFO JobScheduler: Added jobs for time 1421837490000 ms
15/01/21 18:51:30 INFO JobScheduler: Starting job streaming job 1421837490000 ms.0 from job set of time 1421837490000 ms
15/01/21 18:51:30 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:30 INFO DAGScheduler: Got job 8 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:30 INFO DAGScheduler: Final stage: Stage 9(runJob at PythonRDD.scala:344)
15/01/21 18:51:30 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:30 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:30 INFO DAGScheduler: Submitting Stage 9 (PythonRDD[28] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:30 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=91070, maxMem=278302556
15/01/21 18:51:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:30 INFO MemoryStore: ensureFreeSpace(2492) called with curMem=94390, maxMem=278302556
15/01/21 18:51:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:30 INFO BlockManagerMaster: Updated info of block broadcast_9_piece0
15/01/21 18:51:30 INFO SparkContext: Created broadcast 9 from getCallSite at DStream.scala:294
15/01/21 18:51:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 9 (PythonRDD[28] at RDD at PythonRDD.scala:43)
15/01/21 18:51:30 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
15/01/21 18:51:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 77, sh-demo-hadoop-05, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on sh-demo-hadoop-05:59361 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:30 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:30 INFO BlockManagerInfo: Added input-0-1421837495600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:30 INFO BlockManagerInfo: Added input-0-1421837495600 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:31 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 77) in 1540 ms on sh-demo-hadoop-05 (1/1)
15/01/21 18:51:31 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
15/01/21 18:51:31 INFO DAGScheduler: Stage 9 (runJob at PythonRDD.scala:344) finished in 1.539 s
15/01/21 18:51:31 INFO DAGScheduler: Job 8 finished: runJob at PythonRDD.scala:344, took 1.554829 s
15/01/21 18:51:31 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:31 INFO DAGScheduler: Got job 9 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:31 INFO DAGScheduler: Final stage: Stage 10(runJob at PythonRDD.scala:344)
15/01/21 18:51:31 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:31 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:31 INFO DAGScheduler: Submitting Stage 10 (PythonRDD[29] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:31 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=96882, maxMem=278302556
15/01/21 18:51:31 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:31 INFO MemoryStore: ensureFreeSpace(2492) called with curMem=100202, maxMem=278302556
15/01/21 18:51:31 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:31 INFO BlockManagerMaster: Updated info of block broadcast_10_piece0
15/01/21 18:51:31 INFO SparkContext: Created broadcast 10 from getCallSite at DStream.scala:294
15/01/21 18:51:31 INFO DAGScheduler: Submitting 1 missing tasks from Stage 10 (PythonRDD[29] at RDD at PythonRDD.scala:43)
15/01/21 18:51:31 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
15/01/21 18:51:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 78, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:31 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 78) in 94 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:31 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
15/01/21 18:51:31 INFO DAGScheduler: Stage 10 (runJob at PythonRDD.scala:344) finished in 0.095 s
15/01/21 18:51:31 INFO DAGScheduler: Job 9 finished: runJob at PythonRDD.scala:344, took 0.108053 s
15/01/21 18:51:31 INFO JobScheduler: Finished job streaming job 1421837490000 ms.0 from job set of time 1421837490000 ms
15/01/21 18:51:31 INFO JobScheduler: Total delay: 1.686 s for time 1421837490000 ms (execution: 1.685 s)
15/01/21 18:51:31 INFO BlockRDD: Removing RDD 26 from persistence list
15/01/21 18:51:31 INFO BlockManager: Removing RDD 26
15/01/21 18:51:31 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837490000 ms
15/01/21 18:51:31 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837480000 ms)
15/01/21 18:51:31 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:32 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:32 INFO BlockManagerInfo: Added input-0-1421837497600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:32 INFO BlockManagerInfo: Added input-0-1421837497600 in memory on sh-demo-hadoop-02:35432 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:34 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:35 INFO JobScheduler: Added jobs for time 1421837495000 ms
15/01/21 18:51:35 INFO JobScheduler: Starting job streaming job 1421837495000 ms.0 from job set of time 1421837495000 ms
15/01/21 18:51:35 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:35 INFO DAGScheduler: Got job 10 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:35 INFO DAGScheduler: Final stage: Stage 11(runJob at PythonRDD.scala:344)
15/01/21 18:51:35 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:35 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:35 INFO DAGScheduler: Submitting Stage 11 (PythonRDD[31] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:35 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=102694, maxMem=278302556
15/01/21 18:51:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:35 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=106014, maxMem=278302556
15/01/21 18:51:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:35 INFO BlockManagerMaster: Updated info of block broadcast_11_piece0
15/01/21 18:51:35 INFO SparkContext: Created broadcast 11 from getCallSite at DStream.scala:294
15/01/21 18:51:35 INFO DAGScheduler: Submitting 1 missing tasks from Stage 11 (PythonRDD[31] at RDD at PythonRDD.scala:43)
15/01/21 18:51:35 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
15/01/21 18:51:35 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 79, sh-demo-hadoop-03, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on sh-demo-hadoop-03:44092 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:35 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 79) in 849 ms on sh-demo-hadoop-03 (1/1)
15/01/21 18:51:35 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
15/01/21 18:51:35 INFO DAGScheduler: Stage 11 (runJob at PythonRDD.scala:344) finished in 0.852 s
15/01/21 18:51:35 INFO DAGScheduler: Job 10 finished: runJob at PythonRDD.scala:344, took 0.861637 s
15/01/21 18:51:35 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:35 INFO DAGScheduler: Got job 11 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:35 INFO DAGScheduler: Final stage: Stage 12(runJob at PythonRDD.scala:344)
15/01/21 18:51:35 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:35 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:35 INFO DAGScheduler: Submitting Stage 12 (PythonRDD[32] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:35 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=108505, maxMem=278302556
15/01/21 18:51:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:35 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=111825, maxMem=278302556
15/01/21 18:51:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:35 INFO BlockManagerMaster: Updated info of block broadcast_12_piece0
15/01/21 18:51:35 INFO SparkContext: Created broadcast 12 from getCallSite at DStream.scala:294
15/01/21 18:51:35 INFO DAGScheduler: Submitting 1 missing tasks from Stage 12 (PythonRDD[32] at RDD at PythonRDD.scala:43)
15/01/21 18:51:35 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
15/01/21 18:51:35 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 80, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:35 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 80) in 92 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:35 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
15/01/21 18:51:35 INFO DAGScheduler: Stage 12 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:51:35 INFO DAGScheduler: Job 11 finished: runJob at PythonRDD.scala:344, took 0.102132 s
15/01/21 18:51:35 INFO JobScheduler: Finished job streaming job 1421837495000 ms.0 from job set of time 1421837495000 ms
15/01/21 18:51:35 INFO JobScheduler: Total delay: 0.987 s for time 1421837495000 ms (execution: 0.986 s)
15/01/21 18:51:35 INFO BlockRDD: Removing RDD 27 from persistence list
15/01/21 18:51:35 INFO BlockManager: Removing RDD 27
15/01/21 18:51:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[27] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837495000 ms
15/01/21 18:51:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837485000 ms)
15/01/21 18:51:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:36 INFO BlockManagerInfo: Removed input-0-1421837491400 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:36 INFO BlockManagerInfo: Removed input-0-1421837491400 on sh-demo-hadoop-05:59361 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:36 INFO BlockManagerInfo: Removed input-0-1421837493400 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:36 INFO BlockManagerInfo: Removed input-0-1421837493400 on sh-demo-hadoop-05:59361 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:36 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:36 INFO BlockManagerInfo: Added input-0-1421837501600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:36 INFO BlockManagerInfo: Added input-0-1421837501600 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:38 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:38 INFO BlockManagerInfo: Added input-0-1421837503600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:38 INFO BlockManagerInfo: Added input-0-1421837503600 in memory on sh-demo-hadoop-04:38128 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:40 INFO JobScheduler: Added jobs for time 1421837500000 ms
15/01/21 18:51:40 INFO JobScheduler: Starting job streaming job 1421837500000 ms.0 from job set of time 1421837500000 ms
15/01/21 18:51:40 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:40 INFO DAGScheduler: Got job 12 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:40 INFO DAGScheduler: Final stage: Stage 13(runJob at PythonRDD.scala:344)
15/01/21 18:51:40 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:40 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:40 INFO DAGScheduler: Submitting Stage 13 (PythonRDD[34] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:40 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=114316, maxMem=278302556
15/01/21 18:51:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:40 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=117636, maxMem=278302556
15/01/21 18:51:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:40 INFO BlockManagerMaster: Updated info of block broadcast_13_piece0
15/01/21 18:51:40 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:838
15/01/21 18:51:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 13 (PythonRDD[34] at RDD at PythonRDD.scala:43)
15/01/21 18:51:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
15/01/21 18:51:40 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 81, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 81) in 93 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
15/01/21 18:51:40 INFO DAGScheduler: Stage 13 (runJob at PythonRDD.scala:344) finished in 0.096 s
15/01/21 18:51:40 INFO DAGScheduler: Job 12 finished: runJob at PythonRDD.scala:344, took 0.104946 s
15/01/21 18:51:40 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:40 INFO DAGScheduler: Got job 13 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:40 INFO DAGScheduler: Final stage: Stage 14(runJob at PythonRDD.scala:344)
15/01/21 18:51:40 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:40 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:40 INFO DAGScheduler: Submitting Stage 14 (PythonRDD[35] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:40 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=120127, maxMem=278302556
15/01/21 18:51:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:40 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=123447, maxMem=278302556
15/01/21 18:51:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:40 INFO BlockManagerMaster: Updated info of block broadcast_14_piece0
15/01/21 18:51:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:838
15/01/21 18:51:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 14 (PythonRDD[35] at RDD at PythonRDD.scala:43)
15/01/21 18:51:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
15/01/21 18:51:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 82, sh-demo-hadoop-04, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on sh-demo-hadoop-04:38128 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:40 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:40 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:40 INFO BlockManagerInfo: Added input-0-1421837505800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:40 INFO BlockManagerInfo: Added input-0-1421837505800 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 82) in 860 ms on sh-demo-hadoop-04 (1/1)
15/01/21 18:51:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
15/01/21 18:51:40 INFO DAGScheduler: Stage 14 (runJob at PythonRDD.scala:344) finished in 0.861 s
15/01/21 18:51:40 INFO DAGScheduler: Job 13 finished: runJob at PythonRDD.scala:344, took 0.870580 s
15/01/21 18:51:40 INFO JobScheduler: Finished job streaming job 1421837500000 ms.0 from job set of time 1421837500000 ms
15/01/21 18:51:40 INFO JobScheduler: Total delay: 0.999 s for time 1421837500000 ms (execution: 0.998 s)
15/01/21 18:51:41 INFO BlockRDD: Removing RDD 30 from persistence list
15/01/21 18:51:41 INFO BlockManager: Removing RDD 30
15/01/21 18:51:41 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[30] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837500000 ms
15/01/21 18:51:41 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837490000 ms)
15/01/21 18:51:41 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:41 INFO BlockManagerInfo: Removed input-0-1421837497600 on sh-demo-hadoop-02:35432 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:41 INFO BlockManagerInfo: Removed input-0-1421837495600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:41 INFO BlockManagerInfo: Removed input-0-1421837497600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:41 INFO BlockManagerInfo: Removed input-0-1421837495600 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:42 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:42 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:42 INFO BlockManagerInfo: Added input-0-1421837507800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:42 INFO BlockManagerInfo: Added input-0-1421837507800 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:44 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:44 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:44 INFO BlockManagerInfo: Added input-0-1421837509800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:44 INFO BlockManagerInfo: Added input-0-1421837509800 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:45 INFO JobScheduler: Added jobs for time 1421837505000 ms
15/01/21 18:51:45 INFO JobScheduler: Starting job streaming job 1421837505000 ms.0 from job set of time 1421837505000 ms
15/01/21 18:51:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:45 INFO DAGScheduler: Got job 14 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:45 INFO DAGScheduler: Final stage: Stage 15(runJob at PythonRDD.scala:344)
15/01/21 18:51:45 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:45 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:45 INFO DAGScheduler: Submitting Stage 15 (PythonRDD[37] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:45 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=125938, maxMem=278302556
15/01/21 18:51:45 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:45 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=129258, maxMem=278302556
15/01/21 18:51:45 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:45 INFO BlockManagerMaster: Updated info of block broadcast_15_piece0
15/01/21 18:51:45 INFO SparkContext: Created broadcast 15 from getCallSite at DStream.scala:294
15/01/21 18:51:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 15 (PythonRDD[37] at RDD at PythonRDD.scala:43)
15/01/21 18:51:45 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
15/01/21 18:51:45 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 83, sh-demo-hadoop-09, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on sh-demo-hadoop-09:54385 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:45 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 83) in 45 ms on sh-demo-hadoop-09 (1/1)
15/01/21 18:51:45 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
15/01/21 18:51:45 INFO DAGScheduler: Stage 15 (runJob at PythonRDD.scala:344) finished in 0.047 s
15/01/21 18:51:45 INFO DAGScheduler: Job 14 finished: runJob at PythonRDD.scala:344, took 0.057072 s
15/01/21 18:51:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:45 INFO DAGScheduler: Got job 15 (runJob at PythonRDD.scala:344) with 2 output partitions (allowLocal=true)
15/01/21 18:51:45 INFO DAGScheduler: Final stage: Stage 16(runJob at PythonRDD.scala:344)
15/01/21 18:51:45 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:45 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:45 INFO DAGScheduler: Submitting Stage 16 (PythonRDD[38] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:45 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=131749, maxMem=278302556
15/01/21 18:51:45 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:45 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=135069, maxMem=278302556
15/01/21 18:51:45 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:45 INFO BlockManagerMaster: Updated info of block broadcast_16_piece0
15/01/21 18:51:45 INFO SparkContext: Created broadcast 16 from getCallSite at DStream.scala:294
15/01/21 18:51:45 INFO DAGScheduler: Submitting 2 missing tasks from Stage 16 (PythonRDD[38] at RDD at PythonRDD.scala:43)
15/01/21 18:51:45 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
15/01/21 18:51:45 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 84, sh-demo-hadoop-06, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:45 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 85, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on sh-demo-hadoop-06:52083 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:45 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 85) in 93 ms on sh-demo-hadoop-10 (1/2)
15/01/21 18:51:45 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 84) in 847 ms on sh-demo-hadoop-06 (2/2)
15/01/21 18:51:45 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
15/01/21 18:51:45 INFO DAGScheduler: Stage 16 (runJob at PythonRDD.scala:344) finished in 0.849 s
15/01/21 18:51:45 INFO DAGScheduler: Job 15 finished: runJob at PythonRDD.scala:344, took 0.856789 s
15/01/21 18:51:45 INFO JobScheduler: Finished job streaming job 1421837505000 ms.0 from job set of time 1421837505000 ms
15/01/21 18:51:45 INFO BlockRDD: Removing RDD 33 from persistence list
15/01/21 18:51:45 INFO BlockManager: Removing RDD 33
15/01/21 18:51:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[33] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837505000 ms
15/01/21 18:51:45 INFO JobScheduler: Total delay: 0.952 s for time 1421837505000 ms (execution: 0.951 s)
15/01/21 18:51:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837495000 ms)
15/01/21 18:51:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:45 INFO BlockManagerInfo: Removed input-0-1421837501600 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Removed input-0-1421837501600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Removed input-0-1421837503600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:45 INFO BlockManagerInfo: Removed input-0-1421837503600 on sh-demo-hadoop-04:38128 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:46 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:46 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:46 INFO BlockManagerInfo: Added input-0-1421837511800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:46 INFO BlockManagerInfo: Added input-0-1421837511800 in memory on sh-demo-hadoop-02:35432 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:48 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:48 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:48 INFO BlockManagerInfo: Added input-0-1421837513800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:48 INFO BlockManagerInfo: Added input-0-1421837513800 in memory on sh-demo-hadoop-08:59231 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:50 INFO JobScheduler: Added jobs for time 1421837510000 ms
15/01/21 18:51:50 INFO JobScheduler: Starting job streaming job 1421837510000 ms.0 from job set of time 1421837510000 ms
15/01/21 18:51:50 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:50 INFO DAGScheduler: Got job 16 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:50 INFO DAGScheduler: Final stage: Stage 17(runJob at PythonRDD.scala:344)
15/01/21 18:51:50 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:50 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:50 INFO DAGScheduler: Submitting Stage 17 (PythonRDD[40] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:50 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=137560, maxMem=278302556
15/01/21 18:51:50 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:50 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=140880, maxMem=278302556
15/01/21 18:51:50 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:50 INFO BlockManagerMaster: Updated info of block broadcast_17_piece0
15/01/21 18:51:50 INFO SparkContext: Created broadcast 17 from getCallSite at DStream.scala:294
15/01/21 18:51:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 17 (PythonRDD[40] at RDD at PythonRDD.scala:43)
15/01/21 18:51:50 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
15/01/21 18:51:50 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 86, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:50 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 86) in 90 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:50 INFO DAGScheduler: Stage 17 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:51:50 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
15/01/21 18:51:50 INFO DAGScheduler: Job 16 finished: runJob at PythonRDD.scala:344, took 0.103444 s
15/01/21 18:51:50 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:50 INFO DAGScheduler: Got job 17 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:50 INFO DAGScheduler: Final stage: Stage 18(runJob at PythonRDD.scala:344)
15/01/21 18:51:50 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:50 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:50 INFO DAGScheduler: Submitting Stage 18 (PythonRDD[41] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:50 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=143371, maxMem=278302556
15/01/21 18:51:50 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:50 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=146691, maxMem=278302556
15/01/21 18:51:50 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.4 MB)
15/01/21 18:51:50 INFO BlockManagerMaster: Updated info of block broadcast_18_piece0
15/01/21 18:51:50 INFO SparkContext: Created broadcast 18 from getCallSite at DStream.scala:294
15/01/21 18:51:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 18 (PythonRDD[41] at RDD at PythonRDD.scala:43)
15/01/21 18:51:50 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
15/01/21 18:51:50 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 87, sh-demo-hadoop-08, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on sh-demo-hadoop-08:59231 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:50 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:50 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:50 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 87) in 774 ms on sh-demo-hadoop-08 (1/1)
15/01/21 18:51:50 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
15/01/21 18:51:50 INFO DAGScheduler: Stage 18 (runJob at PythonRDD.scala:344) finished in 0.775 s
15/01/21 18:51:50 INFO DAGScheduler: Job 17 finished: runJob at PythonRDD.scala:344, took 0.806167 s
15/01/21 18:51:50 INFO JobScheduler: Finished job streaming job 1421837510000 ms.0 from job set of time 1421837510000 ms
15/01/21 18:51:50 INFO JobScheduler: Total delay: 0.938 s for time 1421837510000 ms (execution: 0.936 s)
15/01/21 18:51:50 INFO BlockRDD: Removing RDD 36 from persistence list
15/01/21 18:51:50 INFO BlockManager: Removing RDD 36
15/01/21 18:51:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[36] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837510000 ms
15/01/21 18:51:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837500000 ms)
15/01/21 18:51:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837505800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837505800 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837507800 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837509800 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837507800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Removed input-0-1421837509800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Added input-0-1421837516000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:50 INFO BlockManagerInfo: Added input-0-1421837516000 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:52 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:52 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:52 INFO BlockManagerInfo: Added input-0-1421837518000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:52 INFO BlockManagerInfo: Added input-0-1421837518000 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:54 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:54 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:54 INFO BlockManagerInfo: Added input-0-1421837520000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:54 INFO BlockManagerInfo: Added input-0-1421837520000 in memory on sh-demo-hadoop-04:38128 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:55 INFO JobScheduler: Added jobs for time 1421837515000 ms
15/01/21 18:51:55 INFO JobScheduler: Starting job streaming job 1421837515000 ms.0 from job set of time 1421837515000 ms
15/01/21 18:51:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:55 INFO DAGScheduler: Got job 18 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:51:55 INFO DAGScheduler: Final stage: Stage 19(runJob at PythonRDD.scala:344)
15/01/21 18:51:55 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:55 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:55 INFO DAGScheduler: Submitting Stage 19 (PythonRDD[43] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:55 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=149182, maxMem=278302556
15/01/21 18:51:55 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:55 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=152502, maxMem=278302556
15/01/21 18:51:55 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:51:55 INFO BlockManagerMaster: Updated info of block broadcast_19_piece0
15/01/21 18:51:55 INFO SparkContext: Created broadcast 19 from getCallSite at DStream.scala:294
15/01/21 18:51:55 INFO DAGScheduler: Submitting 1 missing tasks from Stage 19 (PythonRDD[43] at RDD at PythonRDD.scala:43)
15/01/21 18:51:55 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
15/01/21 18:51:55 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 88, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:55 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 88) in 90 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:51:55 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
15/01/21 18:51:55 INFO DAGScheduler: Stage 19 (runJob at PythonRDD.scala:344) finished in 0.093 s
15/01/21 18:51:55 INFO DAGScheduler: Job 18 finished: runJob at PythonRDD.scala:344, took 0.100860 s
15/01/21 18:51:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:51:55 INFO DAGScheduler: Got job 19 (runJob at PythonRDD.scala:344) with 2 output partitions (allowLocal=true)
15/01/21 18:51:55 INFO DAGScheduler: Final stage: Stage 20(runJob at PythonRDD.scala:344)
15/01/21 18:51:55 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:51:55 INFO DAGScheduler: Missing parents: List()
15/01/21 18:51:55 INFO DAGScheduler: Submitting Stage 20 (PythonRDD[44] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:51:55 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=154993, maxMem=278302556
15/01/21 18:51:55 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:51:55 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=158313, maxMem=278302556
15/01/21 18:51:55 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:51:55 INFO BlockManagerMaster: Updated info of block broadcast_20_piece0
15/01/21 18:51:55 INFO SparkContext: Created broadcast 20 from getCallSite at DStream.scala:294
15/01/21 18:51:55 INFO DAGScheduler: Submitting 2 missing tasks from Stage 20 (PythonRDD[44] at RDD at PythonRDD.scala:43)
15/01/21 18:51:55 INFO TaskSchedulerImpl: Adding task set 20.0 with 2 tasks
15/01/21 18:51:55 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 89, sh-demo-hadoop-09, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:55 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 90, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on sh-demo-hadoop-09:54385 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:51:55 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 89) in 77 ms on sh-demo-hadoop-09 (1/2)
15/01/21 18:51:55 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 90) in 89 ms on sh-demo-hadoop-10 (2/2)
15/01/21 18:51:55 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
15/01/21 18:51:55 INFO DAGScheduler: Stage 20 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:51:55 INFO DAGScheduler: Job 19 finished: runJob at PythonRDD.scala:344, took 0.100986 s
15/01/21 18:51:55 INFO JobScheduler: Finished job streaming job 1421837515000 ms.0 from job set of time 1421837515000 ms
15/01/21 18:51:55 INFO BlockRDD: Removing RDD 39 from persistence list
15/01/21 18:51:55 INFO JobScheduler: Total delay: 0.225 s for time 1421837515000 ms (execution: 0.224 s)
15/01/21 18:51:55 INFO BlockManager: Removing RDD 39
15/01/21 18:51:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[39] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837515000 ms
15/01/21 18:51:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837505000 ms)
15/01/21 18:51:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:51:55 INFO BlockManagerInfo: Removed input-0-1421837511800 on sh-demo-hadoop-02:35432 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Removed input-0-1421837511800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Removed input-0-1421837513800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:55 INFO BlockManagerInfo: Removed input-0-1421837513800 on sh-demo-hadoop-08:59231 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:56 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:56 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:56 INFO BlockManagerInfo: Added input-0-1421837522000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:56 INFO BlockManagerInfo: Added input-0-1421837522000 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:51:58 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:51:58 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:51:59 INFO BlockManagerInfo: Added input-0-1421837524200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:51:59 INFO BlockManagerInfo: Added input-0-1421837524200 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:00 INFO JobScheduler: Added jobs for time 1421837520000 ms
15/01/21 18:52:00 INFO JobScheduler: Starting job streaming job 1421837520000 ms.0 from job set of time 1421837520000 ms
15/01/21 18:52:00 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:00 INFO DAGScheduler: Got job 20 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:00 INFO DAGScheduler: Final stage: Stage 21(runJob at PythonRDD.scala:344)
15/01/21 18:52:00 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:00 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:00 INFO DAGScheduler: Submitting Stage 21 (PythonRDD[46] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:00 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=160804, maxMem=278302556
15/01/21 18:52:00 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.2 KB, free 265.3 MB)
15/01/21 18:52:00 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=164124, maxMem=278302556
15/01/21 18:52:00 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.3 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:00 INFO BlockManagerMaster: Updated info of block broadcast_21_piece0
15/01/21 18:52:00 INFO SparkContext: Created broadcast 21 from getCallSite at DStream.scala:294
15/01/21 18:52:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 21 (PythonRDD[46] at RDD at PythonRDD.scala:43)
15/01/21 18:52:00 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
15/01/21 18:52:00 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 91, sh-demo-hadoop-07, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:00 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on sh-demo-hadoop-07:57986 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:52:00 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 91) in 186 ms on sh-demo-hadoop-07 (1/1)
15/01/21 18:52:00 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
15/01/21 18:52:00 INFO DAGScheduler: Stage 21 (runJob at PythonRDD.scala:344) finished in 0.189 s
15/01/21 18:52:00 INFO DAGScheduler: Job 20 finished: runJob at PythonRDD.scala:344, took 0.196594 s
15/01/21 18:52:00 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:00 INFO DAGScheduler: Got job 21 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:00 INFO DAGScheduler: Final stage: Stage 22(runJob at PythonRDD.scala:344)
15/01/21 18:52:00 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:00 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:00 INFO DAGScheduler: Submitting Stage 22 (PythonRDD[47] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:00 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=166615, maxMem=278302556
15/01/21 18:52:00 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:00 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=169935, maxMem=278302556
15/01/21 18:52:00 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:00 INFO BlockManagerMaster: Updated info of block broadcast_22_piece0
15/01/21 18:52:00 INFO SparkContext: Created broadcast 22 from getCallSite at DStream.scala:294
15/01/21 18:52:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 22 (PythonRDD[47] at RDD at PythonRDD.scala:43)
15/01/21 18:52:00 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
15/01/21 18:52:00 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 92, sh-demo-hadoop-09, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:00 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on sh-demo-hadoop-09:54385 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:52:00 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 92) in 75 ms on sh-demo-hadoop-09 (1/1)
15/01/21 18:52:00 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
15/01/21 18:52:00 INFO DAGScheduler: Stage 22 (runJob at PythonRDD.scala:344) finished in 0.076 s
15/01/21 18:52:00 INFO DAGScheduler: Job 21 finished: runJob at PythonRDD.scala:344, took 0.083436 s
15/01/21 18:52:00 INFO JobScheduler: Finished job streaming job 1421837520000 ms.0 from job set of time 1421837520000 ms
15/01/21 18:52:00 INFO BlockRDD: Removing RDD 42 from persistence list
15/01/21 18:52:00 INFO BlockManager: Removing RDD 42
15/01/21 18:52:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[42] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837520000 ms
15/01/21 18:52:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837510000 ms)
15/01/21 18:52:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:00 INFO JobScheduler: Total delay: 0.305 s for time 1421837520000 ms (execution: 0.304 s)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837518000 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837516000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837520000 on sh-demo-hadoop-04:38128 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837518000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837520000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:00 INFO BlockManagerInfo: Removed input-0-1421837516000 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:00 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:01 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:01 INFO BlockManagerInfo: Added input-0-1421837526200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:01 INFO BlockManagerInfo: Added input-0-1421837526200 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:03 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:03 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:03 INFO BlockManagerInfo: Added input-0-1421837528200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:03 INFO BlockManagerInfo: Added input-0-1421837528200 in memory on sh-demo-hadoop-04:38128 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:05 INFO JobScheduler: Added jobs for time 1421837525000 ms
15/01/21 18:52:05 INFO JobScheduler: Starting job streaming job 1421837525000 ms.0 from job set of time 1421837525000 ms
15/01/21 18:52:05 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:05 INFO DAGScheduler: Got job 22 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:05 INFO DAGScheduler: Final stage: Stage 23(runJob at PythonRDD.scala:344)
15/01/21 18:52:05 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:05 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:05 INFO DAGScheduler: Submitting Stage 23 (PythonRDD[49] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:05 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=172426, maxMem=278302556
15/01/21 18:52:05 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:05 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=175746, maxMem=278302556
15/01/21 18:52:05 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:05 INFO BlockManagerMaster: Updated info of block broadcast_23_piece0
15/01/21 18:52:05 INFO SparkContext: Created broadcast 23 from getCallSite at DStream.scala:294
15/01/21 18:52:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 23 (PythonRDD[49] at RDD at PythonRDD.scala:43)
15/01/21 18:52:05 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
15/01/21 18:52:05 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 93, sh-demo-hadoop-07, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:05 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:05 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on sh-demo-hadoop-07:57986 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:52:05 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:05 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 93) in 136 ms on sh-demo-hadoop-07 (1/1)
15/01/21 18:52:05 INFO DAGScheduler: Stage 23 (runJob at PythonRDD.scala:344) finished in 0.137 s
15/01/21 18:52:05 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
15/01/21 18:52:05 INFO DAGScheduler: Job 22 finished: runJob at PythonRDD.scala:344, took 0.145818 s
15/01/21 18:52:05 INFO BlockManagerInfo: Added input-0-1421837530200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:05 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:05 INFO DAGScheduler: Got job 23 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:05 INFO DAGScheduler: Final stage: Stage 24(runJob at PythonRDD.scala:344)
15/01/21 18:52:05 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:05 INFO BlockManagerInfo: Added input-0-1421837530200 in memory on sh-demo-hadoop-09:54385 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:05 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:05 INFO DAGScheduler: Submitting Stage 24 (PythonRDD[50] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:05 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=178237, maxMem=278302556
15/01/21 18:52:05 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:05 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=181557, maxMem=278302556
15/01/21 18:52:05 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:05 INFO BlockManagerMaster: Updated info of block broadcast_24_piece0
15/01/21 18:52:05 INFO SparkContext: Created broadcast 24 from getCallSite at DStream.scala:294
15/01/21 18:52:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 24 (PythonRDD[50] at RDD at PythonRDD.scala:43)
15/01/21 18:52:05 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
15/01/21 18:52:05 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 94, sh-demo-hadoop-04, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on sh-demo-hadoop-04:38128 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:52:05 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 94) in 93 ms on sh-demo-hadoop-04 (1/1)
15/01/21 18:52:05 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
15/01/21 18:52:05 INFO DAGScheduler: Stage 24 (runJob at PythonRDD.scala:344) finished in 0.090 s
15/01/21 18:52:05 INFO DAGScheduler: Job 23 finished: runJob at PythonRDD.scala:344, took 0.102708 s
15/01/21 18:52:05 INFO JobScheduler: Finished job streaming job 1421837525000 ms.0 from job set of time 1421837525000 ms
15/01/21 18:52:05 INFO BlockRDD: Removing RDD 45 from persistence list
15/01/21 18:52:05 INFO JobScheduler: Total delay: 0.276 s for time 1421837525000 ms (execution: 0.275 s)
15/01/21 18:52:05 INFO BlockManager: Removing RDD 45
15/01/21 18:52:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[45] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837525000 ms
15/01/21 18:52:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837515000 ms)
15/01/21 18:52:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:05 INFO BlockManagerInfo: Removed input-0-1421837522000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Removed input-0-1421837524200 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Removed input-0-1421837524200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:05 INFO BlockManagerInfo: Removed input-0-1421837522000 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:07 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:07 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:09 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:09 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:10 INFO JobScheduler: Added jobs for time 1421837530000 ms
15/01/21 18:52:10 INFO JobScheduler: Starting job streaming job 1421837530000 ms.0 from job set of time 1421837530000 ms
15/01/21 18:52:10 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:10 INFO DAGScheduler: Got job 24 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:10 INFO DAGScheduler: Final stage: Stage 25(runJob at PythonRDD.scala:344)
15/01/21 18:52:10 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:10 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:10 INFO DAGScheduler: Submitting Stage 25 (PythonRDD[52] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:10 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=184048, maxMem=278302556
15/01/21 18:52:10 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:10 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=187368, maxMem=278302556
15/01/21 18:52:10 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:10 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:10 INFO BlockManagerMaster: Updated info of block broadcast_25_piece0
15/01/21 18:52:10 INFO SparkContext: Created broadcast 25 from getCallSite at DStream.scala:294
15/01/21 18:52:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 25 (PythonRDD[52] at RDD at PythonRDD.scala:43)
15/01/21 18:52:10 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
15/01/21 18:52:10 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 95, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:10 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:52:10 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 95) in 90 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:52:10 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
15/01/21 18:52:10 INFO DAGScheduler: Stage 25 (runJob at PythonRDD.scala:344) finished in 0.093 s
15/01/21 18:52:10 INFO DAGScheduler: Job 24 finished: runJob at PythonRDD.scala:344, took 0.101093 s
15/01/21 18:52:10 INFO JobScheduler: Finished job streaming job 1421837530000 ms.0 from job set of time 1421837530000 ms
15/01/21 18:52:10 INFO JobScheduler: Total delay: 0.128 s for time 1421837530000 ms (execution: 0.127 s)
15/01/21 18:52:10 INFO BlockRDD: Removing RDD 48 from persistence list
15/01/21 18:52:10 INFO BlockManager: Removing RDD 48
15/01/21 18:52:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[48] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837530000 ms
15/01/21 18:52:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837520000 ms)
15/01/21 18:52:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:10 INFO BlockManagerInfo: Removed input-0-1421837526200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:10 INFO BlockManagerInfo: Removed input-0-1421837528200 on sh-demo-hadoop-04:38128 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:10 INFO BlockManagerInfo: Removed input-0-1421837528200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:10 INFO BlockManagerInfo: Removed input-0-1421837526200 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:11 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:11 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:13 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:15 INFO JobScheduler: Added jobs for time 1421837535000 ms
15/01/21 18:52:15 INFO JobScheduler: Starting job streaming job 1421837535000 ms.0 from job set of time 1421837535000 ms
15/01/21 18:52:15 INFO JobScheduler: Finished job streaming job 1421837535000 ms.0 from job set of time 1421837535000 ms
15/01/21 18:52:15 INFO JobScheduler: Total delay: 0.004 s for time 1421837535000 ms (execution: 0.003 s)
15/01/21 18:52:15 INFO BlockRDD: Removing RDD 51 from persistence list
15/01/21 18:52:15 INFO BlockManager: Removing RDD 51
15/01/21 18:52:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[51] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837535000 ms
15/01/21 18:52:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837525000 ms)
15/01/21 18:52:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:15 INFO BlockManagerInfo: Removed input-0-1421837530200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:15 INFO BlockManagerInfo: Removed input-0-1421837530200 on sh-demo-hadoop-09:54385 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:15 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:17 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:19 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:20 INFO JobScheduler: Added jobs for time 1421837540000 ms
15/01/21 18:52:20 INFO JobScheduler: Starting job streaming job 1421837540000 ms.0 from job set of time 1421837540000 ms
15/01/21 18:52:20 INFO JobScheduler: Finished job streaming job 1421837540000 ms.0 from job set of time 1421837540000 ms
15/01/21 18:52:20 INFO JobScheduler: Total delay: 0.004 s for time 1421837540000 ms (execution: 0.003 s)
15/01/21 18:52:20 INFO BlockRDD: Removing RDD 53 from persistence list
15/01/21 18:52:20 INFO BlockManager: Removing RDD 53
15/01/21 18:52:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[53] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837540000 ms
15/01/21 18:52:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837530000 ms)
15/01/21 18:52:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:21 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:23 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:25 INFO JobScheduler: Added jobs for time 1421837545000 ms
15/01/21 18:52:25 INFO JobScheduler: Starting job streaming job 1421837545000 ms.0 from job set of time 1421837545000 ms
15/01/21 18:52:25 INFO JobScheduler: Finished job streaming job 1421837545000 ms.0 from job set of time 1421837545000 ms
15/01/21 18:52:25 INFO JobScheduler: Total delay: 0.003 s for time 1421837545000 ms (execution: 0.003 s)
15/01/21 18:52:25 INFO BlockRDD: Removing RDD 54 from persistence list
15/01/21 18:52:25 INFO BlockManager: Removing RDD 54
15/01/21 18:52:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[54] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837545000 ms
15/01/21 18:52:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837535000 ms)
15/01/21 18:52:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:25 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:27 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:29 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:30 INFO JobScheduler: Added jobs for time 1421837550000 ms
15/01/21 18:52:30 INFO JobScheduler: Starting job streaming job 1421837550000 ms.0 from job set of time 1421837550000 ms
15/01/21 18:52:30 INFO JobScheduler: Finished job streaming job 1421837550000 ms.0 from job set of time 1421837550000 ms
15/01/21 18:52:30 INFO JobScheduler: Total delay: 0.003 s for time 1421837550000 ms (execution: 0.002 s)
15/01/21 18:52:30 INFO BlockRDD: Removing RDD 55 from persistence list
15/01/21 18:52:30 INFO BlockManager: Removing RDD 55
15/01/21 18:52:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[55] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837550000 ms
15/01/21 18:52:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837540000 ms)
15/01/21 18:52:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:31 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:33 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:35 INFO JobScheduler: Added jobs for time 1421837555000 ms
15/01/21 18:52:35 INFO JobScheduler: Starting job streaming job 1421837555000 ms.0 from job set of time 1421837555000 ms
15/01/21 18:52:35 INFO JobScheduler: Finished job streaming job 1421837555000 ms.0 from job set of time 1421837555000 ms
15/01/21 18:52:35 INFO JobScheduler: Total delay: 0.004 s for time 1421837555000 ms (execution: 0.003 s)
15/01/21 18:52:35 INFO BlockRDD: Removing RDD 56 from persistence list
15/01/21 18:52:35 INFO BlockManager: Removing RDD 56
15/01/21 18:52:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[56] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837555000 ms
15/01/21 18:52:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837545000 ms)
15/01/21 18:52:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:35 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:37 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:39 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:40 INFO JobScheduler: Added jobs for time 1421837560000 ms
15/01/21 18:52:40 INFO JobScheduler: Starting job streaming job 1421837560000 ms.0 from job set of time 1421837560000 ms
15/01/21 18:52:40 INFO JobScheduler: Finished job streaming job 1421837560000 ms.0 from job set of time 1421837560000 ms
15/01/21 18:52:40 INFO JobScheduler: Total delay: 0.003 s for time 1421837560000 ms (execution: 0.003 s)
15/01/21 18:52:40 INFO BlockRDD: Removing RDD 57 from persistence list
15/01/21 18:52:40 INFO BlockManager: Removing RDD 57
15/01/21 18:52:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[57] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837560000 ms
15/01/21 18:52:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837550000 ms)
15/01/21 18:52:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:41 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:41 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:43 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:43 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:45 INFO JobScheduler: Added jobs for time 1421837565000 ms
15/01/21 18:52:45 INFO JobScheduler: Starting job streaming job 1421837565000 ms.0 from job set of time 1421837565000 ms
15/01/21 18:52:45 INFO JobScheduler: Finished job streaming job 1421837565000 ms.0 from job set of time 1421837565000 ms
15/01/21 18:52:45 INFO JobScheduler: Total delay: 0.004 s for time 1421837565000 ms (execution: 0.003 s)
15/01/21 18:52:45 INFO BlockRDD: Removing RDD 58 from persistence list
15/01/21 18:52:45 INFO BlockManager: Removing RDD 58
15/01/21 18:52:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[58] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837565000 ms
15/01/21 18:52:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837555000 ms)
15/01/21 18:52:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:45 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:45 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:47 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:47 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:49 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:49 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:50 INFO JobScheduler: Added jobs for time 1421837570000 ms
15/01/21 18:52:50 INFO JobScheduler: Starting job streaming job 1421837570000 ms.0 from job set of time 1421837570000 ms
15/01/21 18:52:50 INFO JobScheduler: Finished job streaming job 1421837570000 ms.0 from job set of time 1421837570000 ms
15/01/21 18:52:50 INFO JobScheduler: Total delay: 0.004 s for time 1421837570000 ms (execution: 0.003 s)
15/01/21 18:52:50 INFO BlockRDD: Removing RDD 59 from persistence list
15/01/21 18:52:50 INFO BlockManager: Removing RDD 59
15/01/21 18:52:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[59] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837570000 ms
15/01/21 18:52:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837560000 ms)
15/01/21 18:52:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:51 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:51 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:53 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:53 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:53 INFO BlockManagerInfo: Added input-0-1421837578600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:52:53 INFO BlockManagerInfo: Added input-0-1421837578600 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:52:55 INFO JobScheduler: Added jobs for time 1421837575000 ms
15/01/21 18:52:55 INFO JobScheduler: Starting job streaming job 1421837575000 ms.0 from job set of time 1421837575000 ms
15/01/21 18:52:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:52:55 INFO DAGScheduler: Got job 25 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:52:55 INFO DAGScheduler: Final stage: Stage 26(runJob at PythonRDD.scala:344)
15/01/21 18:52:55 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:52:55 INFO DAGScheduler: Missing parents: List()
15/01/21 18:52:55 INFO DAGScheduler: Submitting Stage 26 (PythonRDD[62] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:52:55 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=189859, maxMem=278302556
15/01/21 18:52:55 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:52:55 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=193179, maxMem=278302556
15/01/21 18:52:55 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:52:55 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:52:55 INFO BlockManagerMaster: Updated info of block broadcast_26_piece0
15/01/21 18:52:55 INFO SparkContext: Created broadcast 26 from getCallSite at DStream.scala:294
15/01/21 18:52:55 INFO DAGScheduler: Submitting 1 missing tasks from Stage 26 (PythonRDD[62] at RDD at PythonRDD.scala:43)
15/01/21 18:52:55 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
15/01/21 18:52:55 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 96, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:52:55 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:52:55 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 96) in 90 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:52:55 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
15/01/21 18:52:55 INFO DAGScheduler: Stage 26 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:52:55 INFO DAGScheduler: Job 25 finished: runJob at PythonRDD.scala:344, took 0.099414 s
15/01/21 18:52:55 INFO JobScheduler: Finished job streaming job 1421837575000 ms.0 from job set of time 1421837575000 ms
15/01/21 18:52:55 INFO JobScheduler: Total delay: 0.113 s for time 1421837575000 ms (execution: 0.112 s)
15/01/21 18:52:55 INFO BlockRDD: Removing RDD 60 from persistence list
15/01/21 18:52:55 INFO BlockManager: Removing RDD 60
15/01/21 18:52:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[60] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837575000 ms
15/01/21 18:52:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837565000 ms)
15/01/21 18:52:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:52:55 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:55 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:57 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:57 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:52:59 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:52:59 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:00 INFO JobScheduler: Added jobs for time 1421837580000 ms
15/01/21 18:53:00 INFO JobScheduler: Starting job streaming job 1421837580000 ms.0 from job set of time 1421837580000 ms
15/01/21 18:53:00 INFO JobScheduler: Finished job streaming job 1421837580000 ms.0 from job set of time 1421837580000 ms
15/01/21 18:53:00 INFO JobScheduler: Total delay: 0.005 s for time 1421837580000 ms (execution: 0.004 s)
15/01/21 18:53:00 INFO BlockRDD: Removing RDD 61 from persistence list
15/01/21 18:53:00 INFO BlockManager: Removing RDD 61
15/01/21 18:53:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[61] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837580000 ms
15/01/21 18:53:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837570000 ms)
15/01/21 18:53:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:00 INFO BlockManagerInfo: Removed input-0-1421837578600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:00 INFO BlockManagerInfo: Removed input-0-1421837578600 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:01 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:01 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:03 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:03 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:05 INFO JobScheduler: Added jobs for time 1421837585000 ms
15/01/21 18:53:05 INFO JobScheduler: Starting job streaming job 1421837585000 ms.0 from job set of time 1421837585000 ms
15/01/21 18:53:05 INFO JobScheduler: Finished job streaming job 1421837585000 ms.0 from job set of time 1421837585000 ms
15/01/21 18:53:05 INFO JobScheduler: Total delay: 0.004 s for time 1421837585000 ms (execution: 0.003 s)
15/01/21 18:53:05 INFO BlockRDD: Removing RDD 63 from persistence list
15/01/21 18:53:05 INFO BlockManager: Removing RDD 63
15/01/21 18:53:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[63] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837585000 ms
15/01/21 18:53:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837575000 ms)
15/01/21 18:53:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:05 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:05 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:07 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:07 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:09 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:09 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:09 INFO BlockManagerInfo: Added input-0-1421837594800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:09 INFO BlockManagerInfo: Added input-0-1421837594800 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:10 INFO JobScheduler: Added jobs for time 1421837590000 ms
15/01/21 18:53:10 INFO JobScheduler: Starting job streaming job 1421837590000 ms.0 from job set of time 1421837590000 ms
15/01/21 18:53:10 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:10 INFO DAGScheduler: Got job 26 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:10 INFO DAGScheduler: Final stage: Stage 27(runJob at PythonRDD.scala:344)
15/01/21 18:53:10 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:10 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:10 INFO DAGScheduler: Submitting Stage 27 (PythonRDD[66] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:10 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=195670, maxMem=278302556
15/01/21 18:53:10 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:10 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=198990, maxMem=278302556
15/01/21 18:53:10 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:10 INFO BlockManagerMaster: Updated info of block broadcast_27_piece0
15/01/21 18:53:10 INFO SparkContext: Created broadcast 27 from getCallSite at DStream.scala:294
15/01/21 18:53:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 27 (PythonRDD[66] at RDD at PythonRDD.scala:43)
15/01/21 18:53:10 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
15/01/21 18:53:10 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 97, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:53:10 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 97) in 88 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:53:10 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
15/01/21 18:53:10 INFO DAGScheduler: Stage 27 (runJob at PythonRDD.scala:344) finished in 0.090 s
15/01/21 18:53:10 INFO DAGScheduler: Job 26 finished: runJob at PythonRDD.scala:344, took 0.097075 s
15/01/21 18:53:10 INFO JobScheduler: Finished job streaming job 1421837590000 ms.0 from job set of time 1421837590000 ms
15/01/21 18:53:10 INFO JobScheduler: Total delay: 0.109 s for time 1421837590000 ms (execution: 0.108 s)
15/01/21 18:53:10 INFO BlockRDD: Removing RDD 64 from persistence list
15/01/21 18:53:10 INFO BlockManager: Removing RDD 64
15/01/21 18:53:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[64] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837590000 ms
15/01/21 18:53:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837580000 ms)
15/01/21 18:53:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:11 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:11 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:11 INFO BlockManagerInfo: Added input-0-1421837596800 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:11 INFO BlockManagerInfo: Added input-0-1421837596800 in memory on sh-demo-hadoop-04:38128 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:13 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:13 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:15 INFO JobScheduler: Added jobs for time 1421837595000 ms
15/01/21 18:53:15 INFO JobScheduler: Starting job streaming job 1421837595000 ms.0 from job set of time 1421837595000 ms
15/01/21 18:53:15 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:15 INFO DAGScheduler: Got job 27 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:15 INFO DAGScheduler: Final stage: Stage 28(runJob at PythonRDD.scala:344)
15/01/21 18:53:15 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:15 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:15 INFO DAGScheduler: Submitting Stage 28 (PythonRDD[68] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:15 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=201481, maxMem=278302556
15/01/21 18:53:15 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:15 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=204801, maxMem=278302556
15/01/21 18:53:15 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:15 INFO BlockManagerMaster: Updated info of block broadcast_28_piece0
15/01/21 18:53:15 INFO SparkContext: Created broadcast 28 from getCallSite at DStream.scala:294
15/01/21 18:53:15 INFO DAGScheduler: Submitting 1 missing tasks from Stage 28 (PythonRDD[68] at RDD at PythonRDD.scala:43)
15/01/21 18:53:15 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
15/01/21 18:53:15 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 98, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:53:15 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 98) in 91 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:53:15 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
15/01/21 18:53:15 INFO DAGScheduler: Stage 28 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:53:15 INFO DAGScheduler: Job 27 finished: runJob at PythonRDD.scala:344, took 0.101362 s
15/01/21 18:53:15 INFO JobScheduler: Finished job streaming job 1421837595000 ms.0 from job set of time 1421837595000 ms
15/01/21 18:53:15 INFO JobScheduler: Total delay: 0.125 s for time 1421837595000 ms (execution: 0.124 s)
15/01/21 18:53:15 INFO BlockRDD: Removing RDD 65 from persistence list
15/01/21 18:53:15 INFO BlockManager: Removing RDD 65
15/01/21 18:53:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[65] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837595000 ms
15/01/21 18:53:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837585000 ms)
15/01/21 18:53:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:15 INFO BlockManagerInfo: Removed input-0-1421837594800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:15 INFO BlockManagerInfo: Removed input-0-1421837594800 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:15 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:17 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:17 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:19 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:19 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:20 INFO JobScheduler: Added jobs for time 1421837600000 ms
15/01/21 18:53:20 INFO JobScheduler: Starting job streaming job 1421837600000 ms.0 from job set of time 1421837600000 ms
15/01/21 18:53:20 INFO JobScheduler: Finished job streaming job 1421837600000 ms.0 from job set of time 1421837600000 ms
15/01/21 18:53:20 INFO BlockRDD: Removing RDD 67 from persistence list
15/01/21 18:53:20 INFO JobScheduler: Total delay: 0.004 s for time 1421837600000 ms (execution: 0.003 s)
15/01/21 18:53:20 INFO BlockManager: Removing RDD 67
15/01/21 18:53:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[67] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837600000 ms
15/01/21 18:53:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837590000 ms)
15/01/21 18:53:20 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:20 INFO BlockManagerInfo: Removed input-0-1421837596800 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:20 INFO BlockManagerInfo: Removed input-0-1421837596800 on sh-demo-hadoop-04:38128 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:21 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:21 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:23 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:23 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:25 INFO JobScheduler: Added jobs for time 1421837605000 ms
15/01/21 18:53:25 INFO JobScheduler: Starting job streaming job 1421837605000 ms.0 from job set of time 1421837605000 ms
15/01/21 18:53:25 INFO JobScheduler: Finished job streaming job 1421837605000 ms.0 from job set of time 1421837605000 ms
15/01/21 18:53:25 INFO JobScheduler: Total delay: 0.003 s for time 1421837605000 ms (execution: 0.003 s)
15/01/21 18:53:25 INFO BlockRDD: Removing RDD 69 from persistence list
15/01/21 18:53:25 INFO BlockManager: Removing RDD 69
15/01/21 18:53:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[69] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837605000 ms
15/01/21 18:53:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837595000 ms)
15/01/21 18:53:25 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:25 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:25 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:27 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:27 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:27 INFO BlockManagerInfo: Added input-0-1421837613000 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:27 INFO BlockManagerInfo: Added input-0-1421837613000 in memory on sh-demo-hadoop-06:52083 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:29 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:29 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:30 INFO JobScheduler: Added jobs for time 1421837610000 ms
15/01/21 18:53:30 INFO JobScheduler: Starting job streaming job 1421837610000 ms.0 from job set of time 1421837610000 ms
15/01/21 18:53:30 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:30 INFO DAGScheduler: Got job 28 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:30 INFO DAGScheduler: Final stage: Stage 29(runJob at PythonRDD.scala:344)
15/01/21 18:53:30 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:30 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:30 INFO DAGScheduler: Submitting Stage 29 (PythonRDD[72] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:30 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=207292, maxMem=278302556
15/01/21 18:53:30 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:30 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=210612, maxMem=278302556
15/01/21 18:53:30 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:30 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:30 INFO BlockManagerMaster: Updated info of block broadcast_29_piece0
15/01/21 18:53:30 INFO SparkContext: Created broadcast 29 from getCallSite at DStream.scala:294
15/01/21 18:53:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 29 (PythonRDD[72] at RDD at PythonRDD.scala:43)
15/01/21 18:53:30 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
15/01/21 18:53:30 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 99, sh-demo-hadoop-06, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:30 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on sh-demo-hadoop-06:52083 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:53:30 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 99) in 63 ms on sh-demo-hadoop-06 (1/1)
15/01/21 18:53:30 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
15/01/21 18:53:30 INFO DAGScheduler: Stage 29 (runJob at PythonRDD.scala:344) finished in 0.065 s
15/01/21 18:53:30 INFO DAGScheduler: Job 28 finished: runJob at PythonRDD.scala:344, took 0.072853 s
15/01/21 18:53:30 INFO JobScheduler: Finished job streaming job 1421837610000 ms.0 from job set of time 1421837610000 ms
15/01/21 18:53:30 INFO JobScheduler: Total delay: 0.087 s for time 1421837610000 ms (execution: 0.086 s)
15/01/21 18:53:30 INFO BlockRDD: Removing RDD 70 from persistence list
15/01/21 18:53:30 INFO BlockManager: Removing RDD 70
15/01/21 18:53:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[70] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837610000 ms
15/01/21 18:53:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837600000 ms)
15/01/21 18:53:30 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:31 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:31 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:33 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:33 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:35 INFO JobScheduler: Added jobs for time 1421837615000 ms
15/01/21 18:53:35 INFO JobScheduler: Starting job streaming job 1421837615000 ms.0 from job set of time 1421837615000 ms
15/01/21 18:53:35 INFO JobScheduler: Finished job streaming job 1421837615000 ms.0 from job set of time 1421837615000 ms
15/01/21 18:53:35 INFO JobScheduler: Total delay: 0.005 s for time 1421837615000 ms (execution: 0.004 s)
15/01/21 18:53:35 INFO BlockRDD: Removing RDD 71 from persistence list
15/01/21 18:53:35 INFO BlockManager: Removing RDD 71
15/01/21 18:53:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[71] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837615000 ms
15/01/21 18:53:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837605000 ms)
15/01/21 18:53:35 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:35 INFO BlockManagerInfo: Removed input-0-1421837613000 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:35 INFO BlockManagerInfo: Removed input-0-1421837613000 on sh-demo-hadoop-06:52083 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:35 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:35 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:37 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:37 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:39 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:39 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:40 INFO JobScheduler: Added jobs for time 1421837620000 ms
15/01/21 18:53:40 INFO JobScheduler: Starting job streaming job 1421837620000 ms.0 from job set of time 1421837620000 ms
15/01/21 18:53:40 INFO JobScheduler: Finished job streaming job 1421837620000 ms.0 from job set of time 1421837620000 ms
15/01/21 18:53:40 INFO JobScheduler: Total delay: 0.003 s for time 1421837620000 ms (execution: 0.002 s)
15/01/21 18:53:40 INFO BlockRDD: Removing RDD 73 from persistence list
15/01/21 18:53:40 INFO BlockManager: Removing RDD 73
15/01/21 18:53:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[73] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837620000 ms
15/01/21 18:53:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837610000 ms)
15/01/21 18:53:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:40 INFO BlockManagerInfo: Added input-0-1421837625200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:40 INFO BlockManagerInfo: Added input-0-1421837625200 in memory on sh-demo-hadoop-07:57986 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:41 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:42 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:42 INFO BlockManagerInfo: Added input-0-1421837627200 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:42 INFO BlockManagerInfo: Added input-0-1421837627200 in memory on sh-demo-hadoop-02:35432 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:44 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:44 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:45 INFO JobScheduler: Added jobs for time 1421837625000 ms
15/01/21 18:53:45 INFO JobScheduler: Starting job streaming job 1421837625000 ms.0 from job set of time 1421837625000 ms
15/01/21 18:53:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:45 INFO DAGScheduler: Got job 29 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:45 INFO DAGScheduler: Final stage: Stage 30(runJob at PythonRDD.scala:344)
15/01/21 18:53:45 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:45 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:45 INFO DAGScheduler: Submitting Stage 30 (PythonRDD[76] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:45 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=213103, maxMem=278302556
15/01/21 18:53:45 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:45 INFO MemoryStore: ensureFreeSpace(2493) called with curMem=216423, maxMem=278302556
15/01/21 18:53:45 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:45 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:45 INFO BlockManagerMaster: Updated info of block broadcast_30_piece0
15/01/21 18:53:45 INFO SparkContext: Created broadcast 30 from getCallSite at DStream.scala:294
15/01/21 18:53:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 30 (PythonRDD[76] at RDD at PythonRDD.scala:43)
15/01/21 18:53:45 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
15/01/21 18:53:45 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 100, sh-demo-hadoop-07, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:45 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on sh-demo-hadoop-07:57986 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:53:45 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 100) in 68 ms on sh-demo-hadoop-07 (1/1)
15/01/21 18:53:45 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
15/01/21 18:53:45 INFO DAGScheduler: Stage 30 (runJob at PythonRDD.scala:344) finished in 0.069 s
15/01/21 18:53:45 INFO DAGScheduler: Job 29 finished: runJob at PythonRDD.scala:344, took 0.077359 s
15/01/21 18:53:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:45 INFO DAGScheduler: Got job 30 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:45 INFO DAGScheduler: Final stage: Stage 31(runJob at PythonRDD.scala:344)
15/01/21 18:53:45 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:45 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:45 INFO DAGScheduler: Submitting Stage 31 (PythonRDD[77] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:45 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=218916, maxMem=278302556
15/01/21 18:53:45 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:45 INFO MemoryStore: ensureFreeSpace(2493) called with curMem=222236, maxMem=278302556
15/01/21 18:53:45 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:45 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:45 INFO BlockManagerMaster: Updated info of block broadcast_31_piece0
15/01/21 18:53:45 INFO SparkContext: Created broadcast 31 from getCallSite at DStream.scala:294
15/01/21 18:53:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 31 (PythonRDD[77] at RDD at PythonRDD.scala:43)
15/01/21 18:53:45 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
15/01/21 18:53:45 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 101, sh-demo-hadoop-10, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:45 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on sh-demo-hadoop-10:56623 (size: 2.4 KB, free: 264.9 MB)
15/01/21 18:53:45 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 101) in 92 ms on sh-demo-hadoop-10 (1/1)
15/01/21 18:53:45 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
15/01/21 18:53:45 INFO DAGScheduler: Stage 31 (runJob at PythonRDD.scala:344) finished in 0.092 s
15/01/21 18:53:45 INFO DAGScheduler: Job 30 finished: runJob at PythonRDD.scala:344, took 0.107191 s
15/01/21 18:53:45 INFO JobScheduler: Finished job streaming job 1421837625000 ms.0 from job set of time 1421837625000 ms
15/01/21 18:53:45 INFO JobScheduler: Total delay: 0.208 s for time 1421837625000 ms (execution: 0.207 s)
15/01/21 18:53:45 INFO BlockRDD: Removing RDD 74 from persistence list
15/01/21 18:53:45 INFO BlockManager: Removing RDD 74
15/01/21 18:53:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[74] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837625000 ms
15/01/21 18:53:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837615000 ms)
15/01/21 18:53:45 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:46 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:46 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:48 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:48 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:50 INFO JobScheduler: Added jobs for time 1421837630000 ms
15/01/21 18:53:50 INFO JobScheduler: Starting job streaming job 1421837630000 ms.0 from job set of time 1421837630000 ms
15/01/21 18:53:50 INFO JobScheduler: Finished job streaming job 1421837630000 ms.0 from job set of time 1421837630000 ms
15/01/21 18:53:50 INFO JobScheduler: Total delay: 0.003 s for time 1421837630000 ms (execution: 0.003 s)
15/01/21 18:53:50 INFO BlockRDD: Removing RDD 75 from persistence list
15/01/21 18:53:50 INFO BlockManager: Removing RDD 75
15/01/21 18:53:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[75] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837630000 ms
15/01/21 18:53:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837620000 ms)
15/01/21 18:53:50 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:50 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:50 INFO BlockManagerInfo: Removed input-0-1421837625200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:50 INFO BlockManagerInfo: Removed input-0-1421837627200 on sh-demo-hadoop-02:35432 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:50 INFO BlockManagerInfo: Removed input-0-1421837625200 on sh-demo-hadoop-07:57986 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:50 INFO BlockManagerInfo: Removed input-0-1421837627200 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:50 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:52 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:52 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:54 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:54 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:54 INFO BlockManagerInfo: Added input-0-1421837639600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:54 INFO BlockManagerInfo: Added input-0-1421837639600 in memory on sh-demo-hadoop-05:59361 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:55 INFO JobScheduler: Added jobs for time 1421837635000 ms
15/01/21 18:53:55 INFO JobScheduler: Starting job streaming job 1421837635000 ms.0 from job set of time 1421837635000 ms
15/01/21 18:53:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:53:55 INFO DAGScheduler: Got job 31 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:53:55 INFO DAGScheduler: Final stage: Stage 32(runJob at PythonRDD.scala:344)
15/01/21 18:53:55 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:53:55 INFO DAGScheduler: Missing parents: List()
15/01/21 18:53:55 INFO DAGScheduler: Submitting Stage 32 (PythonRDD[80] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:53:55 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=224729, maxMem=278302556
15/01/21 18:53:55 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:53:55 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=228049, maxMem=278302556
15/01/21 18:53:55 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:53:55 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:53:55 INFO BlockManagerMaster: Updated info of block broadcast_32_piece0
15/01/21 18:53:55 INFO SparkContext: Created broadcast 32 from getCallSite at DStream.scala:294
15/01/21 18:53:55 INFO DAGScheduler: Submitting 1 missing tasks from Stage 32 (PythonRDD[80] at RDD at PythonRDD.scala:43)
15/01/21 18:53:55 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
15/01/21 18:53:55 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 102, sh-demo-hadoop-05, NODE_LOCAL, 1236 bytes)
15/01/21 18:53:55 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on sh-demo-hadoop-05:59361 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:53:55 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 102) in 61 ms on sh-demo-hadoop-05 (1/1)
15/01/21 18:53:55 INFO DAGScheduler: Stage 32 (runJob at PythonRDD.scala:344) finished in 0.062 s
15/01/21 18:53:55 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
15/01/21 18:53:55 INFO DAGScheduler: Job 31 finished: runJob at PythonRDD.scala:344, took 0.070544 s
15/01/21 18:53:55 INFO JobScheduler: Finished job streaming job 1421837635000 ms.0 from job set of time 1421837635000 ms
15/01/21 18:53:55 INFO JobScheduler: Total delay: 0.083 s for time 1421837635000 ms (execution: 0.082 s)
15/01/21 18:53:55 INFO BlockRDD: Removing RDD 78 from persistence list
15/01/21 18:53:55 INFO BlockManager: Removing RDD 78
15/01/21 18:53:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[78] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837635000 ms
15/01/21 18:53:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837625000 ms)
15/01/21 18:53:55 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:53:56 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:56 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:53:56 INFO BlockManagerInfo: Added input-0-1421837641600 in memory on sh-demo-hadoop-10:56623 (size: 27.0 B, free: 264.9 MB)
15/01/21 18:53:56 INFO BlockManagerInfo: Added input-0-1421837641600 in memory on sh-demo-hadoop-03:44092 (size: 27.0 B, free: 265.0 MB)
15/01/21 18:53:58 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:53:58 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:00 INFO JobScheduler: Added jobs for time 1421837640000 ms
15/01/21 18:54:00 INFO JobScheduler: Starting job streaming job 1421837640000 ms.0 from job set of time 1421837640000 ms
15/01/21 18:54:00 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/21 18:54:00 INFO DAGScheduler: Got job 32 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)
15/01/21 18:54:00 INFO DAGScheduler: Final stage: Stage 33(runJob at PythonRDD.scala:344)
15/01/21 18:54:00 INFO DAGScheduler: Parents of final stage: List()
15/01/21 18:54:00 INFO DAGScheduler: Missing parents: List()
15/01/21 18:54:00 INFO DAGScheduler: Submitting Stage 33 (PythonRDD[82] at RDD at PythonRDD.scala:43), which has no missing parents
15/01/21 18:54:00 INFO MemoryStore: ensureFreeSpace(3320) called with curMem=230540, maxMem=278302556
15/01/21 18:54:00 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 3.2 KB, free 265.2 MB)
15/01/21 18:54:00 INFO MemoryStore: ensureFreeSpace(2491) called with curMem=233860, maxMem=278302556
15/01/21 18:54:00 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.4 KB, free 265.2 MB)
15/01/21 18:54:00 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.20.70.80:40067 (size: 2.4 KB, free: 265.3 MB)
15/01/21 18:54:00 INFO BlockManagerMaster: Updated info of block broadcast_33_piece0
15/01/21 18:54:00 INFO SparkContext: Created broadcast 33 from getCallSite at DStream.scala:294
15/01/21 18:54:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 33 (PythonRDD[82] at RDD at PythonRDD.scala:43)
15/01/21 18:54:00 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
15/01/21 18:54:00 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 103, sh-demo-hadoop-03, NODE_LOCAL, 1236 bytes)
15/01/21 18:54:00 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on sh-demo-hadoop-03:44092 (size: 2.4 KB, free: 265.0 MB)
15/01/21 18:54:00 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 103) in 53 ms on sh-demo-hadoop-03 (1/1)
15/01/21 18:54:00 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
15/01/21 18:54:00 INFO DAGScheduler: Stage 33 (runJob at PythonRDD.scala:344) finished in 0.054 s
15/01/21 18:54:00 INFO DAGScheduler: Job 32 finished: runJob at PythonRDD.scala:344, took 0.062056 s
15/01/21 18:54:00 INFO JobScheduler: Finished job streaming job 1421837640000 ms.0 from job set of time 1421837640000 ms
15/01/21 18:54:00 INFO JobScheduler: Total delay: 0.074 s for time 1421837640000 ms (execution: 0.073 s)
15/01/21 18:54:00 INFO BlockRDD: Removing RDD 79 from persistence list
15/01/21 18:54:00 INFO BlockManager: Removing RDD 79
15/01/21 18:54:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[79] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837640000 ms
15/01/21 18:54:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837630000 ms)
15/01/21 18:54:00 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:54:00 INFO BlockManagerInfo: Removed input-0-1421837639600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:54:00 INFO BlockManagerInfo: Removed input-0-1421837639600 on sh-demo-hadoop-05:59361 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:54:00 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:00 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:02 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:02 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:04 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:04 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:05 INFO JobScheduler: Added jobs for time 1421837645000 ms
15/01/21 18:54:05 INFO JobScheduler: Starting job streaming job 1421837645000 ms.0 from job set of time 1421837645000 ms
15/01/21 18:54:05 INFO JobScheduler: Finished job streaming job 1421837645000 ms.0 from job set of time 1421837645000 ms
15/01/21 18:54:05 INFO JobScheduler: Total delay: 0.003 s for time 1421837645000 ms (execution: 0.003 s)
15/01/21 18:54:05 INFO BlockRDD: Removing RDD 81 from persistence list
15/01/21 18:54:05 INFO BlockManager: Removing RDD 81
15/01/21 18:54:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[81] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837645000 ms
15/01/21 18:54:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837635000 ms)
15/01/21 18:54:05 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:54:05 INFO BlockManagerInfo: Removed input-0-1421837641600 on sh-demo-hadoop-10:56623 in memory (size: 27.0 B, free: 264.9 MB)
15/01/21 18:54:05 INFO BlockManagerInfo: Removed input-0-1421837641600 on sh-demo-hadoop-03:44092 in memory (size: 27.0 B, free: 265.0 MB)
15/01/21 18:54:06 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:06 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:08 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:08 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:10 INFO JobScheduler: Added jobs for time 1421837650000 ms
15/01/21 18:54:10 INFO JobScheduler: Starting job streaming job 1421837650000 ms.0 from job set of time 1421837650000 ms
15/01/21 18:54:10 INFO JobScheduler: Finished job streaming job 1421837650000 ms.0 from job set of time 1421837650000 ms
15/01/21 18:54:10 INFO JobScheduler: Total delay: 0.004 s for time 1421837650000 ms (execution: 0.003 s)
15/01/21 18:54:10 INFO BlockRDD: Removing RDD 83 from persistence list
15/01/21 18:54:10 INFO BlockManager: Removing RDD 83
15/01/21 18:54:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[83] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837650000 ms
15/01/21 18:54:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837640000 ms)
15/01/21 18:54:10 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
15/01/21 18:54:10 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:10 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:12 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:14 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622
15/01/21 18:54:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Retrying connecting to 10.20.102.52:9999
15/01/21 18:54:15 INFO JobScheduler: Added jobs for time 1421837655000 ms
15/01/21 18:54:15 INFO JobScheduler: Starting job streaming job 1421837655000 ms.0 from job set of time 1421837655000 ms
15/01/21 18:54:15 INFO JobScheduler: Finished job streaming job 1421837655000 ms.0 from job set of time 1421837655000 ms
15/01/21 18:54:15 INFO JobScheduler: Total delay: 0.018 s for time 1421837655000 ms (execution: 0.017 s)
15/01/21 18:54:15 INFO BlockRDD: Removing RDD 84 from persistence list
15/01/21 18:54:15 INFO BlockManager: Removing RDD 84
15/01/21 18:54:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[84] at socketTextStream at NativeMethodAccessorImpl.java:-2 of time 1421837655000 ms
15/01/21 18:54:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1421837645000 ms)
15/01/21 18:54:15 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
>>>>>>> 190d2f6dd4a5b93c175db87e4fec93325d68c13b
15/01/21 18:54:16 INFO ReceiverTracker: Registered receiver for stream 0 from akka.tcp://sparkExecutor@sh-demo-hadoop-10:56622